{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"YouTube Spammer Purge What Is This? - Allows you to filter and search for spammer comments on your channel and other's channel(s) in many different ways AND delete/report them all at once (see features below). How to Download: Click the \" Releases \" link on the right, then on the latest release, under 'Assets' click to download \"YTSpammerPurge.exe\". (You might have to click \"Assets\" to view the files for the release) Linux Setup Instructions MacOS Setup Instructions (Windows installation not necessary if using exe file. But see how to set up required API key on this page ) Detailed Info & Documentation \u2192 Visit the wiki (Click Here) for more detailed writeups on the program \u00b6 Features \u00b6 15 Different Filtering Methods Auto-Smart Mode (Recommended) : Automatically detects multiple spammer techniques Sensitive-Smart Mode : More likely to catch elusive spammers, but with more false positives Scan by Channel ID : Enter a known spammer's channel link or ID directly Scan Usernames for: Individual special characters, individual strings, or using a custom Regex expression Scan Comment Text : (Same 3 options as above) Scan Usernames and Comment Text simultaneously: (Same 3 options as above) ASCII Mode : Scan Usernames for non-ASCII special characters (three different sensitivities) 4 Different Scanning Modes Scan a single video Scan Recent Videos (Up to 5) Scan recent comments across entire channel (all videos) Experimental : Scan a community post Automatic deletion of all found comments (after confirmation), as well as the option to ban them Options to instead Report spam comments or 'Hold For Review' Ability to create config file to skip pre-set options Rich text log files 'Recovery Mode' option to re-instate previously deleted comments Displays \"match samples\" after printing comments list to easily spot false positives Ability to exclude selected authors before deletion / reporting Purpose \u00b6 Recently, there has been a massive infestation of spam on YouTube where fake impersonator accounts leave spam/scam replies to hundreds of users on a creator's videos. For some god-forsaken reason, YouTube offers no way to delete all comments by a specific user at once, meaning you must delete them one by one BY HAND. YouTube offers a functionality to ban a user, but it does NOT delete previous comments. Therefore I created this script to allow you to instantly purge their spam replies, and since then it has evolved into a fully featured spam scanner as well. IT DOES NOT PREVENT SPAMMERS - It only makes it easier to delete them when they show up! YouTube still must implement better native tools for dealing with spammers. \ud83e\udd14 Pro-Tip If This Seems Sketchy: Limiting The App's Access \ud83e\udd14 \u00b6 If you feel sketched out about giving the app the required high level permissions to your channel (very understandable), you could instead use the app in 'moderator mode' (set in the config file). First, some context: When you grant access to another channel to be a moderator for your channel, they are able to mark comments for 'held for review', and this permission works through the API as well. Therefore, what you could do is create an blank dummy-google-account with nothing on it except a empty new channel. Then you can grant that channel permission to be a moderator, and use the app through the dummy moderator account . This way, you know that the app will never have the ability to do more than mark comments as held for review (which the app supports) on your main channel, and have no other access to your account's data. You just won't be able to ban the spammers through this app directly, but you can still remove/hide their comments instead of deleting them. Just make sure to create the google cloud API project on the dummy account instead. Read some additional details about 'moderator mode' on the wiki page here . Usage Notes -READ THIS \u00b6 To use this script, you will need to obtain your own API credentials file by making a project via the Google Developers Console (aka 'Google Cloud Platform'). The credential file should be re-named client_secret.json and be placed in the same directory as this script. See Instructions Here . IF IT FREEZES while scanning, it is probably because you clicked within the command prompt window and entered \"selection mode\" which pauses everything. To unfreeze it, simply right click within the window, or press the Escape key. I'm a total amateur, so if something doesn't work I'll try to fix it but might not even know how, so don't expect too much. Therefore I OFFER NO WARRANTY OR GUARANTEE FOR THIS SCRIPT. USE AT YOUR OWN RISK. I tested it on my own and implemented some failsafes as best as I could, but there could always be some kind of unexpected bug. You should inspect the code yourself. Video: Project Demonstrations \u00b6 Latest Demonstration Video: https://www.youtube.com/watch?v=2tRppXW_aKo Original Demo for Context: https://www.youtube.com/watch?v=-vOakOgYLUI (Takes you to YouTube, not embedded. See timestamps in video description.) Screenshots \u00b6 Opening Menu: Filter Mode Selection: Scanning (Auto Smart Mode): Matched Comments List: Match Samples and Deletion Menu: Installation \u00b6 If using the python script version (not the exe), there is a requirements.txt with necessary modules. Created with Python 3.9.7 Either way, you DO need to acquire your own API credentials file to access the YouTube API - See Instructions Here . Operating System Specific Instructions: Linux Setup Instructions MacOS Setup Instructions Docker Instructions: Before running docker-compose you must run the YTSpammerPurge.py script at least once with your client_secrets.json file to confirm OAuth credentials and generate the config/token files. The generated config files, token, and Spam Purge Resources will all be bound to the docker container via volumes. Once you generated the token and config files you are ready to run the docker image. Now you can run docker-compose up to start the container, or use the image to run on a Kubernetes cluster for example. To build your own version you can run this command: docker-compose -f docker-compose.yml -f docker-compose.override.yml up --build Instructions - Obtaining YouTube API Key \u00b6 To use this script, you will need an \"Oauth2\" credential to access the scanning and deletion functions via YouTube's Data API. Otherwise this script won't work at all. * #### Instructions can be found on this page: Instructions: Obtaining an API Key * #### Or, follow a video WalkThrough Here: https://www.youtube.com/watch?v=c6ebWvay8dE","title":"Overview"},{"location":"#detailed-info-documentation-visit-the-wiki-click-here-for-more-detailed-writeups-on-the-program","text":"","title":"Detailed Info &amp; Documentation \u2192 Visit the wiki (Click Here) for more detailed writeups on the program"},{"location":"#features","text":"15 Different Filtering Methods Auto-Smart Mode (Recommended) : Automatically detects multiple spammer techniques Sensitive-Smart Mode : More likely to catch elusive spammers, but with more false positives Scan by Channel ID : Enter a known spammer's channel link or ID directly Scan Usernames for: Individual special characters, individual strings, or using a custom Regex expression Scan Comment Text : (Same 3 options as above) Scan Usernames and Comment Text simultaneously: (Same 3 options as above) ASCII Mode : Scan Usernames for non-ASCII special characters (three different sensitivities) 4 Different Scanning Modes Scan a single video Scan Recent Videos (Up to 5) Scan recent comments across entire channel (all videos) Experimental : Scan a community post Automatic deletion of all found comments (after confirmation), as well as the option to ban them Options to instead Report spam comments or 'Hold For Review' Ability to create config file to skip pre-set options Rich text log files 'Recovery Mode' option to re-instate previously deleted comments Displays \"match samples\" after printing comments list to easily spot false positives Ability to exclude selected authors before deletion / reporting","title":"Features"},{"location":"#purpose","text":"Recently, there has been a massive infestation of spam on YouTube where fake impersonator accounts leave spam/scam replies to hundreds of users on a creator's videos. For some god-forsaken reason, YouTube offers no way to delete all comments by a specific user at once, meaning you must delete them one by one BY HAND. YouTube offers a functionality to ban a user, but it does NOT delete previous comments. Therefore I created this script to allow you to instantly purge their spam replies, and since then it has evolved into a fully featured spam scanner as well. IT DOES NOT PREVENT SPAMMERS - It only makes it easier to delete them when they show up! YouTube still must implement better native tools for dealing with spammers.","title":"Purpose"},{"location":"#pro-tip-if-this-seems-sketchy-limiting-the-apps-access","text":"If you feel sketched out about giving the app the required high level permissions to your channel (very understandable), you could instead use the app in 'moderator mode' (set in the config file). First, some context: When you grant access to another channel to be a moderator for your channel, they are able to mark comments for 'held for review', and this permission works through the API as well. Therefore, what you could do is create an blank dummy-google-account with nothing on it except a empty new channel. Then you can grant that channel permission to be a moderator, and use the app through the dummy moderator account . This way, you know that the app will never have the ability to do more than mark comments as held for review (which the app supports) on your main channel, and have no other access to your account's data. You just won't be able to ban the spammers through this app directly, but you can still remove/hide their comments instead of deleting them. Just make sure to create the google cloud API project on the dummy account instead. Read some additional details about 'moderator mode' on the wiki page here .","title":"\ud83e\udd14 Pro-Tip If This Seems Sketchy: Limiting The App's Access \ud83e\udd14"},{"location":"#usage-notes-read-this","text":"To use this script, you will need to obtain your own API credentials file by making a project via the Google Developers Console (aka 'Google Cloud Platform'). The credential file should be re-named client_secret.json and be placed in the same directory as this script. See Instructions Here . IF IT FREEZES while scanning, it is probably because you clicked within the command prompt window and entered \"selection mode\" which pauses everything. To unfreeze it, simply right click within the window, or press the Escape key. I'm a total amateur, so if something doesn't work I'll try to fix it but might not even know how, so don't expect too much. Therefore I OFFER NO WARRANTY OR GUARANTEE FOR THIS SCRIPT. USE AT YOUR OWN RISK. I tested it on my own and implemented some failsafes as best as I could, but there could always be some kind of unexpected bug. You should inspect the code yourself.","title":"Usage Notes -READ THIS"},{"location":"#video-project-demonstrations","text":"Latest Demonstration Video: https://www.youtube.com/watch?v=2tRppXW_aKo Original Demo for Context: https://www.youtube.com/watch?v=-vOakOgYLUI (Takes you to YouTube, not embedded. See timestamps in video description.)","title":"Video: Project Demonstrations"},{"location":"#screenshots","text":"Opening Menu: Filter Mode Selection: Scanning (Auto Smart Mode): Matched Comments List: Match Samples and Deletion Menu:","title":"Screenshots"},{"location":"#installation","text":"If using the python script version (not the exe), there is a requirements.txt with necessary modules. Created with Python 3.9.7 Either way, you DO need to acquire your own API credentials file to access the YouTube API - See Instructions Here . Operating System Specific Instructions: Linux Setup Instructions MacOS Setup Instructions Docker Instructions: Before running docker-compose you must run the YTSpammerPurge.py script at least once with your client_secrets.json file to confirm OAuth credentials and generate the config/token files. The generated config files, token, and Spam Purge Resources will all be bound to the docker container via volumes. Once you generated the token and config files you are ready to run the docker image. Now you can run docker-compose up to start the container, or use the image to run on a Kubernetes cluster for example. To build your own version you can run this command: docker-compose -f docker-compose.yml -f docker-compose.override.yml up --build","title":"Installation"},{"location":"#instructions-obtaining-youtube-api-key","text":"To use this script, you will need an \"Oauth2\" credential to access the scanning and deletion functions via YouTube's Data API. Otherwise this script won't work at all. * #### Instructions can be found on this page: Instructions: Obtaining an API Key * #### Or, follow a video WalkThrough Here: https://www.youtube.com/watch?v=c6ebWvay8dE","title":"Instructions - Obtaining YouTube API Key"},{"location":"contributing/","text":"Contributing Guidelines \u00b6 If you'd like to make a pull request to contribute, please keep it simple. If you use some higher level techniques I don't understand, I'm not going to approve it because I won't be able to maintain it. Please don't make a pull request with a bunch of changes in syntax just for the sake of 'best practices' (ex: changing \"if blah == False\" to \"if not blah\"). Unless something makes a difference to performance frankly I don't care. Avoid adding new non-standard libraries if at all possible. If you have an idea that would require one, please suggest it as an issue first instead of going through all the work and submitting a pull request. Don't modify SpamAccountsList.txt, SpamDomainsList.txt & SpamThreadsList.txt in the assets folder. There is a dedicated repo for these, for which you can submit additions via issues - https://github.com/ThioJoe/YT-Spam-Domains-List MAKE SURE IT RUNS","title":"Contributing"},{"location":"contributing/#contributing-guidelines","text":"If you'd like to make a pull request to contribute, please keep it simple. If you use some higher level techniques I don't understand, I'm not going to approve it because I won't be able to maintain it. Please don't make a pull request with a bunch of changes in syntax just for the sake of 'best practices' (ex: changing \"if blah == False\" to \"if not blah\"). Unless something makes a difference to performance frankly I don't care. Avoid adding new non-standard libraries if at all possible. If you have an idea that would require one, please suggest it as an issue first instead of going through all the work and submitting a pull request. Don't modify SpamAccountsList.txt, SpamDomainsList.txt & SpamThreadsList.txt in the assets folder. There is a dedicated repo for these, for which you can submit additions via issues - https://github.com/ThioJoe/YT-Spam-Domains-List MAKE SURE IT RUNS","title":"Contributing Guidelines"},{"location":"credits/","text":"Credits \u00b6 These projects were used to build YT-Spammer-Purge . Thank you! python | poetry | copier-poetry Run dependencies \u00b6 Package Description Version License certifi Python package for providing Mozilla's CA Bundle. 2021.10.8 MPL-2.0 colorama Cross-platform colored terminal text. 0.4.4 BSD confusables A python package providing functionality for matching words that can be confused for eachother, but contain different characters 1.2.0 UNKNOWN google-api-python-client Google API Client Library for Python 2.33.0 Apache 2.0 google-auth-oauthlib Google Authentication Library 0.4.6 Apache 2.0 protobuf Protocol Buffers 3.19.1 3-Clause BSD License python-Levenshtein Python extension for computing string edit distances and similarities. 0.12.2 GPL rtfunicode Encoder for unicode to RTF 1.5 command sequences 2.0 BSD six Python 2 and 3 compatibility utilities 1.16.0 MIT Development dependencies \u00b6 Package Description Version License mkdocs-gen-files MkDocs plugin to programmatically generate documentation pages during the build 0.3.4 MIT mkdocs-literate-nav MkDocs plugin to specify the navigation in Markdown instead of YAML 0.4.1 MIT mkdocs-macros-plugin Unleash the power of MkDocs with macros and variables 0.6.4 MIT mkdocs-material A Material Design theme for MkDocs 8.1.11 MIT mkdocstrings Automatic documentation from sources, for MkDocs. 0.18.0 UNKNOWN pytest pytest: simple powerful testing with Python 6.2.5 MIT Indirect dependencies \u00b6 Package Description Version License astunparse atomicwrites attrs Classes Without Boilerplate 21.4.0 MIT better-exceptions cached-property cachetools Extensible memoizing collections and decorators 4.2.4 MIT charset-normalizer The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. 2.0.12 MIT click Composable command line interface toolkit 8.0.3 BSD-3-Clause fancycompleter ghp-import Copy your docs directly to the gh-pages branch. 2.0.2 Apache Software License google-api-core Google API client core library 2.5.0 Apache 2.0 google-auth Google Authentication Library 2.6.0 Apache 2.0 google-auth-httplib2 Google Authentication Library: httplib2 transport 0.1.0 Apache 2.0 googleapis-common-protos Common protobufs used in Google APIs 1.54.0 Apache-2.0 griffe Signatures for entire Python programs. Extract the structure, the frame, the skeleton of your project, to generate API documentation or find breaking changes in your API. 0.12.2 UNKNOWN httplib2 A comprehensive HTTP client library. 0.20.4 MIT idna Internationalized Domain Names in Applications (IDNA) 3.3 BSD-3-Clause importlib-metadata Read metadata from Python packages 4.8.3 UNKNOWN iniconfig iniconfig: brain-dead simple config-ini parsing 1.1.1 MIT License Jinja2 A very fast and expressive template engine. 3.0.3 BSD-3-Clause Markdown Python implementation of Markdown. 3.3.6 BSD License MarkupSafe Safely add untrusted strings to HTML/XML markup. 2.0.1 BSD-3-Clause mergedeep A deep merge function for \ud83d\udc0d. 1.3.4 UNKNOWN mkdocs Project documentation with Markdown. 1.2.3 BSD mkdocs-autorefs Automatically link across pages in MkDocs. 0.3.1 ISC mkdocs-material-extensions Extension pack for Python Markdown. 1.0.3 MIT License mkdocstrings-python A Python handler for mkdocstrings. 0.6.0 UNKNOWN mkdocstrings-python-legacy A legacy Python handler for mkdocstrings. 0.2.1 UNKNOWN oauthlib A generic, spec-compliant, thorough implementation of the OAuth request-signing logic 3.2.0 BSD packaging Core utilities for Python packages 21.3 BSD-2-Clause or Apache-2.0 pdbpp pluggy plugin and hook calling mechanisms for python 1.0.0 MIT py library with cross-python path, ini-parsing, io, code, log facilities 1.11.0 MIT license pyasn1 ASN.1 types and codecs 0.4.8 BSD pyasn1-modules A collection of ASN.1-based protocols modules. 0.2.8 BSD-2-Clause Pygments Pygments is a syntax highlighting package written in Python. 2.11.2 BSD License pymdown-extensions Extension pack for Python Markdown. 9.2 MIT License pyparsing Python parsing module 3.0.7 MIT License pyreadline pyrepl python-dateutil Extensions to the standard Python datetime module 2.8.2 Dual License pytkdocs Load Python objects documentation. 0.15.0 UNKNOWN PyYAML YAML parser and emitter for Python 6.0 MIT pyyaml-env-tag requests Python HTTP for Humans. 2.27.1 Apache 2.0 requests-oauthlib OAuthlib authentication support for Requests. 1.3.1 ISC rsa Pure-Python RSA implementation 4.8 Apache-2.0 termcolor ANSII Color formatting for output in terminal. 1.1.0 MIT toml Python Library for Tom's Obvious, Minimal Language 0.10.2 MIT typing-extensions uritemplate Implementation of RFC 6570 URI Templates 4.1.1 BSD 3-Clause License or Apache License, Version 2.0 urllib3 HTTP library with thread-safe connection pooling, file post, and more. 1.26.8 MIT watchdog Filesystem events monitoring 2.1.6 Apache License 2.0 wmctrl zipp Backport of pathlib-compatible object wrapper for zip files 3.6.0 UNKNOWN","title":"Credits"},{"location":"credits/#credits","text":"These projects were used to build YT-Spammer-Purge . Thank you! python | poetry | copier-poetry","title":"Credits"},{"location":"credits/#run-dependencies","text":"Package Description Version License certifi Python package for providing Mozilla's CA Bundle. 2021.10.8 MPL-2.0 colorama Cross-platform colored terminal text. 0.4.4 BSD confusables A python package providing functionality for matching words that can be confused for eachother, but contain different characters 1.2.0 UNKNOWN google-api-python-client Google API Client Library for Python 2.33.0 Apache 2.0 google-auth-oauthlib Google Authentication Library 0.4.6 Apache 2.0 protobuf Protocol Buffers 3.19.1 3-Clause BSD License python-Levenshtein Python extension for computing string edit distances and similarities. 0.12.2 GPL rtfunicode Encoder for unicode to RTF 1.5 command sequences 2.0 BSD six Python 2 and 3 compatibility utilities 1.16.0 MIT","title":"Run dependencies"},{"location":"credits/#development-dependencies","text":"Package Description Version License mkdocs-gen-files MkDocs plugin to programmatically generate documentation pages during the build 0.3.4 MIT mkdocs-literate-nav MkDocs plugin to specify the navigation in Markdown instead of YAML 0.4.1 MIT mkdocs-macros-plugin Unleash the power of MkDocs with macros and variables 0.6.4 MIT mkdocs-material A Material Design theme for MkDocs 8.1.11 MIT mkdocstrings Automatic documentation from sources, for MkDocs. 0.18.0 UNKNOWN pytest pytest: simple powerful testing with Python 6.2.5 MIT","title":"Development dependencies"},{"location":"credits/#indirect-dependencies","text":"Package Description Version License astunparse atomicwrites attrs Classes Without Boilerplate 21.4.0 MIT better-exceptions cached-property cachetools Extensible memoizing collections and decorators 4.2.4 MIT charset-normalizer The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. 2.0.12 MIT click Composable command line interface toolkit 8.0.3 BSD-3-Clause fancycompleter ghp-import Copy your docs directly to the gh-pages branch. 2.0.2 Apache Software License google-api-core Google API client core library 2.5.0 Apache 2.0 google-auth Google Authentication Library 2.6.0 Apache 2.0 google-auth-httplib2 Google Authentication Library: httplib2 transport 0.1.0 Apache 2.0 googleapis-common-protos Common protobufs used in Google APIs 1.54.0 Apache-2.0 griffe Signatures for entire Python programs. Extract the structure, the frame, the skeleton of your project, to generate API documentation or find breaking changes in your API. 0.12.2 UNKNOWN httplib2 A comprehensive HTTP client library. 0.20.4 MIT idna Internationalized Domain Names in Applications (IDNA) 3.3 BSD-3-Clause importlib-metadata Read metadata from Python packages 4.8.3 UNKNOWN iniconfig iniconfig: brain-dead simple config-ini parsing 1.1.1 MIT License Jinja2 A very fast and expressive template engine. 3.0.3 BSD-3-Clause Markdown Python implementation of Markdown. 3.3.6 BSD License MarkupSafe Safely add untrusted strings to HTML/XML markup. 2.0.1 BSD-3-Clause mergedeep A deep merge function for \ud83d\udc0d. 1.3.4 UNKNOWN mkdocs Project documentation with Markdown. 1.2.3 BSD mkdocs-autorefs Automatically link across pages in MkDocs. 0.3.1 ISC mkdocs-material-extensions Extension pack for Python Markdown. 1.0.3 MIT License mkdocstrings-python A Python handler for mkdocstrings. 0.6.0 UNKNOWN mkdocstrings-python-legacy A legacy Python handler for mkdocstrings. 0.2.1 UNKNOWN oauthlib A generic, spec-compliant, thorough implementation of the OAuth request-signing logic 3.2.0 BSD packaging Core utilities for Python packages 21.3 BSD-2-Clause or Apache-2.0 pdbpp pluggy plugin and hook calling mechanisms for python 1.0.0 MIT py library with cross-python path, ini-parsing, io, code, log facilities 1.11.0 MIT license pyasn1 ASN.1 types and codecs 0.4.8 BSD pyasn1-modules A collection of ASN.1-based protocols modules. 0.2.8 BSD-2-Clause Pygments Pygments is a syntax highlighting package written in Python. 2.11.2 BSD License pymdown-extensions Extension pack for Python Markdown. 9.2 MIT License pyparsing Python parsing module 3.0.7 MIT License pyreadline pyrepl python-dateutil Extensions to the standard Python datetime module 2.8.2 Dual License pytkdocs Load Python objects documentation. 0.15.0 UNKNOWN PyYAML YAML parser and emitter for Python 6.0 MIT pyyaml-env-tag requests Python HTTP for Humans. 2.27.1 Apache 2.0 requests-oauthlib OAuthlib authentication support for Requests. 1.3.1 ISC rsa Pure-Python RSA implementation 4.8 Apache-2.0 termcolor ANSII Color formatting for output in terminal. 1.1.0 MIT toml Python Library for Tom's Obvious, Minimal Language 0.10.2 MIT typing-extensions uritemplate Implementation of RFC 6570 URI Templates 4.1.1 BSD 3-Clause License or Apache License, Version 2.0 urllib3 HTTP library with thread-safe connection pooling, file post, and more. 1.26.8 MIT watchdog Filesystem events monitoring 2.1.6 Apache License 2.0 wmctrl zipp Backport of pathlib-compatible object wrapper for zip files 3.6.0 UNKNOWN","title":"Indirect dependencies"},{"location":"license/","text":"GNU GENERAL PUBLIC LICENSE Version 3, 29 June 2007 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/> Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. Preamble The GNU General Public License is a free, copyleft license for software and other kinds of works. The licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too. When we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things. To protect your rights, we need to prevent others from denying you these rights or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others. For example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights. Developers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and/or modify it. For the developers' and authors' protection, the GPL clearly explains that there is no warranty for this free software. For both users' and authors' sake, the GPL requires that modified versions be marked as changed, so that their problems will not be attributed erroneously to authors of previous versions. Some devices are designed to deny users access to install or run modified versions of the software inside them, although the manufacturer can do so. This is fundamentally incompatible with the aim of protecting users' freedom to change the software. The systematic pattern of such abuse occurs in the area of products for individuals to use, which is precisely where it is most unacceptable. Therefore, we have designed this version of the GPL to prohibit the practice for those products. If such problems arise substantially in other domains, we stand ready to extend this provision to those domains in future versions of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software patents. States should not allow patents to restrict development and use of software on general-purpose computers, but in those that do, we wish to avoid the special danger that patents applied to a free program could make it effectively proprietary. To prevent this, the GPL assures that patents cannot be used to render the program non-free. The precise terms and conditions for copying, distribution and modification follow. TERMS AND CONDITIONS 0. Definitions. \"This License\" refers to version 3 of the GNU General Public License. \"Copyright\" also means copyright-like laws that apply to other kinds of works, such as semiconductor masks. \"The Program\" refers to any copyrightable work licensed under this License. Each licensee is addressed as \"you\". \"Licensees\" and \"recipients\" may be individuals or organizations. To \"modify\" a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a \"modified version\" of the earlier work or a work \"based on\" the earlier work. A \"covered work\" means either the unmodified Program or a work based on the Program. To \"propagate\" a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well. To \"convey\" a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays \"Appropriate Legal Notices\" to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion. 1. Source Code. The \"source code\" for a work means the preferred form of the work for making modifications to it. \"Object code\" means any non-source form of a work. A \"Standard Interface\" means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language. The \"System Libraries\" of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A \"Major Component\", in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it. The \"Corresponding Source\" for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work's System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work. The Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source. The Corresponding Source for a work in source code form is that same work. 2. Basic Permissions. All rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law. You may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you. Conveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary. 3. Protecting Users' Legal Rights From Anti-Circumvention Law. No covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures. When you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work's users, your or third parties' legal rights to forbid circumvention of technological measures. 4. Conveying Verbatim Copies. You may convey verbatim copies of the Program's source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program. You may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee. 5. Conveying Modified Source Versions. You may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions: a) The work must carry prominent notices stating that you modified it, and giving a relevant date. b) The work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to \"keep intact all notices\". c) You must license the entire work, as a whole, under this License to anyone who comes into possession of a copy. This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged. This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it. d) If the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so. A compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an \"aggregate\" if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation's users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate. 6. Conveying Non-Source Forms. You may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways: a) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange. b) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the written offer to provide the Corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b. d) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d. A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work. A \"User Product\" is either (1) a \"consumer product\", which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, \"normally used\" refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product. \"Installation Information\" for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made. If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM). The requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying. 7. Additional Terms. \"Additional permissions\" are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions. When you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission. Notwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms: a) Disclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or b) Requiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or c) Prohibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or d) Limiting the use for publicity purposes of names of licensors or authors of the material; or e) Declining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or f) Requiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors. All other non-permissive additional terms are considered \"further restrictions\" within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying. If you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms. Additional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way. 8. Termination. You may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11). However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation. Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice. Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10. 9. Acceptance Not Required for Having Copies. You are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so. 10. Automatic Licensing of Downstream Recipients. Each time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License. An \"entity transaction\" is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party's predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts. You may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it. 11. Patents. A \"contributor\" is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor's \"contributor version\". A contributor's \"essential patent claims\" are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, \"control\" includes the right to grant patent sublicenses in a manner consistent with the requirements of this License. Each contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor's essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version. In the following three paragraphs, a \"patent license\" is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To \"grant\" such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party. If you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. \"Knowingly relying\" means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient's use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it. A patent license is \"discriminatory\" if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007. Nothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law. 12. No Surrender of Others' Freedom. If conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program. 13. Use with the GNU Affero General Public License. Notwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU Affero General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the special requirements of the GNU Affero General Public License, section 13, concerning interaction through a network will apply to the combination as such. 14. Revised Versions of this License. The Free Software Foundation may publish revised and/or new versions of the GNU General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU General Public License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU General Public License, you may choose any version ever published by the Free Software Foundation. If the Program specifies that a proxy can decide which future versions of the GNU General Public License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Program. Later license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version. 15. Disclaimer of Warranty. THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION. 16. Limitation of Liability. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. 17. Interpretation of Sections 15 and 16. If the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee. END OF TERMS AND CONDITIONS How to Apply These Terms to Your New Programs If you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms. To do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the \"copyright\" line and a pointer to where the full notice is found. <one line to give the program's name and a brief idea of what it does.> Copyright (C) <year> <name of author> This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see <https://www.gnu.org/licenses/>. Also add information on how to contact you by electronic and paper mail. If the program does terminal interaction, make it output a short notice like this when it starts in an interactive mode: <program> Copyright (C) <year> <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details. The hypothetical commands `show w' and `show c' should show the appropriate parts of the General Public License. Of course, your program's commands might be different; for a GUI interface, you would use an \"about box\". You should also get your employer (if you work as a programmer) or school, if any, to sign a \"copyright disclaimer\" for the program, if necessary. For more information on this, and how to apply and follow the GNU GPL, see <https://www.gnu.org/licenses/>. The GNU General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Lesser General Public License instead of this License. But first, please read <https://www.gnu.org/licenses/why-not-lgpl.html>.","title":"License"},{"location":"reference/SUMMARY/","text":"YTSpammerPurge Scripts auth community_downloader files gui logging operations prepare_modes shared_imports utils validation","title":"SUMMARY"},{"location":"reference/YTSpammerPurge/","text":"configVersion module-attribute \u00b6 configVersion = 26 reason module-attribute \u00b6 reason = str ( hx . error_details [ 0 ][ 'reason' ]) version module-attribute \u00b6 version = '2.15.4' main \u00b6 main () Source code in YT-Spammer-Purge/YTSpammerPurge.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 def main (): # Run check on python version, must be 3.6 or higher because of f strings if sys . version_info [ 0 ] < 3 or sys . version_info [ 1 ] < 6 : print ( \"Error Code U-2: This program requires running python 3.6 or higher! You are running\" + str ( sys . version_info [ 0 ]) + \".\" + str ( sys . version_info [ 1 ])) input ( \"Press Enter to exit...\" ) sys . exit () # Declare Global Variables global YOUTUBE global CURRENTUSER User = namedtuple ( 'User' , 'id name configMatch' ) # Some Typehints scanMode : str config : dict jsonData : dict versionInfoJson : dict # Checks system platform to set correct console clear command # Clears console otherwise the windows terminal doesn't work with colorama for some reason clear_command = \"cls\" if platform . system () == \"Windows\" else \"clear\" os . system ( clear_command ) # Initiates colorama and creates shorthand variables for resetting colors init ( autoreset = True ) S . R = S . RESET_ALL F . R = F . RESET B . R = B . RESET print ( \" \\n Loading YT Spammer Purge @ \" + str ( version ) + \"...\" ) # Authenticate with the Google API - If token expired and invalid, deletes and re-authenticates YOUTUBE = auth . first_authentication () #### Prepare Resources #### resourceFolder = RESOURCES_FOLDER_NAME whitelistPathWithName = os . path . join ( resourceFolder , \"whitelist.txt\" ) spamListFolder = os . path . join ( resourceFolder , \"Spam_Lists\" ) spamListDict = { 'Lists' : { 'Domains' : { 'FileName' : \"SpamDomainsList.txt\" }, 'Accounts' : { 'FileName' : \"SpamAccountsList.txt\" }, 'Threads' : { 'FileName' : \"SpamThreadsList.txt\" } }, 'Meta' : { 'VersionInfo' : { 'FileName' : \"SpamVersionInfo.json\" }, 'SpamListFolder' : spamListFolder #'LatestLocalVersion': {} } } resourcesDict = { 'Whitelist' : { 'PathWithName' : whitelistPathWithName , 'FileName' : \"whitelist.txt\" , } } print ( \"Checking for updates to program and spam lists...\" ) # Check if resources and spam list folders exist, and create them if not os . path . isdir ( resourceFolder ): try : os . mkdir ( resourceFolder ) # Create readme with open ( os . path . join ( resourceFolder , \"_What_Is_This_Folder.txt\" ), \"w\" ) as f : f . write ( \"# This Resources folder is used to store resources required for the YT Spammer Purge program. \\n \" ) f . write ( \"# Note: If you had a previous spam_lists folder that was created in the same folder as \\n \" ) f . write ( \"# the .exe file, you can delete that old spam_lists folder. The resources folder is the \\n \" ) f . write ( \"# new location they will be stored. \\n \" ) except : print ( \" \\n Error: Could not create folder. To update the spam lists, try creating a folder called 'SpamPurge_Resources',\" ) print ( \" then inside that, create another folder called 'Spam_Lists'.\" ) input ( \"Press Enter to continue...\" ) if os . path . isdir ( resourceFolder ) and not os . path . isdir ( spamListFolder ): try : os . mkdir ( spamListFolder ) except : print ( \" \\n Error: Could not create folder. To update the spam lists, go into the 'SpamPurge_Resources' folder,\" ) print ( \" then inside that, create another folder called 'Spam_Lists'.\" ) # Prepare to check and ingest spammer list files # Iterate and get paths of each list for x , spamList in spamListDict [ 'Lists' ] . items (): spamList [ 'Path' ] = os . path . join ( spamListFolder , spamList [ 'FileName' ]) spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ] = os . path . join ( spamListFolder , spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'FileName' ]) # Path to version included in packaged assets folder # Check if each spam list exists, if not copy from assets, then get local version number, calculate latest version number latestLocalSpamListVersion = \"1900.12.31\" for x , spamList in spamListDict [ 'Lists' ] . items (): if not os . path . exists ( spamList [ 'Path' ]): files . copy_asset_file ( spamList [ 'FileName' ], spamList [ 'Path' ]) listVersion = files . get_list_file_version ( spamList [ 'Path' ]) spamList [ 'Version' ] = listVersion if listVersion and parse_version ( listVersion ) > parse_version ( latestLocalSpamListVersion ): latestLocalSpamListVersion = listVersion spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestLocalVersion' ] = latestLocalSpamListVersion # Check for version info file, if it doesn't exist, get from assets folder if not os . path . exists ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ]): files . copy_asset_file ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'FileName' ], spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ]) # Get stored spam list version data from json file jsonData = open ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ], 'r' , encoding = \"utf-8\" ) versionInfoJson = str ( json . load ( jsonData )) # Parses json file into a string versionInfo = ast . literal_eval ( versionInfoJson ) # Parses json string into a dictionary spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestRelease' ] = versionInfo [ 'LatestRelease' ] spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LastChecked' ] = versionInfo [ 'LastChecked' ] # Check for primary config file, load into dictionary 'config'. If no config found, loads data from default config in assets folder os . system ( clear_command ) config = files . load_config_file ( configVersion ) validation . validate_config_settings ( config ) os . system ( clear_command ) # Check for program and list updates if auto updates enabled in config try : if config [ 'release_channel' ] == \"all\" : updateReleaseChannel = \"all\" elif config [ 'release_channel' ] == \"stable\" : updateReleaseChannel = \"stable\" else : print ( \"Invalid value for 'release_channel' in config file. Must be 'All' or 'Stable'\" ) print ( \"Defaulting to 'All'\" ) input ( \"Press Enter to continue...\" ) updateReleaseChannel = \"all\" except KeyError : print ( \" \\n Your version of the config file does not specify a release channel. Defaulting to 'All'\" ) print ( f \" { F . YELLOW } Re-create your config { S . R } to get the latest version.\" ) input ( \" \\n Press Enter to continue...\" ) updateReleaseChannel = \"all\" if config [ 'auto_check_update' ] == True : try : updateAvailable = files . check_for_update ( version , updateReleaseChannel , silentCheck = True , ) except Exception as e : print ( f \" { F . LIGHTRED_EX } Error Code U-3 occurred while checking for updates. (Checking can be disabled using the config file setting) Continuing... { S . R } \\n \" ) updateAvailable = None # Check if today or tomorrow's date is later than the last update date (add day to account for time zones) if datetime . today () + timedelta ( days = 1 ) >= datetime . strptime ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestLocalVersion' ], '%Y.%m. %d ' ): # Only check for updates until the next day if datetime . today () > datetime . strptime ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LastChecked' ], '%Y.%m. %d .%H.%M' ) + timedelta ( days = 1 ): spamListDict = files . check_lists_update ( spamListDict , silentCheck = True ) else : updateAvailable = False # In all scenarios, load spam lists into memory for x , spamList in spamListDict [ 'Lists' ] . items (): spamList [ 'FilterContents' ] = files . ingest_list_file ( spamList [ 'Path' ], keepCase = False ) ####### Load Other Data into MiscData ####### print ( \" \\n Loading other assets.. \\n \" ) @dataclass class MiscDataStore : resources : dict spamLists : dict rootDomainsList : list totalCommentCount : int channelOwnerID : str channelOwnerName : str miscData = MiscDataStore ( resources = {}, spamLists = {}, rootDomainsList = [], totalCommentCount = 0 , channelOwnerID = \"\" , channelOwnerName = \"\" , ) rootDomainListAssetFile = \"rootZoneDomainList.txt\" rootDomainList = files . ingest_asset_file ( rootDomainListAssetFile ) miscData . resources = rootDomainList miscData . spamLists [ 'spamDomainsList' ] = spamListDict [ 'Lists' ][ 'Domains' ][ 'FilterContents' ] miscData . spamLists [ 'spamAccountsList' ] = spamListDict [ 'Lists' ][ 'Accounts' ][ 'FilterContents' ] miscData . spamLists [ 'spamThreadsList' ] = spamListDict [ 'Lists' ][ 'Threads' ][ 'FilterContents' ] miscData . resources = resourcesDict # Create Whitelist if it doesn't exist, if not os . path . exists ( whitelistPathWithName ): with open ( whitelistPathWithName , \"a\" ) as f : f . write ( \"# Commenters whose channel IDs are in this list will always be ignored. You can add or remove IDs (one per line) from this list as you wish. \\n \" ) f . write ( \"# Channel IDs for a channel can be found in the URL after clicking a channel's name while on the watch page or where they've left a comment. \\n \" ) f . write ( \"# - Channels that were 'excluded' will also appear in this list. \\n \" ) f . write ( \"# - Lines beginning with a '#' are comments and aren't read by the program. (But do not put a '#' on the same line as actual data) \\n\\n \" ) miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] = [] else : miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] = files . ingest_list_file ( whitelistPathWithName , keepCase = True ) if config : moderator_mode = config [ 'moderator_mode' ] else : moderator_mode = False os . system ( clear_command ) #----------------------------------- Begin Showing Program --------------------------------- print ( f \" { F . LIGHTYELLOW_EX } \\n ===================== YOUTUBE SPAMMER PURGE v\" + version + f \" ===================== { S . R } \" ) print ( \"=========== https://github.com/ThioJoe/YT-Spammer-Purge ===========\" ) print ( \"================= Author: ThioJoe - YouTube.com/ThioJoe ================ \\n \" ) # Instructions print ( \"Purpose: Lets you scan for spam comments and mass-delete them all at once \\n \" ) print ( \"NOTE: It's probably better to scan individual videos, because you can scan all those comments,\" ) print ( \" but scanning your entire channel must be limited and might miss older spam comments.\" ) print ( \"You will be shown the comments to confirm before they are deleted.\" ) # While loop until user confirms they are logged into the correct account confirmedCorrectLogin = False while confirmedCorrectLogin == False : # Get channel ID and title of current user, confirm with user userInfo = auth . get_current_user ( config ) CURRENTUSER = User ( id = userInfo [ 0 ], name = userInfo [ 1 ], configMatch = userInfo [ 2 ]) # Returns [channelID, channelTitle, configmatch] auth . CURRENTUSER = CURRENTUSER print ( \" \\n > Currently logged in user: \" + f \" { F . LIGHTGREEN_EX } \" + str ( CURRENTUSER . name ) + f \" { S . R } (Channel ID: { F . LIGHTGREEN_EX } \" + str ( CURRENTUSER . id ) + f \" { S . R } )\" ) if choice ( \" Continue as this user?\" , CURRENTUSER . configMatch ) == True : confirmedCorrectLogin = True os . system ( clear_command ) else : auth . remove_token () os . system ( clear_command ) YOUTUBE = auth . get_authenticated_service () # Declare Classes @dataclass class ScanInstance : matchedCommentsDict : dict duplicateCommentsDict : dict otherCommentsByMatchedAuthorsDict : dict spamThreadsDict : dict allScannedCommentsDict : dict vidIdDict : dict vidTitleDict : dict matchSamplesDict : dict authorMatchCountDict : dict scannedRepliesCount : int scannedCommentsCount : int logTime : str logFileName : str errorOccurred : bool # matchTypeCount:dict ############################################## ######### PRIMARY INSTANCE FUNCTION ########## ############################################## ## Allows Re-running Program From Main Menu ## ############################################## def primaryInstance ( miscData ): timestamp = datetime . now () . strftime ( \"%Y-%m- %d _%H-%M-%S\" ) # Instantiate class for primary instance current = ScanInstance ( matchedCommentsDict = {}, duplicateCommentsDict = {}, otherCommentsByMatchedAuthorsDict = {}, spamThreadsDict = {}, allScannedCommentsDict = {}, vidIdDict = {}, vidTitleDict = {}, matchSamplesDict = {}, authorMatchCountDict = {}, scannedRepliesCount = 0 , scannedCommentsCount = 0 , logTime = timestamp , logFileName = None , errorOccurred = False , ) # Declare Default Variables maxScanNumber = 999999999 scanVideoID = None videosToScan = [] loggingEnabled = False userNotChannelOwner = False os . system ( clear_command ) # ----------------------------------------------------------------------------------------------------------------------------- if updateAvailable != False : updateStringLabel = \"Update Available: \" if updateAvailable == True : # Stable update available updateString = f \" { F . LIGHTGREEN_EX } Yes { S . R } \" elif updateAvailable == \"beta\" : # Beta Update Available if updateReleaseChannel == \"stable\" : updateStringLabel = \"\" updateString = \"\" else : updateString = f \" { F . CYAN } Beta { S . R } \" elif updateAvailable == None : updateString = f \" { F . LIGHTRED_EX } Error { S . R } \" print ( \"> Note: Error during check for updates. Select 'Check For Updates' for details.\" ) else : if config [ 'auto_check_update' ] == False : updateStringLabel = \"Update Checking: \" updateString = \"Off\" else : updateStringLabel = \"\" updateString = \"\" # User selects scanning mode, while Loop to get scanning mode, so if invalid input, it will keep asking until valid input print ( \" \\n {:<59}{:<18}{:>5} \" . format ( \"> At any prompt, enter 'X' to return here\" , updateStringLabel , updateString )) print ( \"> Enter 'Q' now to quit\" ) print ( f \" \\n\\n -------------------------------- { F . YELLOW } Scanning Options { S . R } --------------------------------\" ) print ( f \" 1. Scan { F . LIGHTCYAN_EX } specific videos { S . R } \" ) print ( f \" 2. Scan { F . LIGHTCYAN_EX } recent videos { S . R } for a channel\" ) print ( f \" 3. Scan recent comments across your { F . LIGHTBLUE_EX } Entire Channel { S . R } \" ) print ( f \" 4. Scan a specific { F . LIGHTMAGENTA_EX } community post { S . R } (Experimental)\" ) print ( f \" 5. Scan { F . LIGHTMAGENTA_EX } recent community posts { S . R } for a channel (Experimental)\" ) print ( f \" \\n --------------------------------- { F . YELLOW } Other Options { S . R } ----------------------------------\" ) print ( f \" 6. Create your own { F . LIGHTGREEN_EX } config file(s) { S . R } to run the program with pre-set settings\" ) print ( f \" 7. Remove comments using a { F . LIGHTRED_EX } pre-existing list { S . R } or log file\" ) print ( f \" 8. Recover deleted comments using log file\" ) print ( f \" 9. Check & Download { F . LIGHTCYAN_EX } Updates { S . R } \\n \" ) # Make sure input is valid, if not ask again validMode : bool = False validConfigSetting : bool = True while validMode == False : if validConfigSetting == True and config and config [ 'scan_mode' ] != 'ask' : scanMode = config [ 'scan_mode' ] else : scanMode = input ( \"Choice (1-9): \" ) if scanMode . lower () == \"q\" : sys . exit () # Set scanMode Variable Names validModeValues = [ '1' , '2' , '3' , '4' , '5' , '6' , '7' , '8' , '9' , 'chosenvideos' , 'recentvideos' , 'entirechannel' , 'communitypost' , 'commentlist' , 'recentcommunityposts' ] if scanMode in validModeValues : validMode = True if scanMode == \"1\" or scanMode == \"chosenvideos\" : scanMode = \"chosenVideos\" elif scanMode == \"2\" or scanMode == \"recentvideos\" : scanMode = \"recentVideos\" elif scanMode == \"3\" or scanMode == \"entirechannel\" : scanMode = \"entireChannel\" elif scanMode == \"4\" or scanMode == \"communitypost\" : scanMode = \"communityPost\" elif scanMode == \"5\" or scanMode == \"recentcommunityposts\" : scanMode = \"recentCommunityPosts\" elif scanMode == \"6\" : scanMode = \"makeConfig\" elif scanMode == \"7\" or scanMode == \"commentlist\" : scanMode = \"commentList\" elif scanMode == \"8\" : scanMode = \"recoverMode\" elif scanMode == \"9\" : scanMode = \"checkUpdates\" else : print ( f \" \\n Invalid choice: { scanMode } - Enter a number from 1 to 9\" ) validConfigSetting = False # ================================================================================= CHOSEN VIDEOS ====================================================================================================== # If chooses to scan single video - Validate Video ID, get title, and confirm with user if scanMode == \"chosenVideos\" : # While loop to get video ID and if invalid ask again confirm : bool = False validConfigSetting = True while confirm == False : numVideos = 1 allVideosMatchBool = True miscData . totalCommentCount = 0 # Checks if input list is empty and if contains only valid video IDs listNotEmpty : bool = False validVideoIDs = False # False just to get into the loop while listNotEmpty == False or validVideoIDs == False : if validConfigSetting == True and config and config [ 'videos_to_scan' ] != 'ask' : enteredVideosList = utils . string_to_list ( config [ 'videos_to_scan' ]) if len ( enteredVideosList ) == 0 : validConfigSetting = False listNotEmpty = False print ( f \" { F . LIGHTRED_EX } \\n Error: Video list is empty! { S . R } \" ) else : listNotEmpty = True else : print ( f \" \\n Enter a list of { F . YELLOW } Video Links { S . R } or { F . YELLOW } Video IDs { S . R } to scan, separated by commas.\" ) print ( \" > Note: All videos must be from the same channel.\" ) enteredVideosList = utils . string_to_list ( input ( \" \\n Enter here: \" )) if str ( enteredVideosList ) . lower () == \"['x']\" : return True # Return to main menu validConfigSetting = False if len ( enteredVideosList ) == 0 : listNotEmpty = False print ( f \" { F . LIGHTRED_EX } \\n Error: Video list is empty! { S . R } \" ) else : listNotEmpty = True # Validates all video IDs/Links, gets necessary info about them validVideoIDs : bool = True videosToScan = [] videoListResult = [] # True/False, video ID, videoTitle, commentCount, channelID, channelTitle for i in range ( len ( enteredVideosList )): videoListResult . append ([]) videosToScan . append ({}) videoListResult [ i ] = validation . validate_video_id ( enteredVideosList [ i ]) # Sends link or video ID for isolation and validation if videoListResult [ i ][ 0 ] == False : validVideoIDs = False confirm = False break for i in range ( len ( videoListResult )): # Change this if videoListResult [ i ][ 0 ] == True : videosToScan [ i ][ 'videoID' ] = str ( videoListResult [ i ][ 1 ]) videosToScan [ i ][ 'videoTitle' ] = str ( videoListResult [ i ][ 2 ]) videosToScan [ i ][ 'commentCount' ] = int ( videoListResult [ i ][ 3 ]) videosToScan [ i ][ 'channelOwnerID' ] = str ( videoListResult [ i ][ 4 ]) videosToScan [ i ][ 'channelOwnerName' ] = str ( videoListResult [ i ][ 5 ]) miscData . totalCommentCount += int ( videoListResult [ i ][ 3 ]) else : print ( f \" \\n Invalid Video: { enteredVideosList [ i ] } | Video ID = { videoListResult [ 1 ] } \" ) validConfigSetting = False break # Check each video against first to ensure all on same channel if allVideosMatchBool == True : misMatchVidIndex = 0 if videosToScan [ 0 ][ 'channelOwnerID' ] != videosToScan [ i ][ 'channelOwnerID' ]: misMatchVidIndex += 1 if allVideosMatchBool == True : print ( f \" \\n { F . LIGHTRED_EX } ERROR: Videos scanned together all must be from the same channel. { S . R } \" ) print ( \" The following videos do not match the channel owner of the first video in the list: \" ) if misMatchVidIndex == 11 and len ( enteredVideosList ) > 10 : remainingCount = str ( len ( enteredVideosList ) - 10 ) userChoice = choice ( f \"There are { remainingCount } more mis-matched videos, do you want to see the rest?\" ) if userChoice == False : break elif userChoice == None : return True # Return to main menu print ( f \" { misMatchVidIndex } . { str ( videosToScan [ i ][ 'videoTitle' ]) } \" ) validConfigSetting = False allVideosMatchBool = False # If videos not from same channel, skip and re-prompt if allVideosMatchBool == True : # Print video titles, if there are many, ask user to see all if more than 5 i = 0 print ( f \" \\n { F . BLUE } Chosen Videos: { S . R } \" ) for video in videosToScan : i += 1 if i == 6 and len ( enteredVideosList ) > 5 : remainingCount = str ( len ( enteredVideosList ) - 5 ) userChoice = choice ( f \"You have entered many videos, do you need to see the rest (x { remainingCount } )?\" ) if userChoice == False : break elif userChoice == None : return True # Return to main menu print ( f \" { i } . { video [ 'videoTitle' ] } \" ) print ( \"\" ) if CURRENTUSER . id != videosToScan [ 0 ][ 'channelOwnerID' ]: userNotChannelOwner = True miscData . channelOwnerID = videosToScan [ 0 ][ 'channelOwnerID' ] miscData . channelOwnerName = videosToScan [ 0 ][ 'channelOwnerName' ] # Ask if correct videos, or skip if config if config [ 'skip_confirm_video' ] == True : confirm = True else : if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . LIGHTRED_EX } NOTE: This is not your video. Enabling ' { F . YELLOW } Not Your Channel Mode { F . LIGHTRED_EX } '. You can report spam comments, but not delete them. { S . R } \" ) elif userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . LIGHTRED_EX } NOTE: { F . YELLOW } Moderator Mode is enabled { F . LIGHTRED_EX } . You can hold comments for review when using certain modes { S . R } \" ) print ( \"Total number of comments to scan: \" + str ( miscData . totalCommentCount )) if miscData . totalCommentCount >= 100000 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of comments. The default API quota limit ends up\" ) print ( f \" around { F . YELLOW } 10,000 comment deletions per day { S . R } . If you find more spam than that you will go over the limit.\" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if userNotChannelOwner == True or moderator_mode == True : print ( f \" { F . LIGHTCYAN_EX } > Note: { S . R } You may want to disable 'check_deletion_success' in the config, as this doubles the API cost! (So a 5K limit)\" ) confirm = choice ( \"Is this video list correct?\" , bypass = validConfigSetting ) if confirm == None : return True # Return to main menu # ============================================================================ RECENT VIDEOS ========================================================================================================== elif scanMode == \"recentVideos\" : confirm = False validEntry = False validChannel = False while validChannel == False : # Get and verify config setting for channel ID if config [ 'channel_to_scan' ] != 'ask' : if config [ 'channel_to_scan' ] == 'mine' : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True break else : validChannel , channelID , channelTitle = validation . validate_channel_id ( config [ 'channel_to_scan' ]) if validChannel == True : break else : print ( \"Invalid Channel ID or Link in config file!\" ) print ( f \" \\n Enter a { F . YELLOW } channel ID or Link { S . R } to scan { F . LIGHTCYAN_EX } recent videos { S . R } from\" ) print ( f \" > If scanning { F . YELLOW } your own channel { S . R } , just hit { F . LIGHTGREEN_EX } Enter { S . R } \" ) inputtedChannel = input ( \" \\n Enter Here: \" ) if inputtedChannel == \"\" : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True elif str ( inputtedChannel ) . lower () == \"x\" : return True # Return to main menu else : validChannel , channelID , channelTitle = validation . validate_channel_id ( inputtedChannel ) if CURRENTUSER . id != channelID : userNotChannelOwner = True print ( f \" \\n Chosen Channel: { F . LIGHTCYAN_EX }{ channelTitle }{ S . R } \" ) # Get number of recent videos to scan, either from config or user input, and validate while validEntry == False or confirm == False : videosToScan = [] validConfigSetting = True if config [ 'recent_videos_amount' ] != 'ask' and validConfigSetting == True : numVideos = config [ 'recent_videos_amount' ] try : numVideos = int ( numVideos ) except : validConfigSetting = False print ( \"Invalid number entered in config file for recent_videos_amount\" ) numVideos = None else : print ( f \" \\n Enter the { F . YELLOW } number most recent videos { S . R } to scan back-to-back:\" ) numVideos = input ( \" \\n Number of Recent Videos: \" ) print ( \"\" ) if str ( numVideos ) . lower () == \"x\" : return True # Return to main menu try : numVideos = int ( numVideos ) if numVideos > 0 and numVideos <= 500 : validEntry = True validConfigSetting = True else : print ( \"Error: Entry must be from 1 to 500 (the YouTube API Limit)\" ) validEntry = False validConfigSetting = False except ValueError : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Entry must be a whole number greater than zero.\" ) if validEntry == True and numVideos >= 100 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of videos. With the default API quota limit,\" ) print ( f \" every 100 videos will use up 20% of the quota { F . YELLOW } just from listing the videos alone, before any comment scanning. { S . R } \" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if validEntry == True : # Fetch recent videos and print titles to user for confirmation videosToScan = operations . get_recent_videos ( channelID , numVideos ) if str ( videosToScan ) == \"MainMenu\" : return True # Return to main menu if len ( videosToScan ) == 0 : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } No scannable videos found in selected range! They all may have no comments and/or are live streams.\" ) if config [ 'auto_close' ] == True : print ( \"Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( \" \\n Press Enter to return to main menu...\" ) return True # Get total comment count miscData . totalCommentCount = 0 for video in videosToScan : miscData . totalCommentCount += int ( video [ 'commentCount' ]) if len ( videosToScan ) < numVideos : print ( f \" \\n { F . YELLOW } WARNING: { S . R } Only { len ( videosToScan ) } videos found. Videos may be skipped if there are no comments.\" ) print ( \" \\n Recent Videos To Be Scanned:\" ) for i in range ( len ( videosToScan )): if config [ 'skip_confirm_video' ] == False : if i == 10 and len ( videosToScan ) > 11 : remainingCount = str ( len ( videosToScan ) - 10 ) userChoice = choice ( f \"There are { remainingCount } more recent videos, do you want to see the rest?\" ) if userChoice == False : break elif userChoice == None : return True # Return to main menu print ( f \" { i + 1 } . { videosToScan [ i ][ 'videoTitle' ] } \" ) if config [ 'skip_confirm_video' ] == True and validConfigSetting == True : confirm = True else : if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . LIGHTRED_EX } NOTE: These aren't your videos. Enabling ' { F . YELLOW } Not Your Channel Mode { F . LIGHTRED_EX } '. You can report spam comments, but not delete them. { S . R } \" ) elif userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . LIGHTRED_EX } NOTE: { F . YELLOW } Moderator Mode is enabled { F . LIGHTRED_EX } . You can hold comments for review when using certain modes { S . R } \" ) print ( \" \\n Total number of comments to scan: \" + str ( miscData . totalCommentCount )) if miscData . totalCommentCount >= 100000 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of comments. The default API quota limit ends up\" ) print ( f \" around { F . YELLOW } 10,000 comment deletions per day { S . R } . If you find more spam than that you will go over the limit.\" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if userNotChannelOwner == True or moderator_mode == True : print ( f \" { F . LIGHTCYAN_EX } > Note: { S . R } You may want to disable 'check_deletion_success' in the config, as this doubles the API cost! (So a 5K limit)\" ) confirm = choice ( \"Is everything correct?\" , bypass = config [ 'skip_confirm_video' ]) if confirm == None : return True # Return to main menu miscData . channelOwnerID = channelID miscData . channelOwnerName = channelTitle # ============================================================================= ENTIRE CHANNEL ============================================================================================================ # If chooses to scan entire channel - Validate Channel ID elif scanMode == \"entireChannel\" : numVideos = 1 # Using this variable to indicate only one loop of scanning done later # While loop to get max scan number, not an integer, asks again validInteger = False if config : validConfigSetting = True while validInteger == False : try : if validConfigSetting == True and config and config [ 'max_comments' ] != 'ask' : maxScanNumber = int ( config [ 'max_comments' ]) else : maxScanNumber = input ( f \"Enter the maximum { F . YELLOW } number of comments { S . R } to scan: \" ) if str ( maxScanNumber ) . lower () == \"x\" : return True # Return to main menu maxScanNumber = int ( maxScanNumber ) if maxScanNumber >= 100000 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of comments. The default API quota limit ends up\" ) print ( f \" around { F . YELLOW } 10,000 comment deletions per day { S . R } . If you find more spam than that you will go over the limit.\" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if userNotChannelOwner == True or moderator_mode == True : print ( f \" { F . LIGHTCYAN_EX } > Note: { S . R } You may want to disable 'check_deletion_success' in the config, as this doubles the API cost! (So a 5K limit)\" ) userChoice = choice ( \"Do you still want to continue?\" ) if userChoice == False : validInteger == False elif userChoice == None : return True # Return to main menu if maxScanNumber > 0 : validInteger = True # If it gets here, it's an integer, otherwise goes to exception else : print ( \" \\n Invalid Input! Number must be greater than zero.\" ) validConfigSetting = False except : print ( \" \\n Invalid Input! - Must be a whole number.\" ) validConfigSetting = False miscData . channelOwnerID = CURRENTUSER . id miscData . channelOwnerName = CURRENTUSER . name # ================================================================================ COMMUNITY POST ===================================================================================================== elif scanMode == 'communityPost' : print ( f \" \\n NOTES: This mode is { F . YELLOW } experimental { S . R } , and not as polished as other features. Expect some janky-ness.\" ) print ( \" > It is also much slower to retrieve comments, because it does not use the API\" ) confirm = False while confirm == False : communityPostInput = input ( \" \\n Enter the ID or link of the community post: \" ) if str ( communityPostInput ) . lower () == \"x\" : return True # Return to main menu # Validate post ID or link, get additional info about owner, and useable link isValid , communityPostID , postURL , postOwnerID , postOwnerUsername = validation . validate_post_id ( communityPostInput ) if isValid == True : print ( \" \\n Community Post By: \" + postOwnerUsername ) if postOwnerID != CURRENTUSER . id : userNotChannelOwner = True print ( f \" \\n { F . YELLOW } Warning: { S . R } You are scanning someone elses post. ' { F . LIGHTRED_EX } Not Your Channel Mode { S . R } ' Enabled.\" ) confirm = choice ( \"Continue?\" ) if confirm == None : return True # Return to main menu else : print ( \"Problem interpreting the post information, please check the link or ID.\" ) miscData . channelOwnerID = postOwnerID miscData . channelOwnerName = postOwnerUsername # Checking config for max comments in config if config [ 'max_comments' ] != 'ask' : validInteger = False try : maxScanNumber = int ( config [ 'max_comments' ]) if maxScanNumber > 0 : validInteger = True else : pass except : pass if validInteger == False : print ( \" \\n Invalid max_comments setting in config! Number must a whole number be greater than zero.\" ) while validInteger == False : maxScanInput = input ( f \" \\n Enter the maximum { F . YELLOW } number of comments { S . R } to scan: \" ) if str ( maxScanInput ) . lower () == \"x\" : return True # Return to main menu try : maxScanNumber = int ( maxScanInput ) if maxScanNumber > 0 : validInteger = True # If it gets here, it's an integer, otherwise goes to exception else : print ( \" \\n Invalid Input! Number must a whole number be greater than zero.\" ) except : print ( \" \\n Invalid Input! - Must be a whole number greater than zero.\" ) # ==================================================================== RECENT COMMUNITY POSTS ============================================================================================================= # Recent Community Posts elif scanMode == 'recentCommunityPosts' : print ( f \" \\n NOTES: This mode is { F . YELLOW } experimental { S . R } , and not as polished as other features. Expect some janky-ness.\" ) print ( \" > It is also much slower to retrieve comments, because it does not use the API\" ) confirm = False validEntry = False validChannel = False while validChannel == False : # Get and verify config setting for channel ID if config [ 'channel_to_scan' ] != 'ask' : if config [ 'channel_to_scan' ] == 'mine' : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True break else : validChannel , channelID , channelTitle = validation . validate_channel_id ( config [ 'channel_to_scan' ]) if validChannel == True : break else : print ( \"Invalid Channel ID or Link in config file!\" ) print ( f \" \\n Enter a { F . YELLOW } channel ID or Link { S . R } to scan { F . LIGHTCYAN_EX } recent community posts { S . R } from\" ) print ( f \" > If scanning { F . YELLOW } your own channel { S . R } , just hit { F . LIGHTGREEN_EX } Enter { S . R } \" ) inputtedChannel = input ( \" \\n Enter Here: \" ) if inputtedChannel == \"\" : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True elif str ( inputtedChannel ) . lower () == \"x\" : return True # Return to main menu else : validChannel , channelID , channelTitle = validation . validate_channel_id ( inputtedChannel ) if CURRENTUSER . id != channelID : userNotChannelOwner = True # Get and print community posts recentPostsListofDicts = community_downloader . fetch_recent_community_posts ( channelID ) print ( \" \\n ------------------------------------------------------------\" ) print ( f \"Retrieved { F . YELLOW }{ len ( recentPostsListofDicts ) } recent posts { S . R } from { F . LIGHTCYAN_EX }{ channelTitle }{ S . R } \" ) print ( f \" \\n Post Content Samples:\" ) for i in range ( len ( recentPostsListofDicts )): print ( f \" { i + 1 } .\" . ljust ( 9 , \" \" ) + f \" { list ( recentPostsListofDicts [ i ] . values ())[ 0 ][ 0 : 50 ] } \" ) if userNotChannelOwner == True : print ( f \" \\n > { F . LIGHTRED_EX } Warning: { S . R } You are scanning someone elses post. { F . LIGHTRED_EX } 'Not Your Channel Mode' { S . R } Enabled.\" ) print ( f \" \\n { F . YELLOW } How many { S . R } of the most recent posts do you want to scan?\" ) inputStr = \"\" while True : if config [ 'recent_videos_amount' ] != 'ask' and inputStr == \"\" : inputStr = config [ 'recent_videos_amount' ] else : inputStr = input ( \" \\n Number of Recent Posts: \" ) if str ( inputStr ) . lower () == \"x\" : return True try : numRecentPosts = int ( inputStr ) if numRecentPosts > len ( recentPostsListofDicts ): print ( \"Number entered is more than posts available. Will just scan all posts available.\" ) numRecentPosts = len ( recentPostsListofDicts ) break elif numRecentPosts <= 0 : print ( \"Please enter a whole number greater than zero.\" ) else : break except ValueError : print ( \"Invalid Input! - Must be a whole number.\" ) miscData . channelOwnerID = channelID miscData . channelOwnerName = channelTitle # =============================================================================== OTHER MENU OPTIONS ============================================================================================= # Create config file elif scanMode == \"makeConfig\" : result = files . create_config_file () if str ( result ) == \"MainMenu\" : return True # Check for latest version elif scanMode == \"checkUpdates\" : files . check_lists_update ( spamListDict ) files . check_for_update ( version , updateReleaseChannel ) input ( \" \\n Press Enter to return to main menu...\" ) return True # Recove deleted comments mode elif scanMode == \"recoverMode\" : result = modes . recover_deleted_comments ( config ) if str ( result ) == \"MainMenu\" : return True elif scanMode == \"commentList\" : result = modes . delete_comment_list ( config ) if str ( result ) == \"MainMenu\" : return True # ==================================================================================================================================================================================================== # ==================================================================================================================================================================================================== # User inputs filtering mode print ( \" \\n -------------------------------------------------------\" ) print ( f \"~~~~~~~~~~~ Choose how to identify spammers ~~~~~~~~~~~\" ) print ( \"-------------------------------------------------------\" ) print ( f \" 1. { F . BLACK }{ B . LIGHTGREEN_EX } (RECOMMENDED): { S . R } { F . YELLOW } Auto-Smart Mode { S . R } : Automatically detects multiple spammer techniques\" ) print ( f \" 2. { F . YELLOW } Sensitive-Smart Mode { S . R } : Much more likely to catch all spammers, but with significantly more false positives\" ) print ( f \" 3. Enter Spammer's { F . LIGHTRED_EX } channel ID(s) or link(s) { S . R } \" ) print ( f \" 4. Scan { F . LIGHTBLUE_EX } usernames { S . R } for criteria you choose\" ) print ( f \" 5. Scan { F . CYAN } comment text { S . R } for criteria you choose\" ) print ( f \" 6. Scan both { F . LIGHTBLUE_EX } usernames { S . R } and { F . CYAN } comment text { S . R } for criteria you choose\" ) print ( f \" 7. ASCII Mode: Scan usernames for { F . LIGHTMAGENTA_EX } ANY non-ASCII special characters { S . R } (May cause collateral damage!)\" ) if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . LIGHTRED_EX } Note: With 'Not Your Channel Mode' enabled, you can only report matched comments while using 'Auto-Smart Mode' \\n or 'Sensitive-Smart Mode'. { S . R } \" ) # Based on filterModesAllowedforNonOwners elif userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . LIGHTRED_EX } Note: With 'Moderator Mode', you can hold for review using: 'Auto-Smart', 'Sensitive-Smart', and Channel ID modes. { S . R } \" ) # Make sure input is valid, if not ask again validFilterMode = False validFilterSubMode = False filterSubMode = None validConfigSetting = True validConfigSetting = True while validFilterMode == False : if validConfigSetting == True and config and config [ 'filter_mode' ] != 'ask' : filterChoice = config [ 'filter_mode' ] else : filterChoice = input ( \" \\n Choice (1-7): \" ) if str ( filterChoice ) . lower () == \"x\" : return True # Return to main menu validChoices = [ '1' , '2' , '3' , '4' , '5' , '6' , '7' , 'id' , 'username' , 'text' , 'nameandtext' , 'autoascii' , 'autosmart' , 'sensitivesmart' ] if filterChoice in validChoices : validFilterMode = True # Set string variable names for filtering modes if filterChoice == \"1\" or filterChoice == \"autosmart\" : filterMode = \"AutoSmart\" elif filterChoice == \"2\" or filterChoice == \"sensitivesmart\" : filterMode = \"SensitiveSmart\" elif filterChoice == \"3\" or filterChoice == \"id\" : filterMode = \"ID\" elif filterChoice == \"4\" or filterChoice == \"username\" : filterMode = \"Username\" elif filterChoice == \"5\" or filterChoice == \"text\" : filterMode = \"Text\" elif filterChoice == \"6\" or filterChoice == \"nameandtext\" : filterMode = \"NameAndText\" elif filterChoice == \"7\" or filterChoice == \"autoascii\" : filterMode = \"AutoASCII\" else : print ( f \" \\n Invalid Filter Mode: { filterChoice } - Enter a whole number from 1-7\" ) validConfigSetting = False ## Get filter sub-mode to decide if searching characters or string validConfigSetting = None if config [ 'filter_submode' ] != 'ask' : filterSubMode = config [ 'filter_submode' ] validConfigSetting = True else : validConfigSetting = False if filterMode == \"Username\" or filterMode == \"Text\" or filterMode == \"NameAndText\" : print ( \" \\n --------------------------------------------------------------\" ) if filterMode == \"Username\" : print ( \"~~~ What do you want to scan usernames for specifically? ~~~\" ) elif filterMode == \"Text\" : print ( \"~~~ What do you want to scan comment text for specifically? ~~~\" ) elif filterMode == \"NameAndText\" : print ( \"~~~ What do you want to scan names and comments for specifically? ~~~\" ) print ( f \" 1. A { F . CYAN } certain special character { S . R } , or set of multiple characters\" ) print ( f \" 2. An { F . LIGHTMAGENTA_EX } entire string { S . R } , or multiple strings\" ) print ( f \" 3. Advanced: A custom { F . YELLOW } Regex pattern { S . R } you'll enter\" ) while validFilterSubMode == False : if validConfigSetting == True : pass else : filterSubMode = input ( \" \\n Choice (1, 2, or 3): \" ) if str ( filterSubMode ) . lower () == \"x\" : return True # Return to main menu validFilterSubModes = [ \"1\" , \"2\" , \"3\" , \"characters\" , \"strings\" , \"regex\" ] if filterSubMode in validFilterSubModes : validFilterSubMode = True validConfigSetting = True if filterSubMode == \"1\" or filterSubMode == \"characters\" : filterSubMode = \"chars\" elif filterSubMode == \"2\" or filterSubMode == \"strings\" : filterSubMode = \"string\" elif filterSubMode == \"3\" or filterSubMode == \"regex\" : filterSubMode = \"regex\" else : print ( f \" \\n Invalid choice: { filterSubMode } - Enter 1, 2 or 3\" ) validConfigSetting = False ### Prepare Filtering Modes ### # Default values for filter criteria inputtedSpammerChannelID = None inputtedUsernameFilter = None inputtedCommentTextFilter = None regexPattern = \"\" if filterMode == \"ID\" : filterSettings = modes . prepare_filter_mode_ID ( scanMode , config ) inputtedSpammerChannelID = filterSettings [ 0 ] elif filterMode == \"AutoASCII\" : filterSettings = modes . prepare_filter_mode_non_ascii ( scanMode , config ) regexPattern = filterSettings [ 0 ] elif filterMode == \"AutoSmart\" : filterSettings = modes . prepare_filter_mode_smart ( scanMode , config , miscData ) inputtedUsernameFilter = filterSettings [ 0 ] inputtedCommentTextFilter = filterSettings [ 0 ] elif filterMode == \"SensitiveSmart\" : filterSettings = modes . prepare_filter_mode_smart ( scanMode , config , miscData , sensitive = True ) inputtedUsernameFilter = filterSettings [ 0 ] inputtedCommentTextFilter = filterSettings [ 0 ] elif filterSubMode == \"chars\" : filterSettings = modes . prepare_filter_mode_chars ( scanMode , filterMode , config ) elif filterSubMode == \"string\" : filterSettings = modes . prepare_filter_mode_strings ( scanMode , filterMode , config ) elif filterSubMode == \"regex\" : filterSettings = modes . prepare_filter_mode_regex ( scanMode , filterMode , config ) regexPattern = filterSettings [ 1 ] if filterSettings [ 0 ] == \"MainMenu\" : return True if filterSubMode != \"regex\" : if filterMode == \"Username\" : inputtedUsernameFilter = filterSettings [ 0 ] elif filterMode == \"Text\" : inputtedCommentTextFilter = filterSettings [ 0 ] elif filterMode == \"NameAndText\" : inputtedUsernameFilter = filterSettings [ 0 ] inputtedCommentTextFilter = filterSettings [ 0 ] ##################### START SCANNING ##################### filtersDict = { 'filterSettings' : filterSettings , 'filterMode' : filterMode , 'filterSubMode' : filterSubMode , 'CustomChannelIdFilter' : inputtedSpammerChannelID , 'CustomUsernameFilter' : inputtedUsernameFilter , 'CustomCommentTextFilter' : inputtedCommentTextFilter , 'CustomRegexPattern' : regexPattern } if scanMode == \"communityPost\" or scanMode == \"recentCommunityPosts\" : def scan_community_post ( current , config , communityPostID , limit , postScanProgressDict = None , postText = None ): authorKeyAllCommentsDict = {} allCommunityCommentsDict = get_community_comments ( communityPostID = communityPostID , limit = limit , postScanProgressDict = postScanProgressDict , postText = postText ) retrievedCount = len ( allCommunityCommentsDict ) print ( f \" \\n Retrieved { retrievedCount } comments from post. \\n \" ) scannedCount = 0 threadDict = {} # Analyze and store comments for key , value in allCommunityCommentsDict . items (): currentCommentDict = { 'authorChannelID' : value [ 'authorChannelID' ], 'parentAuthorChannelID' : None , 'authorChannelName' : value [ 'authorName' ], 'commentText' : value [ 'commentText' ], 'commentID' : key , } try : authorKeyAllCommentsDict [ value [ 'authorChannelID' ]] . append ( currentCommentDict ) except KeyError : authorKeyAllCommentsDict [ value [ 'authorChannelID' ]] = [ currentCommentDict ] except TypeError : pass operations . check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID = communityPostID ) # Scam for spam threads if config [ 'detect_spam_threads' ] == True : threadDict = operations . make_community_thread_dict ( key , allCommunityCommentsDict ) if threadDict : parentCommentDict = dict ( currentCommentDict ) parentCommentDict [ 'videoID' ] = communityPostID current = operations . check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ) scannedCount += 1 # Print Progress percent = (( scannedCount / retrievedCount ) * 100 ) progressStats = f \"[ { str ( scannedCount ) } / { str ( retrievedCount ) } ]\" . ljust ( 15 , \" \" ) + f \" ( { percent : .2f } %)\" print ( f ' { progressStats } - Analyzing Comments For Spam ' , end = ' \\r ' ) print ( \" \" ) dupeCheckModes = utils . string_to_list ( config [ 'duplicate_check_modes' ]) if filtersDict [ 'filterMode' ] . lower () in dupeCheckModes : operations . check_duplicates ( current , config , miscData , authorKeyAllCommentsDict , communityPostID ) print ( \" \" ) if scanMode == \"communityPost\" : scan_community_post ( current , config , communityPostID , maxScanNumber ) elif scanMode == \"recentCommunityPosts\" : postScanProgressDict = { 'scanned' : 0 , 'total' : numRecentPosts } for post in recentPostsListofDicts : postScanProgressDict [ 'scanned' ] += 1 id = list ( post . keys ())[ 0 ] # Each dict only has one key/value pair postText = list ( post . values ())[ 0 ] current . vidTitleDict [ id ] = f \"[Community Post]: { postText } \" scan_community_post ( current , config , id , maxScanNumber , postScanProgressDict = postScanProgressDict , postText = postText ) if postScanProgressDict [ 'scanned' ] == numRecentPosts : break else : # Goes to get comments for first page print ( \" \\n ------------------------------------------------------------------------------\" ) print ( \"(Note: If the program appears to freeze, try right clicking within the window) \\n \" ) print ( \" --- Scanning --- \\n \" ) # ---------------------------------------------------------------------------------------------------------------------- def scan_video ( miscData , config , filtersDict , scanVideoID , videosToScan = None , currentVideoDict = {}, videoTitle = None , showTitle = False , i = 1 ): nextPageToken , currentVideoDict = operations . get_comments ( current , filtersDict , miscData , config , currentVideoDict , scanVideoID , videosToScan = videosToScan ) if nextPageToken == \"Error\" : return \"Error\" if showTitle == True and len ( videosToScan ) > 0 : # Prints video title, progress count, adds enough spaces to cover up previous stat print line offset = 95 - len ( videoTitle ) if offset > 0 : spacesStr = \" \" * offset else : spacesStr = \"\" print ( f \"Scanning { i } / { len ( videosToScan ) } : \" + videoTitle + spacesStr + \" \\n \" ) operations . print_count_stats ( current , miscData , videosToScan , final = False ) # Prints comment scan stats, updates on same line # After getting first page, if there are more pages, goes to get comments for next page while nextPageToken != \"End\" and current . scannedCommentsCount < maxScanNumber : nextPageToken , currentVideoDict = operations . get_comments ( current , filtersDict , miscData , config , currentVideoDict , scanVideoID , nextPageToken , videosToScan = videosToScan ) if nextPageToken == \"Error\" : return \"Error\" return \"OK\" # ---------------------------------------------------------------------------------------------------------------------- if scanMode == \"entireChannel\" : status = scan_video ( miscData , config , filtersDict , scanVideoID ) if status == \"Error\" : pass elif scanMode == \"recentVideos\" or scanMode == \"chosenVideos\" : i = 1 for video in videosToScan : currentVideoDict = {} scanVideoID = str ( video [ 'videoID' ]) videoTitle = str ( video [ 'videoTitle' ]) status = scan_video ( miscData , config , filtersDict , scanVideoID , videosToScan = videosToScan , currentVideoDict = currentVideoDict , videoTitle = videoTitle , showTitle = True , i = i ) if status == \"Error\" : break i += 1 if current . errorOccurred == False : operations . print_count_stats ( current , miscData , videosToScan , final = True ) # Prints comment scan stats, finalizes else : utils . print_break_finished ( scanMode ) ########################################################## bypass = False if config [ 'enable_logging' ] != 'ask' : logSetting = config [ 'enable_logging' ] if logSetting == True : loggingEnabled = True bypass = True elif logSetting == False : loggingEnabled = False bypass = True elif logSetting == \"ask\" : bypass = False else : bypass = False print ( \"Error Code C-2: Invalid value for 'enable_logging' in config file: \" + logSetting ) # Counts number of found spam comments and prints list if not current . matchedCommentsDict and not current . duplicateCommentsDict and not current . spamThreadsDict : # If no spam comments found, exits print ( f \" { B . RED }{ F . BLACK } No matched comments or users found! { F . R }{ B . R }{ S . R } \\n \" ) print ( f \"If you see missed spam or false positives, you can submit a filter suggestion here: { F . YELLOW } TJoe.io/filter-feedback { S . R } \" ) if config [ 'auto_close' ] == False : input ( \" \\n Press Enter to return to main menu...\" ) return True elif config [ 'auto_close' ] == True : print ( \" \\n Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () print ( f \"Number of { S . BRIGHT }{ F . LIGHTRED_EX } Matched { S . R } Comments Found: { B . RED }{ F . WHITE } { str ( len ( current . matchedCommentsDict )) } { F . R }{ B . R }{ S . R } \" ) if current . spamThreadsDict : print ( f \" \\n Number of { S . BRIGHT }{ F . RED } Spam Bot Threads { S . R } Found: { S . BRIGHT }{ B . RED }{ F . WHITE } { str ( len ( current . spamThreadsDict )) } { F . R }{ B . R }{ S . R } \" ) if current . duplicateCommentsDict : print ( f \" \\n Number of { S . BRIGHT }{ F . LIGHTBLUE_EX } Non-Matched But Duplicate { S . R } Comments Found: { S . BRIGHT }{ F . WHITE }{ B . BLUE } { str ( len ( current . duplicateCommentsDict )) } { F . R }{ B . R }{ S . R } \" ) # If spam comments were found, continue if bypass == False : # Asks user if they want to save list of spam comments to a file print ( f \" \\n Comments ready to display. Also { F . LIGHTGREEN_EX } save a log file? { S . R } { B . GREEN }{ F . BLACK } Highly Recommended! { F . R }{ B . R }{ S . R } \" ) print ( f \" (It even allows you to { F . LIGHTGREEN_EX } restore { S . R } deleted comments later)\" ) loggingEnabled = choice ( f \"Save Log File (Recommended)?\" ) if loggingEnabled == None : return True # Return to main menu print ( \"\" ) # Prepare log file and json log file settings - Location and names jsonSettingsDict = {} if loggingEnabled == True : current , logMode , jsonSettingsDict = logging . prepare_logFile_settings ( current , config , miscData , jsonSettingsDict , filtersDict , bypass ) print ( \" \\n ----------------------------------------------------------------------------------------------------------------- \\n \" ) else : print ( \"Continuing without logging... \\n \" ) logMode = None jsonSettingsDict [ 'jsonLogging' ] = False # Prints list of spam comments if scanMode == \"communityPost\" : scanVideoID = communityPostID # Print comments and write to log files logFileContents , logMode = logging . print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode ) if loggingEnabled : logInfo = { 'logMode' : logMode , 'logFileContents' : logFileContents , 'jsonSettingsDict' : jsonSettingsDict , 'filtersDict' : filtersDict , } else : logInfo = None print ( f \" \\n { F . WHITE }{ B . RED } NOTE: { S . R } Check that all comments listed above are indeed spam.\" ) print ( f \" > If you see missed spam or false positives, you can submit a filter suggestion here: { F . YELLOW } TJoe.io/filter-feedback { S . R } \" ) print () ### ---------------- Decide whether to skip deletion ---------------- returnToMenu = False # Defaults deletionEnabled = False deletionMode = None # Should be changed later, but if missed it will default to heldForReview confirmDelete = None # If None, will later cause user to be asked to delete if moderator_mode == False : filterModesAllowedforNonOwners = [ \"AutoSmart\" , \"SensitiveSmart\" ] elif moderator_mode == True : filterModesAllowedforNonOwners = [ \"AutoSmart\" , \"SensitiveSmart\" , 'ID' ] # If user isn't channel owner and not using allowed filter mode, skip deletion if userNotChannelOwner == True and filterMode not in filterModesAllowedforNonOwners : confirmDelete = False deletionEnabled = False print ( f \" { F . LIGHTRED_EX } Error: { S . R } To prevent abuse, even in moderator mode, you can only use filter modes: Auto Smart, Sensitive Smart, and ID\" ) response = input ( \"Press Enter to continue, or type 'x' to return to Main Menu...\" ) if response . lower () == 'x' : return True # Test skip_deletion preference - If passes both, will either delete or ask user to delete if config [ 'skip_deletion' ] == True : print ( \" \\n Config setting skip_deletion enabled.\" ) returnToMenu = True elif config [ 'skip_deletion' ] != False : print ( \"Error Code C-3: Invalid value for 'skip_deletion' in config file. Must be 'True' or 'False'. Current Value: \" + str ( config [ 'skip_deletion' ])) print ( f \"Defaulting to ' { F . YELLOW } False { S . R } '\" ) input ( \" \\n Press Enter to continue...\" ) ### ---------------------------------------------------------------- ### ------------- Decide whether to ask before deleting ------------- # Using config to determine deletion type, block invalid settings elif config [ 'delete_without_reviewing' ] == False : deletionEnabled = \"Allowed\" if config [ 'removal_type' ] == \"reportspam\" or userNotChannelOwner == True : deletionMode = \"reportSpam\" elif config [ 'removal_type' ] == \"heldforreview\" : deletionMode = \"heldForReview\" elif config [ 'removal_type' ] == \"rejected\" : deletionMode = \"rejected\" else : print ( \"Error Code C-4: Invalid value for 'removal_type' in config file. Must be 'heldforreview', 'rejected', or 'reportSpam': \" + config [ 'removal_type' ]) input ( \" \\n Press Enter to exit...\" ) sys . exit () # User wants to automatically delete with no user intervention elif config [ 'delete_without_reviewing' ] == True : if userNotChannelOwner == True : confirmDelete = \"report\" deletionMode = \"reportSpam\" deletionEnabled = True elif config [ 'removal_type' ] == \"reportspam\" or config [ 'removal_type' ] == \"heldforreview\" : if filterMode == \"AutoSmart\" or filterMode == \"ID\" : deletionEnabled = True if config [ 'removal_type' ] == \"reportspam\" : deletionMode = \"reportSpam\" confirmDelete = \"report\" elif config [ 'removal_type' ] == \"heldforreview\" : deletionMode = \"heldForReview\" confirmDelete = \"hold\" else : # If non-permitted filter mode with delete_without_reviewing, will allow deletion, but now warns and requires usual confirmation prompt print ( \"Error Code C-5: 'delete_without_reviewing' is set to 'True' in config file. So only filter mode 'AutoSmart' allowed.. \\n \" ) print ( \"Next time use one of those filter modes, or set 'delete_without_reviewing' to 'False'.\" ) print ( \" > For this run, you will be asked to confirm removal of spam comments.\" ) input ( \" \\n Press Enter to continue...\" ) confirmDelete = None deletionEnabled = \"Allowed\" else : print ( \"Error Code C-6: 'delete_without_reviewing' is set to 'True' in config file. So 'removal_type' must be either 'heldForReview' or 'reportSpam'. \\n \" ) print ( \"Next time, either set one of those removal types, or set 'delete_without_reviewing' to 'False'.\" ) print ( \" > For this run, you will be asked to confirm removal of spam comments.\" ) input ( \" \\n Press Enter to continue...\" ) confirmDelete = None deletionEnabled = \"Allowed\" else : # Catch Invalid value print ( \"Error C-7: Invalid value for 'delete_without_reviewing' in config file. Must be 'True' or 'False': \" + config [ 'delete_without_reviewing' ]) input ( \" \\n Press Enter to exit...\" ) sys . exit () # Check if deletion is enabled, otherwise block and quit if returnToMenu == False and deletionEnabled != \"Allowed\" and deletionEnabled != True : print ( \" \\n The deletion functionality was not enabled. Cannot delete or report comments.\" ) print ( \"Possible Cause: You're scanning someone elses video with a non-supported filter mode. \\n \" ) print ( \"If you think this is a bug, you may report it on this project's GitHub page: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) if config [ 'auto_close' ] == True : print ( \" \\n Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( \" \\n Press Enter to return to main menu...\" ) return True ### ---------------- Set Up How To Handle Comments ---------------- rtfExclude = None plaintextExclude = None authorsToExcludeSet = set () commentIDExcludeSet = set () exclude = False excludedCommentsDict = {} excludeDisplayString = \"\" # If not skipped by config, ask user what to do if confirmDelete == None and returnToMenu == False : # Menu for deletion mode validResponses = [ 'delete' , 'report' , 'hold' , 'none' ] while confirmDelete == None or confirmDelete . lower () not in validResponses : # Title if current . errorOccurred == True : print ( f \" \\n --- { F . WHITE }{ B . RED } NOTE: { S . R } Options limited due to error during scanning ---\" ) if exclude == False : print ( f \" { F . YELLOW } How do you want to { F . BLACK }{ B . YELLOW } ALL { S . R }{ F . YELLOW } the listed comments above? { S . R } (Including Non-Matched Duplicates)\" ) elif exclude == True : print ( f \" { F . YELLOW } How do you want to handle the rest of the comments (not ones you { F . LIGHTGREEN_EX } excluded { F . YELLOW } )? { S . R } \" ) if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . GREEN } ~~ Not Your Channel Mode: Only Reporting is Possible ~~ { S . R } \" ) if userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . GREEN } ~~ Moderator Mode: Reporting and Holding for Review is possible ~~ { S . R } \" ) # Exclude if exclude == False : print ( f \" > To { F . LIGHTGREEN_EX } exclude certain authors { S . R } : Type \\' { F . LIGHTGREEN_EX } exclude { S . R } \\' followed by a list of the numbers (or ranges of #'s) { F . LIGHTMAGENTA_EX } from the sample list { S . R } \" ) print ( \" > Example: exclude 1, 3-5, 7, 12-15\" ) print ( f \" > To { F . LIGHTGREEN_EX } only process certain authors { S . R } : Type \\' { F . LIGHTGREEN_EX } only { S . R } \\' followed by a list of the numbers (or ranges of #s) { F . LIGHTMAGENTA_EX } from the sample list { S . R } \" ) print ( \" > Example: only 1, 3-5, 7, 12-15 -- (Will effectively exclude the 'inverse' of the 'only' selected authors)\" ) # Delete & Hold if exclude == False : if userNotChannelOwner == False and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } delete ALL of the above comments { S . R } : Type ' { F . LIGHTRED_EX } DELETE { S . R } ', then hit Enter.\" ) if ( userNotChannelOwner == False or moderator_mode == True ) and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } move ALL comments above to 'Held For Review' in YT Studio { S . R } : Type ' { F . LIGHTRED_EX } HOLD { S . R } ', then hit Enter.\" ) elif exclude == True : if userNotChannelOwner == False and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } delete the rest of the comments { S . R } : Type ' { F . LIGHTRED_EX } DELETE { S . R } ', then hit Enter.\" ) if ( userNotChannelOwner == False or moderator_mode == True ) and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } move rest of comments above to 'Held For Review' in YT Studio { S . R } : Type ' { F . LIGHTRED_EX } HOLD { S . R } ', then hit Enter.\" ) # Report & None if current . errorOccurred == False : print ( f \" > To { F . LIGHTCYAN_EX } report the comments for spam { S . R } , type ' { F . LIGHTCYAN_EX } REPORT { S . R } '.\" ) if loggingEnabled : print ( f \" > To do nothing and { F . YELLOW } only log { S . R } , type ' { F . YELLOW } NONE { S . R } '\" ) else : print ( f \" > To do { F . YELLOW } nothing { S . R } , type ' { F . YELLOW } NONE { S . R } '\" ) if config [ 'json_log' ] == True and config [ 'json_extra_data' ] == True and loggingEnabled : print ( f \" \\n { F . WHITE }{ B . BLUE } JSON NOTE: { S . R } You must proceed to write the JSON log file, even if you choose nothing\" ) # Take Entry confirmDelete = input ( \" \\n (Not Case Sensitive) Input: \" ) # Process Entry if confirmDelete . lower () == \"delete\" and userNotChannelOwner == False : deletionEnabled = True deletionMode = \"rejected\" elif confirmDelete . lower () == \"hold\" and ( userNotChannelOwner == False or moderator_mode == True ): deletionEnabled = True deletionMode = \"heldForReview\" elif confirmDelete . lower () == \"report\" : deletionEnabled = True deletionMode = \"reportSpam\" elif \"exclude\" in confirmDelete . lower () or \"only\" in confirmDelete . lower (): if \"exclude\" in confirmDelete . lower (): onlyBool = False elif \"only\" in confirmDelete . lower (): onlyBool = True if loggingEnabled : logInfo = { 'logMode' : logMode , 'logFileContents' : logFileContents , 'jsonSettingsDict' : jsonSettingsDict , 'filtersDict' : filtersDict } else : logInfo = None # This is very messy for now, will later consolidate the parameters current , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , rtfFormattedExcludes , plaintextFormattedExcludes = operations . exclude_authors ( current , config , miscData , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , excludeDisplayString , inputtedString = confirmDelete , logInfo = logInfo , only = onlyBool ) miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] = files . ingest_list_file ( whitelistPathWithName , keepCase = True ) exclude = True # Check that remaining comments list to remove is not empty if not current . matchedCommentsDict and not current . duplicateCommentsDict and not current . spamThreadsDict : print ( f \" \\n { F . YELLOW } All authors excluded, no comments left to remove! { S . R } \" ) input ( \" \\n Press Enter to log and/or return to main menu...\" ) returnToMenu = True break elif confirmDelete . lower () == \"none\" : returnToMenu = True else : print ( f \" \\n { F . LIGHTRED_EX } ERROR: { S . R } This entry was invalid or not allowed with current settings: { confirmDelete } \" ) input ( \" \\n Press Enter to try again...\" ) print ( \" \\n \" ) # Combine commentIDs from different match type dicts combinedCommentDict = dict ( current . matchedCommentsDict ) combinedCommentDict . update ( current . duplicateCommentsDict ) combinedCommentDict . update ( current . spamThreadsDict ) includeOtherAuthorComments = False banChoice = False if returnToMenu == False : # Set deletion mode friendly name if deletionMode == \"rejected\" : deletionModeFriendlyName = \"Removed\" elif deletionMode == \"heldForReview\" : deletionModeFriendlyName = \"Moved to 'Held for Review' Section\" elif deletionMode == \"reportSpam\" : deletionModeFriendlyName = \"Reported for spam\" # Set or choose ban mode, check if valid based on deletion mode if ( deletionMode == \"rejected\" or deletionMode == \"reportSpam\" or deletionMode == \"heldForReview\" ) and deletionEnabled == True and current . errorOccurred == False : proceedWithDeletion = True if config [ 'enable_ban' ] != \"ask\" : if config [ 'enable_ban' ] == False : pass elif config [ 'enable_ban' ] == True : print ( \"Error Code C-8: 'enable_ban' is set to 'True' in config file. Only possible config options are 'ask' or 'False' when using config. \\n \" ) input ( \"Press Enter to continue...\" ) else : print ( \"Error Code C-9: 'enable_ban' is set to an invalid value in config file. Only possible config options are 'ask' or 'False' when using config. \\n \" ) input ( \"Press Enter to continue...\" ) elif deletionMode == \"rejected\" : print ( \" \\n Also ban the spammer(s)?\" ) banChoice = choice ( f \" { F . YELLOW } Ban { S . R } the spammer(s) ?\" ) if banChoice == None : banChoice = False returnToMenu = True includeOtherAuthorComments = False if deletionMode == \"rejected\" or deletionMode == \"heldForReview\" : if config [ 'remove_all_author_comments' ] != 'ask' : includeOtherAuthorComments = config [ 'remove_all_author_comments' ] else : print ( f \" \\n Also remove { F . YELLOW } all other comments { S . R } from the selected authors, even if their other comments weren't matched?\" ) includeOtherAuthorComments = choice ( \"Choose:\" ) else : includeOtherAuthorComments = False else : proceedWithDeletion = False deletionModeFriendlyName = \"Nothing (Log Only)\" else : proceedWithDeletion = False deletionModeFriendlyName = \"Nothing (Log Only)\" # Print Final Logs if includeOtherAuthorComments == True : current = operations . get_all_author_comments ( current , config , miscData , current . allScannedCommentsDict ) combinedCommentDict . update ( current . otherCommentsByMatchedAuthorsDict ) if loggingEnabled == True : # Rewrites the contents of entire file, but now without the excluded comments in the list of comment IDs # Also if other non-matched comments by matched authors were added if exclude == True or current . otherCommentsByMatchedAuthorsDict : # This is just to redo the logFileContents to write later, not to actually write to log file logFileContents , logMode = logging . print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode , doWritePrint = False ) # Update logFile Contents after updating them logInfo [ 'logFileContents' ] = logFileContents logging . rewrite_log_file ( current , logInfo , combinedCommentDict ) print ( \"Updating log file, please wait...\" , end = \" \\r \" ) # Appends the excluded comment info to the log file that was just re-written if exclude == True : if logInfo [ 'logMode' ] == \"rtf\" : logging . write_rtf ( current . logFileName , str ( rtfFormattedExcludes )) elif logInfo [ 'logMode' ] == \"plaintext\" : logging . write_plaintext_log ( current . logFileName , str ( plaintextFormattedExcludes )) print ( \" \" ) print ( \" Finishing Log File...\" , end = \" \\r \" ) logging . write_log_completion_summary ( current , exclude , logMode , banChoice , deletionModeFriendlyName , includeOtherAuthorComments ) print ( \" \" ) # Write Json Log File if config [ 'json_log' ] == True and loggingEnabled and current . matchedCommentsDict : print ( \" \\n Writing JSON log file...\" ) if config [ 'json_extra_data' ] == True : if current . errorOccurred == False : jsonDataDict = logging . get_extra_json_data ( list ( current . matchSamplesDict . keys ()), jsonSettingsDict ) logging . write_json_log ( jsonSettingsDict , combinedCommentDict , jsonDataDict ) else : print ( f \" \\n { F . LIGHTRED_EX } NOTE: { S . R } Extra JSON data collection disabled due to error during scanning\" ) else : logging . write_json_log ( jsonSettingsDict , combinedCommentDict ) if returnToMenu == True : print ( \" \\n JSON Operation Finished.\" ) ### ---------------- Reporting / Deletion Begin ---------------- if returnToMenu == False : if proceedWithDeletion == True : operations . delete_found_comments ( list ( combinedCommentDict ), banChoice , deletionMode ) if deletionMode != \"reportSpam\" : if config [ 'check_deletion_success' ] == True : operations . check_deleted_comments ( list ( combinedCommentDict )) elif config [ 'check_deletion_success' ] == False : print ( \" \\n Skipped checking if deletion was successful. \\n \" ) if config [ 'auto_close' ] == True : print ( \" \\n Program Complete.\" ) print ( \"Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( f \" \\n Program { F . LIGHTGREEN_EX } Complete { S . R } . Press Enter to to return to main menu...\" ) return True elif current . errorOccurred == True : if config [ 'auto_close' ] == True : print ( \"Deletion disabled due to error during scanning. Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( f \" \\n Deletion disabled due to error during scanning. Press Enter to return to main menu...\" ) return True elif config [ 'skip_deletion' ] == True : if config [ 'auto_close' ] == True : print ( \" \\n Deletion disabled in config file.\" ) print ( \"Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : if confirmDelete != None and str ( confirmDelete . lower ()) == \"none\" : input ( f \" \\n Deletion { F . LIGHTCYAN_EX } Declined { S . R } . Press Enter to to return to main menu...\" ) else : input ( f \" \\n Deletion { F . LIGHTRED_EX } Cancelled { S . R } . Press Enter to to return to main menu...\" ) return True else : if config [ 'auto_close' ] == True : print ( \"Deletion Cancelled. Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( f \" \\n Deletion { F . LIGHTRED_EX } Cancelled { S . R } . Press Enter to to return to main menu...\" ) return True # ------------------------------------------------------------------------------------------------------------------------------------------------- # ------------------------------------------------END PRIMARY INSTANCE----------------------------------------------------------------------------- # ------------------------------------------------------------------------------------------------------------------------------------------------- # Loops Entire Program to Main Menu continueRunning = True while continueRunning == True : continueRunning = primaryInstance ( miscData )","title":"YTSpammerPurge"},{"location":"reference/YTSpammerPurge/#YTSpammerPurge.configVersion","text":"configVersion = 26","title":"configVersion"},{"location":"reference/YTSpammerPurge/#YTSpammerPurge.reason","text":"reason = str ( hx . error_details [ 0 ][ 'reason' ])","title":"reason"},{"location":"reference/YTSpammerPurge/#YTSpammerPurge.version","text":"version = '2.15.4'","title":"version"},{"location":"reference/YTSpammerPurge/#YTSpammerPurge.main","text":"main () Source code in YT-Spammer-Purge/YTSpammerPurge.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 def main (): # Run check on python version, must be 3.6 or higher because of f strings if sys . version_info [ 0 ] < 3 or sys . version_info [ 1 ] < 6 : print ( \"Error Code U-2: This program requires running python 3.6 or higher! You are running\" + str ( sys . version_info [ 0 ]) + \".\" + str ( sys . version_info [ 1 ])) input ( \"Press Enter to exit...\" ) sys . exit () # Declare Global Variables global YOUTUBE global CURRENTUSER User = namedtuple ( 'User' , 'id name configMatch' ) # Some Typehints scanMode : str config : dict jsonData : dict versionInfoJson : dict # Checks system platform to set correct console clear command # Clears console otherwise the windows terminal doesn't work with colorama for some reason clear_command = \"cls\" if platform . system () == \"Windows\" else \"clear\" os . system ( clear_command ) # Initiates colorama and creates shorthand variables for resetting colors init ( autoreset = True ) S . R = S . RESET_ALL F . R = F . RESET B . R = B . RESET print ( \" \\n Loading YT Spammer Purge @ \" + str ( version ) + \"...\" ) # Authenticate with the Google API - If token expired and invalid, deletes and re-authenticates YOUTUBE = auth . first_authentication () #### Prepare Resources #### resourceFolder = RESOURCES_FOLDER_NAME whitelistPathWithName = os . path . join ( resourceFolder , \"whitelist.txt\" ) spamListFolder = os . path . join ( resourceFolder , \"Spam_Lists\" ) spamListDict = { 'Lists' : { 'Domains' : { 'FileName' : \"SpamDomainsList.txt\" }, 'Accounts' : { 'FileName' : \"SpamAccountsList.txt\" }, 'Threads' : { 'FileName' : \"SpamThreadsList.txt\" } }, 'Meta' : { 'VersionInfo' : { 'FileName' : \"SpamVersionInfo.json\" }, 'SpamListFolder' : spamListFolder #'LatestLocalVersion': {} } } resourcesDict = { 'Whitelist' : { 'PathWithName' : whitelistPathWithName , 'FileName' : \"whitelist.txt\" , } } print ( \"Checking for updates to program and spam lists...\" ) # Check if resources and spam list folders exist, and create them if not os . path . isdir ( resourceFolder ): try : os . mkdir ( resourceFolder ) # Create readme with open ( os . path . join ( resourceFolder , \"_What_Is_This_Folder.txt\" ), \"w\" ) as f : f . write ( \"# This Resources folder is used to store resources required for the YT Spammer Purge program. \\n \" ) f . write ( \"# Note: If you had a previous spam_lists folder that was created in the same folder as \\n \" ) f . write ( \"# the .exe file, you can delete that old spam_lists folder. The resources folder is the \\n \" ) f . write ( \"# new location they will be stored. \\n \" ) except : print ( \" \\n Error: Could not create folder. To update the spam lists, try creating a folder called 'SpamPurge_Resources',\" ) print ( \" then inside that, create another folder called 'Spam_Lists'.\" ) input ( \"Press Enter to continue...\" ) if os . path . isdir ( resourceFolder ) and not os . path . isdir ( spamListFolder ): try : os . mkdir ( spamListFolder ) except : print ( \" \\n Error: Could not create folder. To update the spam lists, go into the 'SpamPurge_Resources' folder,\" ) print ( \" then inside that, create another folder called 'Spam_Lists'.\" ) # Prepare to check and ingest spammer list files # Iterate and get paths of each list for x , spamList in spamListDict [ 'Lists' ] . items (): spamList [ 'Path' ] = os . path . join ( spamListFolder , spamList [ 'FileName' ]) spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ] = os . path . join ( spamListFolder , spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'FileName' ]) # Path to version included in packaged assets folder # Check if each spam list exists, if not copy from assets, then get local version number, calculate latest version number latestLocalSpamListVersion = \"1900.12.31\" for x , spamList in spamListDict [ 'Lists' ] . items (): if not os . path . exists ( spamList [ 'Path' ]): files . copy_asset_file ( spamList [ 'FileName' ], spamList [ 'Path' ]) listVersion = files . get_list_file_version ( spamList [ 'Path' ]) spamList [ 'Version' ] = listVersion if listVersion and parse_version ( listVersion ) > parse_version ( latestLocalSpamListVersion ): latestLocalSpamListVersion = listVersion spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestLocalVersion' ] = latestLocalSpamListVersion # Check for version info file, if it doesn't exist, get from assets folder if not os . path . exists ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ]): files . copy_asset_file ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'FileName' ], spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ]) # Get stored spam list version data from json file jsonData = open ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ], 'r' , encoding = \"utf-8\" ) versionInfoJson = str ( json . load ( jsonData )) # Parses json file into a string versionInfo = ast . literal_eval ( versionInfoJson ) # Parses json string into a dictionary spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestRelease' ] = versionInfo [ 'LatestRelease' ] spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LastChecked' ] = versionInfo [ 'LastChecked' ] # Check for primary config file, load into dictionary 'config'. If no config found, loads data from default config in assets folder os . system ( clear_command ) config = files . load_config_file ( configVersion ) validation . validate_config_settings ( config ) os . system ( clear_command ) # Check for program and list updates if auto updates enabled in config try : if config [ 'release_channel' ] == \"all\" : updateReleaseChannel = \"all\" elif config [ 'release_channel' ] == \"stable\" : updateReleaseChannel = \"stable\" else : print ( \"Invalid value for 'release_channel' in config file. Must be 'All' or 'Stable'\" ) print ( \"Defaulting to 'All'\" ) input ( \"Press Enter to continue...\" ) updateReleaseChannel = \"all\" except KeyError : print ( \" \\n Your version of the config file does not specify a release channel. Defaulting to 'All'\" ) print ( f \" { F . YELLOW } Re-create your config { S . R } to get the latest version.\" ) input ( \" \\n Press Enter to continue...\" ) updateReleaseChannel = \"all\" if config [ 'auto_check_update' ] == True : try : updateAvailable = files . check_for_update ( version , updateReleaseChannel , silentCheck = True , ) except Exception as e : print ( f \" { F . LIGHTRED_EX } Error Code U-3 occurred while checking for updates. (Checking can be disabled using the config file setting) Continuing... { S . R } \\n \" ) updateAvailable = None # Check if today or tomorrow's date is later than the last update date (add day to account for time zones) if datetime . today () + timedelta ( days = 1 ) >= datetime . strptime ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestLocalVersion' ], '%Y.%m. %d ' ): # Only check for updates until the next day if datetime . today () > datetime . strptime ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LastChecked' ], '%Y.%m. %d .%H.%M' ) + timedelta ( days = 1 ): spamListDict = files . check_lists_update ( spamListDict , silentCheck = True ) else : updateAvailable = False # In all scenarios, load spam lists into memory for x , spamList in spamListDict [ 'Lists' ] . items (): spamList [ 'FilterContents' ] = files . ingest_list_file ( spamList [ 'Path' ], keepCase = False ) ####### Load Other Data into MiscData ####### print ( \" \\n Loading other assets.. \\n \" ) @dataclass class MiscDataStore : resources : dict spamLists : dict rootDomainsList : list totalCommentCount : int channelOwnerID : str channelOwnerName : str miscData = MiscDataStore ( resources = {}, spamLists = {}, rootDomainsList = [], totalCommentCount = 0 , channelOwnerID = \"\" , channelOwnerName = \"\" , ) rootDomainListAssetFile = \"rootZoneDomainList.txt\" rootDomainList = files . ingest_asset_file ( rootDomainListAssetFile ) miscData . resources = rootDomainList miscData . spamLists [ 'spamDomainsList' ] = spamListDict [ 'Lists' ][ 'Domains' ][ 'FilterContents' ] miscData . spamLists [ 'spamAccountsList' ] = spamListDict [ 'Lists' ][ 'Accounts' ][ 'FilterContents' ] miscData . spamLists [ 'spamThreadsList' ] = spamListDict [ 'Lists' ][ 'Threads' ][ 'FilterContents' ] miscData . resources = resourcesDict # Create Whitelist if it doesn't exist, if not os . path . exists ( whitelistPathWithName ): with open ( whitelistPathWithName , \"a\" ) as f : f . write ( \"# Commenters whose channel IDs are in this list will always be ignored. You can add or remove IDs (one per line) from this list as you wish. \\n \" ) f . write ( \"# Channel IDs for a channel can be found in the URL after clicking a channel's name while on the watch page or where they've left a comment. \\n \" ) f . write ( \"# - Channels that were 'excluded' will also appear in this list. \\n \" ) f . write ( \"# - Lines beginning with a '#' are comments and aren't read by the program. (But do not put a '#' on the same line as actual data) \\n\\n \" ) miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] = [] else : miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] = files . ingest_list_file ( whitelistPathWithName , keepCase = True ) if config : moderator_mode = config [ 'moderator_mode' ] else : moderator_mode = False os . system ( clear_command ) #----------------------------------- Begin Showing Program --------------------------------- print ( f \" { F . LIGHTYELLOW_EX } \\n ===================== YOUTUBE SPAMMER PURGE v\" + version + f \" ===================== { S . R } \" ) print ( \"=========== https://github.com/ThioJoe/YT-Spammer-Purge ===========\" ) print ( \"================= Author: ThioJoe - YouTube.com/ThioJoe ================ \\n \" ) # Instructions print ( \"Purpose: Lets you scan for spam comments and mass-delete them all at once \\n \" ) print ( \"NOTE: It's probably better to scan individual videos, because you can scan all those comments,\" ) print ( \" but scanning your entire channel must be limited and might miss older spam comments.\" ) print ( \"You will be shown the comments to confirm before they are deleted.\" ) # While loop until user confirms they are logged into the correct account confirmedCorrectLogin = False while confirmedCorrectLogin == False : # Get channel ID and title of current user, confirm with user userInfo = auth . get_current_user ( config ) CURRENTUSER = User ( id = userInfo [ 0 ], name = userInfo [ 1 ], configMatch = userInfo [ 2 ]) # Returns [channelID, channelTitle, configmatch] auth . CURRENTUSER = CURRENTUSER print ( \" \\n > Currently logged in user: \" + f \" { F . LIGHTGREEN_EX } \" + str ( CURRENTUSER . name ) + f \" { S . R } (Channel ID: { F . LIGHTGREEN_EX } \" + str ( CURRENTUSER . id ) + f \" { S . R } )\" ) if choice ( \" Continue as this user?\" , CURRENTUSER . configMatch ) == True : confirmedCorrectLogin = True os . system ( clear_command ) else : auth . remove_token () os . system ( clear_command ) YOUTUBE = auth . get_authenticated_service () # Declare Classes @dataclass class ScanInstance : matchedCommentsDict : dict duplicateCommentsDict : dict otherCommentsByMatchedAuthorsDict : dict spamThreadsDict : dict allScannedCommentsDict : dict vidIdDict : dict vidTitleDict : dict matchSamplesDict : dict authorMatchCountDict : dict scannedRepliesCount : int scannedCommentsCount : int logTime : str logFileName : str errorOccurred : bool # matchTypeCount:dict ############################################## ######### PRIMARY INSTANCE FUNCTION ########## ############################################## ## Allows Re-running Program From Main Menu ## ############################################## def primaryInstance ( miscData ): timestamp = datetime . now () . strftime ( \"%Y-%m- %d _%H-%M-%S\" ) # Instantiate class for primary instance current = ScanInstance ( matchedCommentsDict = {}, duplicateCommentsDict = {}, otherCommentsByMatchedAuthorsDict = {}, spamThreadsDict = {}, allScannedCommentsDict = {}, vidIdDict = {}, vidTitleDict = {}, matchSamplesDict = {}, authorMatchCountDict = {}, scannedRepliesCount = 0 , scannedCommentsCount = 0 , logTime = timestamp , logFileName = None , errorOccurred = False , ) # Declare Default Variables maxScanNumber = 999999999 scanVideoID = None videosToScan = [] loggingEnabled = False userNotChannelOwner = False os . system ( clear_command ) # ----------------------------------------------------------------------------------------------------------------------------- if updateAvailable != False : updateStringLabel = \"Update Available: \" if updateAvailable == True : # Stable update available updateString = f \" { F . LIGHTGREEN_EX } Yes { S . R } \" elif updateAvailable == \"beta\" : # Beta Update Available if updateReleaseChannel == \"stable\" : updateStringLabel = \"\" updateString = \"\" else : updateString = f \" { F . CYAN } Beta { S . R } \" elif updateAvailable == None : updateString = f \" { F . LIGHTRED_EX } Error { S . R } \" print ( \"> Note: Error during check for updates. Select 'Check For Updates' for details.\" ) else : if config [ 'auto_check_update' ] == False : updateStringLabel = \"Update Checking: \" updateString = \"Off\" else : updateStringLabel = \"\" updateString = \"\" # User selects scanning mode, while Loop to get scanning mode, so if invalid input, it will keep asking until valid input print ( \" \\n {:<59}{:<18}{:>5} \" . format ( \"> At any prompt, enter 'X' to return here\" , updateStringLabel , updateString )) print ( \"> Enter 'Q' now to quit\" ) print ( f \" \\n\\n -------------------------------- { F . YELLOW } Scanning Options { S . R } --------------------------------\" ) print ( f \" 1. Scan { F . LIGHTCYAN_EX } specific videos { S . R } \" ) print ( f \" 2. Scan { F . LIGHTCYAN_EX } recent videos { S . R } for a channel\" ) print ( f \" 3. Scan recent comments across your { F . LIGHTBLUE_EX } Entire Channel { S . R } \" ) print ( f \" 4. Scan a specific { F . LIGHTMAGENTA_EX } community post { S . R } (Experimental)\" ) print ( f \" 5. Scan { F . LIGHTMAGENTA_EX } recent community posts { S . R } for a channel (Experimental)\" ) print ( f \" \\n --------------------------------- { F . YELLOW } Other Options { S . R } ----------------------------------\" ) print ( f \" 6. Create your own { F . LIGHTGREEN_EX } config file(s) { S . R } to run the program with pre-set settings\" ) print ( f \" 7. Remove comments using a { F . LIGHTRED_EX } pre-existing list { S . R } or log file\" ) print ( f \" 8. Recover deleted comments using log file\" ) print ( f \" 9. Check & Download { F . LIGHTCYAN_EX } Updates { S . R } \\n \" ) # Make sure input is valid, if not ask again validMode : bool = False validConfigSetting : bool = True while validMode == False : if validConfigSetting == True and config and config [ 'scan_mode' ] != 'ask' : scanMode = config [ 'scan_mode' ] else : scanMode = input ( \"Choice (1-9): \" ) if scanMode . lower () == \"q\" : sys . exit () # Set scanMode Variable Names validModeValues = [ '1' , '2' , '3' , '4' , '5' , '6' , '7' , '8' , '9' , 'chosenvideos' , 'recentvideos' , 'entirechannel' , 'communitypost' , 'commentlist' , 'recentcommunityposts' ] if scanMode in validModeValues : validMode = True if scanMode == \"1\" or scanMode == \"chosenvideos\" : scanMode = \"chosenVideos\" elif scanMode == \"2\" or scanMode == \"recentvideos\" : scanMode = \"recentVideos\" elif scanMode == \"3\" or scanMode == \"entirechannel\" : scanMode = \"entireChannel\" elif scanMode == \"4\" or scanMode == \"communitypost\" : scanMode = \"communityPost\" elif scanMode == \"5\" or scanMode == \"recentcommunityposts\" : scanMode = \"recentCommunityPosts\" elif scanMode == \"6\" : scanMode = \"makeConfig\" elif scanMode == \"7\" or scanMode == \"commentlist\" : scanMode = \"commentList\" elif scanMode == \"8\" : scanMode = \"recoverMode\" elif scanMode == \"9\" : scanMode = \"checkUpdates\" else : print ( f \" \\n Invalid choice: { scanMode } - Enter a number from 1 to 9\" ) validConfigSetting = False # ================================================================================= CHOSEN VIDEOS ====================================================================================================== # If chooses to scan single video - Validate Video ID, get title, and confirm with user if scanMode == \"chosenVideos\" : # While loop to get video ID and if invalid ask again confirm : bool = False validConfigSetting = True while confirm == False : numVideos = 1 allVideosMatchBool = True miscData . totalCommentCount = 0 # Checks if input list is empty and if contains only valid video IDs listNotEmpty : bool = False validVideoIDs = False # False just to get into the loop while listNotEmpty == False or validVideoIDs == False : if validConfigSetting == True and config and config [ 'videos_to_scan' ] != 'ask' : enteredVideosList = utils . string_to_list ( config [ 'videos_to_scan' ]) if len ( enteredVideosList ) == 0 : validConfigSetting = False listNotEmpty = False print ( f \" { F . LIGHTRED_EX } \\n Error: Video list is empty! { S . R } \" ) else : listNotEmpty = True else : print ( f \" \\n Enter a list of { F . YELLOW } Video Links { S . R } or { F . YELLOW } Video IDs { S . R } to scan, separated by commas.\" ) print ( \" > Note: All videos must be from the same channel.\" ) enteredVideosList = utils . string_to_list ( input ( \" \\n Enter here: \" )) if str ( enteredVideosList ) . lower () == \"['x']\" : return True # Return to main menu validConfigSetting = False if len ( enteredVideosList ) == 0 : listNotEmpty = False print ( f \" { F . LIGHTRED_EX } \\n Error: Video list is empty! { S . R } \" ) else : listNotEmpty = True # Validates all video IDs/Links, gets necessary info about them validVideoIDs : bool = True videosToScan = [] videoListResult = [] # True/False, video ID, videoTitle, commentCount, channelID, channelTitle for i in range ( len ( enteredVideosList )): videoListResult . append ([]) videosToScan . append ({}) videoListResult [ i ] = validation . validate_video_id ( enteredVideosList [ i ]) # Sends link or video ID for isolation and validation if videoListResult [ i ][ 0 ] == False : validVideoIDs = False confirm = False break for i in range ( len ( videoListResult )): # Change this if videoListResult [ i ][ 0 ] == True : videosToScan [ i ][ 'videoID' ] = str ( videoListResult [ i ][ 1 ]) videosToScan [ i ][ 'videoTitle' ] = str ( videoListResult [ i ][ 2 ]) videosToScan [ i ][ 'commentCount' ] = int ( videoListResult [ i ][ 3 ]) videosToScan [ i ][ 'channelOwnerID' ] = str ( videoListResult [ i ][ 4 ]) videosToScan [ i ][ 'channelOwnerName' ] = str ( videoListResult [ i ][ 5 ]) miscData . totalCommentCount += int ( videoListResult [ i ][ 3 ]) else : print ( f \" \\n Invalid Video: { enteredVideosList [ i ] } | Video ID = { videoListResult [ 1 ] } \" ) validConfigSetting = False break # Check each video against first to ensure all on same channel if allVideosMatchBool == True : misMatchVidIndex = 0 if videosToScan [ 0 ][ 'channelOwnerID' ] != videosToScan [ i ][ 'channelOwnerID' ]: misMatchVidIndex += 1 if allVideosMatchBool == True : print ( f \" \\n { F . LIGHTRED_EX } ERROR: Videos scanned together all must be from the same channel. { S . R } \" ) print ( \" The following videos do not match the channel owner of the first video in the list: \" ) if misMatchVidIndex == 11 and len ( enteredVideosList ) > 10 : remainingCount = str ( len ( enteredVideosList ) - 10 ) userChoice = choice ( f \"There are { remainingCount } more mis-matched videos, do you want to see the rest?\" ) if userChoice == False : break elif userChoice == None : return True # Return to main menu print ( f \" { misMatchVidIndex } . { str ( videosToScan [ i ][ 'videoTitle' ]) } \" ) validConfigSetting = False allVideosMatchBool = False # If videos not from same channel, skip and re-prompt if allVideosMatchBool == True : # Print video titles, if there are many, ask user to see all if more than 5 i = 0 print ( f \" \\n { F . BLUE } Chosen Videos: { S . R } \" ) for video in videosToScan : i += 1 if i == 6 and len ( enteredVideosList ) > 5 : remainingCount = str ( len ( enteredVideosList ) - 5 ) userChoice = choice ( f \"You have entered many videos, do you need to see the rest (x { remainingCount } )?\" ) if userChoice == False : break elif userChoice == None : return True # Return to main menu print ( f \" { i } . { video [ 'videoTitle' ] } \" ) print ( \"\" ) if CURRENTUSER . id != videosToScan [ 0 ][ 'channelOwnerID' ]: userNotChannelOwner = True miscData . channelOwnerID = videosToScan [ 0 ][ 'channelOwnerID' ] miscData . channelOwnerName = videosToScan [ 0 ][ 'channelOwnerName' ] # Ask if correct videos, or skip if config if config [ 'skip_confirm_video' ] == True : confirm = True else : if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . LIGHTRED_EX } NOTE: This is not your video. Enabling ' { F . YELLOW } Not Your Channel Mode { F . LIGHTRED_EX } '. You can report spam comments, but not delete them. { S . R } \" ) elif userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . LIGHTRED_EX } NOTE: { F . YELLOW } Moderator Mode is enabled { F . LIGHTRED_EX } . You can hold comments for review when using certain modes { S . R } \" ) print ( \"Total number of comments to scan: \" + str ( miscData . totalCommentCount )) if miscData . totalCommentCount >= 100000 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of comments. The default API quota limit ends up\" ) print ( f \" around { F . YELLOW } 10,000 comment deletions per day { S . R } . If you find more spam than that you will go over the limit.\" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if userNotChannelOwner == True or moderator_mode == True : print ( f \" { F . LIGHTCYAN_EX } > Note: { S . R } You may want to disable 'check_deletion_success' in the config, as this doubles the API cost! (So a 5K limit)\" ) confirm = choice ( \"Is this video list correct?\" , bypass = validConfigSetting ) if confirm == None : return True # Return to main menu # ============================================================================ RECENT VIDEOS ========================================================================================================== elif scanMode == \"recentVideos\" : confirm = False validEntry = False validChannel = False while validChannel == False : # Get and verify config setting for channel ID if config [ 'channel_to_scan' ] != 'ask' : if config [ 'channel_to_scan' ] == 'mine' : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True break else : validChannel , channelID , channelTitle = validation . validate_channel_id ( config [ 'channel_to_scan' ]) if validChannel == True : break else : print ( \"Invalid Channel ID or Link in config file!\" ) print ( f \" \\n Enter a { F . YELLOW } channel ID or Link { S . R } to scan { F . LIGHTCYAN_EX } recent videos { S . R } from\" ) print ( f \" > If scanning { F . YELLOW } your own channel { S . R } , just hit { F . LIGHTGREEN_EX } Enter { S . R } \" ) inputtedChannel = input ( \" \\n Enter Here: \" ) if inputtedChannel == \"\" : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True elif str ( inputtedChannel ) . lower () == \"x\" : return True # Return to main menu else : validChannel , channelID , channelTitle = validation . validate_channel_id ( inputtedChannel ) if CURRENTUSER . id != channelID : userNotChannelOwner = True print ( f \" \\n Chosen Channel: { F . LIGHTCYAN_EX }{ channelTitle }{ S . R } \" ) # Get number of recent videos to scan, either from config or user input, and validate while validEntry == False or confirm == False : videosToScan = [] validConfigSetting = True if config [ 'recent_videos_amount' ] != 'ask' and validConfigSetting == True : numVideos = config [ 'recent_videos_amount' ] try : numVideos = int ( numVideos ) except : validConfigSetting = False print ( \"Invalid number entered in config file for recent_videos_amount\" ) numVideos = None else : print ( f \" \\n Enter the { F . YELLOW } number most recent videos { S . R } to scan back-to-back:\" ) numVideos = input ( \" \\n Number of Recent Videos: \" ) print ( \"\" ) if str ( numVideos ) . lower () == \"x\" : return True # Return to main menu try : numVideos = int ( numVideos ) if numVideos > 0 and numVideos <= 500 : validEntry = True validConfigSetting = True else : print ( \"Error: Entry must be from 1 to 500 (the YouTube API Limit)\" ) validEntry = False validConfigSetting = False except ValueError : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Entry must be a whole number greater than zero.\" ) if validEntry == True and numVideos >= 100 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of videos. With the default API quota limit,\" ) print ( f \" every 100 videos will use up 20% of the quota { F . YELLOW } just from listing the videos alone, before any comment scanning. { S . R } \" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if validEntry == True : # Fetch recent videos and print titles to user for confirmation videosToScan = operations . get_recent_videos ( channelID , numVideos ) if str ( videosToScan ) == \"MainMenu\" : return True # Return to main menu if len ( videosToScan ) == 0 : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } No scannable videos found in selected range! They all may have no comments and/or are live streams.\" ) if config [ 'auto_close' ] == True : print ( \"Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( \" \\n Press Enter to return to main menu...\" ) return True # Get total comment count miscData . totalCommentCount = 0 for video in videosToScan : miscData . totalCommentCount += int ( video [ 'commentCount' ]) if len ( videosToScan ) < numVideos : print ( f \" \\n { F . YELLOW } WARNING: { S . R } Only { len ( videosToScan ) } videos found. Videos may be skipped if there are no comments.\" ) print ( \" \\n Recent Videos To Be Scanned:\" ) for i in range ( len ( videosToScan )): if config [ 'skip_confirm_video' ] == False : if i == 10 and len ( videosToScan ) > 11 : remainingCount = str ( len ( videosToScan ) - 10 ) userChoice = choice ( f \"There are { remainingCount } more recent videos, do you want to see the rest?\" ) if userChoice == False : break elif userChoice == None : return True # Return to main menu print ( f \" { i + 1 } . { videosToScan [ i ][ 'videoTitle' ] } \" ) if config [ 'skip_confirm_video' ] == True and validConfigSetting == True : confirm = True else : if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . LIGHTRED_EX } NOTE: These aren't your videos. Enabling ' { F . YELLOW } Not Your Channel Mode { F . LIGHTRED_EX } '. You can report spam comments, but not delete them. { S . R } \" ) elif userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . LIGHTRED_EX } NOTE: { F . YELLOW } Moderator Mode is enabled { F . LIGHTRED_EX } . You can hold comments for review when using certain modes { S . R } \" ) print ( \" \\n Total number of comments to scan: \" + str ( miscData . totalCommentCount )) if miscData . totalCommentCount >= 100000 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of comments. The default API quota limit ends up\" ) print ( f \" around { F . YELLOW } 10,000 comment deletions per day { S . R } . If you find more spam than that you will go over the limit.\" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if userNotChannelOwner == True or moderator_mode == True : print ( f \" { F . LIGHTCYAN_EX } > Note: { S . R } You may want to disable 'check_deletion_success' in the config, as this doubles the API cost! (So a 5K limit)\" ) confirm = choice ( \"Is everything correct?\" , bypass = config [ 'skip_confirm_video' ]) if confirm == None : return True # Return to main menu miscData . channelOwnerID = channelID miscData . channelOwnerName = channelTitle # ============================================================================= ENTIRE CHANNEL ============================================================================================================ # If chooses to scan entire channel - Validate Channel ID elif scanMode == \"entireChannel\" : numVideos = 1 # Using this variable to indicate only one loop of scanning done later # While loop to get max scan number, not an integer, asks again validInteger = False if config : validConfigSetting = True while validInteger == False : try : if validConfigSetting == True and config and config [ 'max_comments' ] != 'ask' : maxScanNumber = int ( config [ 'max_comments' ]) else : maxScanNumber = input ( f \"Enter the maximum { F . YELLOW } number of comments { S . R } to scan: \" ) if str ( maxScanNumber ) . lower () == \"x\" : return True # Return to main menu maxScanNumber = int ( maxScanNumber ) if maxScanNumber >= 100000 : print ( f \" \\n { B . YELLOW }{ F . BLACK } WARNING: { S . R } You have chosen to scan a large amount of comments. The default API quota limit ends up\" ) print ( f \" around { F . YELLOW } 10,000 comment deletions per day { S . R } . If you find more spam than that you will go over the limit.\" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) if userNotChannelOwner == True or moderator_mode == True : print ( f \" { F . LIGHTCYAN_EX } > Note: { S . R } You may want to disable 'check_deletion_success' in the config, as this doubles the API cost! (So a 5K limit)\" ) userChoice = choice ( \"Do you still want to continue?\" ) if userChoice == False : validInteger == False elif userChoice == None : return True # Return to main menu if maxScanNumber > 0 : validInteger = True # If it gets here, it's an integer, otherwise goes to exception else : print ( \" \\n Invalid Input! Number must be greater than zero.\" ) validConfigSetting = False except : print ( \" \\n Invalid Input! - Must be a whole number.\" ) validConfigSetting = False miscData . channelOwnerID = CURRENTUSER . id miscData . channelOwnerName = CURRENTUSER . name # ================================================================================ COMMUNITY POST ===================================================================================================== elif scanMode == 'communityPost' : print ( f \" \\n NOTES: This mode is { F . YELLOW } experimental { S . R } , and not as polished as other features. Expect some janky-ness.\" ) print ( \" > It is also much slower to retrieve comments, because it does not use the API\" ) confirm = False while confirm == False : communityPostInput = input ( \" \\n Enter the ID or link of the community post: \" ) if str ( communityPostInput ) . lower () == \"x\" : return True # Return to main menu # Validate post ID or link, get additional info about owner, and useable link isValid , communityPostID , postURL , postOwnerID , postOwnerUsername = validation . validate_post_id ( communityPostInput ) if isValid == True : print ( \" \\n Community Post By: \" + postOwnerUsername ) if postOwnerID != CURRENTUSER . id : userNotChannelOwner = True print ( f \" \\n { F . YELLOW } Warning: { S . R } You are scanning someone elses post. ' { F . LIGHTRED_EX } Not Your Channel Mode { S . R } ' Enabled.\" ) confirm = choice ( \"Continue?\" ) if confirm == None : return True # Return to main menu else : print ( \"Problem interpreting the post information, please check the link or ID.\" ) miscData . channelOwnerID = postOwnerID miscData . channelOwnerName = postOwnerUsername # Checking config for max comments in config if config [ 'max_comments' ] != 'ask' : validInteger = False try : maxScanNumber = int ( config [ 'max_comments' ]) if maxScanNumber > 0 : validInteger = True else : pass except : pass if validInteger == False : print ( \" \\n Invalid max_comments setting in config! Number must a whole number be greater than zero.\" ) while validInteger == False : maxScanInput = input ( f \" \\n Enter the maximum { F . YELLOW } number of comments { S . R } to scan: \" ) if str ( maxScanInput ) . lower () == \"x\" : return True # Return to main menu try : maxScanNumber = int ( maxScanInput ) if maxScanNumber > 0 : validInteger = True # If it gets here, it's an integer, otherwise goes to exception else : print ( \" \\n Invalid Input! Number must a whole number be greater than zero.\" ) except : print ( \" \\n Invalid Input! - Must be a whole number greater than zero.\" ) # ==================================================================== RECENT COMMUNITY POSTS ============================================================================================================= # Recent Community Posts elif scanMode == 'recentCommunityPosts' : print ( f \" \\n NOTES: This mode is { F . YELLOW } experimental { S . R } , and not as polished as other features. Expect some janky-ness.\" ) print ( \" > It is also much slower to retrieve comments, because it does not use the API\" ) confirm = False validEntry = False validChannel = False while validChannel == False : # Get and verify config setting for channel ID if config [ 'channel_to_scan' ] != 'ask' : if config [ 'channel_to_scan' ] == 'mine' : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True break else : validChannel , channelID , channelTitle = validation . validate_channel_id ( config [ 'channel_to_scan' ]) if validChannel == True : break else : print ( \"Invalid Channel ID or Link in config file!\" ) print ( f \" \\n Enter a { F . YELLOW } channel ID or Link { S . R } to scan { F . LIGHTCYAN_EX } recent community posts { S . R } from\" ) print ( f \" > If scanning { F . YELLOW } your own channel { S . R } , just hit { F . LIGHTGREEN_EX } Enter { S . R } \" ) inputtedChannel = input ( \" \\n Enter Here: \" ) if inputtedChannel == \"\" : channelID = CURRENTUSER . id channelTitle = CURRENTUSER . name validChannel = True elif str ( inputtedChannel ) . lower () == \"x\" : return True # Return to main menu else : validChannel , channelID , channelTitle = validation . validate_channel_id ( inputtedChannel ) if CURRENTUSER . id != channelID : userNotChannelOwner = True # Get and print community posts recentPostsListofDicts = community_downloader . fetch_recent_community_posts ( channelID ) print ( \" \\n ------------------------------------------------------------\" ) print ( f \"Retrieved { F . YELLOW }{ len ( recentPostsListofDicts ) } recent posts { S . R } from { F . LIGHTCYAN_EX }{ channelTitle }{ S . R } \" ) print ( f \" \\n Post Content Samples:\" ) for i in range ( len ( recentPostsListofDicts )): print ( f \" { i + 1 } .\" . ljust ( 9 , \" \" ) + f \" { list ( recentPostsListofDicts [ i ] . values ())[ 0 ][ 0 : 50 ] } \" ) if userNotChannelOwner == True : print ( f \" \\n > { F . LIGHTRED_EX } Warning: { S . R } You are scanning someone elses post. { F . LIGHTRED_EX } 'Not Your Channel Mode' { S . R } Enabled.\" ) print ( f \" \\n { F . YELLOW } How many { S . R } of the most recent posts do you want to scan?\" ) inputStr = \"\" while True : if config [ 'recent_videos_amount' ] != 'ask' and inputStr == \"\" : inputStr = config [ 'recent_videos_amount' ] else : inputStr = input ( \" \\n Number of Recent Posts: \" ) if str ( inputStr ) . lower () == \"x\" : return True try : numRecentPosts = int ( inputStr ) if numRecentPosts > len ( recentPostsListofDicts ): print ( \"Number entered is more than posts available. Will just scan all posts available.\" ) numRecentPosts = len ( recentPostsListofDicts ) break elif numRecentPosts <= 0 : print ( \"Please enter a whole number greater than zero.\" ) else : break except ValueError : print ( \"Invalid Input! - Must be a whole number.\" ) miscData . channelOwnerID = channelID miscData . channelOwnerName = channelTitle # =============================================================================== OTHER MENU OPTIONS ============================================================================================= # Create config file elif scanMode == \"makeConfig\" : result = files . create_config_file () if str ( result ) == \"MainMenu\" : return True # Check for latest version elif scanMode == \"checkUpdates\" : files . check_lists_update ( spamListDict ) files . check_for_update ( version , updateReleaseChannel ) input ( \" \\n Press Enter to return to main menu...\" ) return True # Recove deleted comments mode elif scanMode == \"recoverMode\" : result = modes . recover_deleted_comments ( config ) if str ( result ) == \"MainMenu\" : return True elif scanMode == \"commentList\" : result = modes . delete_comment_list ( config ) if str ( result ) == \"MainMenu\" : return True # ==================================================================================================================================================================================================== # ==================================================================================================================================================================================================== # User inputs filtering mode print ( \" \\n -------------------------------------------------------\" ) print ( f \"~~~~~~~~~~~ Choose how to identify spammers ~~~~~~~~~~~\" ) print ( \"-------------------------------------------------------\" ) print ( f \" 1. { F . BLACK }{ B . LIGHTGREEN_EX } (RECOMMENDED): { S . R } { F . YELLOW } Auto-Smart Mode { S . R } : Automatically detects multiple spammer techniques\" ) print ( f \" 2. { F . YELLOW } Sensitive-Smart Mode { S . R } : Much more likely to catch all spammers, but with significantly more false positives\" ) print ( f \" 3. Enter Spammer's { F . LIGHTRED_EX } channel ID(s) or link(s) { S . R } \" ) print ( f \" 4. Scan { F . LIGHTBLUE_EX } usernames { S . R } for criteria you choose\" ) print ( f \" 5. Scan { F . CYAN } comment text { S . R } for criteria you choose\" ) print ( f \" 6. Scan both { F . LIGHTBLUE_EX } usernames { S . R } and { F . CYAN } comment text { S . R } for criteria you choose\" ) print ( f \" 7. ASCII Mode: Scan usernames for { F . LIGHTMAGENTA_EX } ANY non-ASCII special characters { S . R } (May cause collateral damage!)\" ) if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . LIGHTRED_EX } Note: With 'Not Your Channel Mode' enabled, you can only report matched comments while using 'Auto-Smart Mode' \\n or 'Sensitive-Smart Mode'. { S . R } \" ) # Based on filterModesAllowedforNonOwners elif userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . LIGHTRED_EX } Note: With 'Moderator Mode', you can hold for review using: 'Auto-Smart', 'Sensitive-Smart', and Channel ID modes. { S . R } \" ) # Make sure input is valid, if not ask again validFilterMode = False validFilterSubMode = False filterSubMode = None validConfigSetting = True validConfigSetting = True while validFilterMode == False : if validConfigSetting == True and config and config [ 'filter_mode' ] != 'ask' : filterChoice = config [ 'filter_mode' ] else : filterChoice = input ( \" \\n Choice (1-7): \" ) if str ( filterChoice ) . lower () == \"x\" : return True # Return to main menu validChoices = [ '1' , '2' , '3' , '4' , '5' , '6' , '7' , 'id' , 'username' , 'text' , 'nameandtext' , 'autoascii' , 'autosmart' , 'sensitivesmart' ] if filterChoice in validChoices : validFilterMode = True # Set string variable names for filtering modes if filterChoice == \"1\" or filterChoice == \"autosmart\" : filterMode = \"AutoSmart\" elif filterChoice == \"2\" or filterChoice == \"sensitivesmart\" : filterMode = \"SensitiveSmart\" elif filterChoice == \"3\" or filterChoice == \"id\" : filterMode = \"ID\" elif filterChoice == \"4\" or filterChoice == \"username\" : filterMode = \"Username\" elif filterChoice == \"5\" or filterChoice == \"text\" : filterMode = \"Text\" elif filterChoice == \"6\" or filterChoice == \"nameandtext\" : filterMode = \"NameAndText\" elif filterChoice == \"7\" or filterChoice == \"autoascii\" : filterMode = \"AutoASCII\" else : print ( f \" \\n Invalid Filter Mode: { filterChoice } - Enter a whole number from 1-7\" ) validConfigSetting = False ## Get filter sub-mode to decide if searching characters or string validConfigSetting = None if config [ 'filter_submode' ] != 'ask' : filterSubMode = config [ 'filter_submode' ] validConfigSetting = True else : validConfigSetting = False if filterMode == \"Username\" or filterMode == \"Text\" or filterMode == \"NameAndText\" : print ( \" \\n --------------------------------------------------------------\" ) if filterMode == \"Username\" : print ( \"~~~ What do you want to scan usernames for specifically? ~~~\" ) elif filterMode == \"Text\" : print ( \"~~~ What do you want to scan comment text for specifically? ~~~\" ) elif filterMode == \"NameAndText\" : print ( \"~~~ What do you want to scan names and comments for specifically? ~~~\" ) print ( f \" 1. A { F . CYAN } certain special character { S . R } , or set of multiple characters\" ) print ( f \" 2. An { F . LIGHTMAGENTA_EX } entire string { S . R } , or multiple strings\" ) print ( f \" 3. Advanced: A custom { F . YELLOW } Regex pattern { S . R } you'll enter\" ) while validFilterSubMode == False : if validConfigSetting == True : pass else : filterSubMode = input ( \" \\n Choice (1, 2, or 3): \" ) if str ( filterSubMode ) . lower () == \"x\" : return True # Return to main menu validFilterSubModes = [ \"1\" , \"2\" , \"3\" , \"characters\" , \"strings\" , \"regex\" ] if filterSubMode in validFilterSubModes : validFilterSubMode = True validConfigSetting = True if filterSubMode == \"1\" or filterSubMode == \"characters\" : filterSubMode = \"chars\" elif filterSubMode == \"2\" or filterSubMode == \"strings\" : filterSubMode = \"string\" elif filterSubMode == \"3\" or filterSubMode == \"regex\" : filterSubMode = \"regex\" else : print ( f \" \\n Invalid choice: { filterSubMode } - Enter 1, 2 or 3\" ) validConfigSetting = False ### Prepare Filtering Modes ### # Default values for filter criteria inputtedSpammerChannelID = None inputtedUsernameFilter = None inputtedCommentTextFilter = None regexPattern = \"\" if filterMode == \"ID\" : filterSettings = modes . prepare_filter_mode_ID ( scanMode , config ) inputtedSpammerChannelID = filterSettings [ 0 ] elif filterMode == \"AutoASCII\" : filterSettings = modes . prepare_filter_mode_non_ascii ( scanMode , config ) regexPattern = filterSettings [ 0 ] elif filterMode == \"AutoSmart\" : filterSettings = modes . prepare_filter_mode_smart ( scanMode , config , miscData ) inputtedUsernameFilter = filterSettings [ 0 ] inputtedCommentTextFilter = filterSettings [ 0 ] elif filterMode == \"SensitiveSmart\" : filterSettings = modes . prepare_filter_mode_smart ( scanMode , config , miscData , sensitive = True ) inputtedUsernameFilter = filterSettings [ 0 ] inputtedCommentTextFilter = filterSettings [ 0 ] elif filterSubMode == \"chars\" : filterSettings = modes . prepare_filter_mode_chars ( scanMode , filterMode , config ) elif filterSubMode == \"string\" : filterSettings = modes . prepare_filter_mode_strings ( scanMode , filterMode , config ) elif filterSubMode == \"regex\" : filterSettings = modes . prepare_filter_mode_regex ( scanMode , filterMode , config ) regexPattern = filterSettings [ 1 ] if filterSettings [ 0 ] == \"MainMenu\" : return True if filterSubMode != \"regex\" : if filterMode == \"Username\" : inputtedUsernameFilter = filterSettings [ 0 ] elif filterMode == \"Text\" : inputtedCommentTextFilter = filterSettings [ 0 ] elif filterMode == \"NameAndText\" : inputtedUsernameFilter = filterSettings [ 0 ] inputtedCommentTextFilter = filterSettings [ 0 ] ##################### START SCANNING ##################### filtersDict = { 'filterSettings' : filterSettings , 'filterMode' : filterMode , 'filterSubMode' : filterSubMode , 'CustomChannelIdFilter' : inputtedSpammerChannelID , 'CustomUsernameFilter' : inputtedUsernameFilter , 'CustomCommentTextFilter' : inputtedCommentTextFilter , 'CustomRegexPattern' : regexPattern } if scanMode == \"communityPost\" or scanMode == \"recentCommunityPosts\" : def scan_community_post ( current , config , communityPostID , limit , postScanProgressDict = None , postText = None ): authorKeyAllCommentsDict = {} allCommunityCommentsDict = get_community_comments ( communityPostID = communityPostID , limit = limit , postScanProgressDict = postScanProgressDict , postText = postText ) retrievedCount = len ( allCommunityCommentsDict ) print ( f \" \\n Retrieved { retrievedCount } comments from post. \\n \" ) scannedCount = 0 threadDict = {} # Analyze and store comments for key , value in allCommunityCommentsDict . items (): currentCommentDict = { 'authorChannelID' : value [ 'authorChannelID' ], 'parentAuthorChannelID' : None , 'authorChannelName' : value [ 'authorName' ], 'commentText' : value [ 'commentText' ], 'commentID' : key , } try : authorKeyAllCommentsDict [ value [ 'authorChannelID' ]] . append ( currentCommentDict ) except KeyError : authorKeyAllCommentsDict [ value [ 'authorChannelID' ]] = [ currentCommentDict ] except TypeError : pass operations . check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID = communityPostID ) # Scam for spam threads if config [ 'detect_spam_threads' ] == True : threadDict = operations . make_community_thread_dict ( key , allCommunityCommentsDict ) if threadDict : parentCommentDict = dict ( currentCommentDict ) parentCommentDict [ 'videoID' ] = communityPostID current = operations . check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ) scannedCount += 1 # Print Progress percent = (( scannedCount / retrievedCount ) * 100 ) progressStats = f \"[ { str ( scannedCount ) } / { str ( retrievedCount ) } ]\" . ljust ( 15 , \" \" ) + f \" ( { percent : .2f } %)\" print ( f ' { progressStats } - Analyzing Comments For Spam ' , end = ' \\r ' ) print ( \" \" ) dupeCheckModes = utils . string_to_list ( config [ 'duplicate_check_modes' ]) if filtersDict [ 'filterMode' ] . lower () in dupeCheckModes : operations . check_duplicates ( current , config , miscData , authorKeyAllCommentsDict , communityPostID ) print ( \" \" ) if scanMode == \"communityPost\" : scan_community_post ( current , config , communityPostID , maxScanNumber ) elif scanMode == \"recentCommunityPosts\" : postScanProgressDict = { 'scanned' : 0 , 'total' : numRecentPosts } for post in recentPostsListofDicts : postScanProgressDict [ 'scanned' ] += 1 id = list ( post . keys ())[ 0 ] # Each dict only has one key/value pair postText = list ( post . values ())[ 0 ] current . vidTitleDict [ id ] = f \"[Community Post]: { postText } \" scan_community_post ( current , config , id , maxScanNumber , postScanProgressDict = postScanProgressDict , postText = postText ) if postScanProgressDict [ 'scanned' ] == numRecentPosts : break else : # Goes to get comments for first page print ( \" \\n ------------------------------------------------------------------------------\" ) print ( \"(Note: If the program appears to freeze, try right clicking within the window) \\n \" ) print ( \" --- Scanning --- \\n \" ) # ---------------------------------------------------------------------------------------------------------------------- def scan_video ( miscData , config , filtersDict , scanVideoID , videosToScan = None , currentVideoDict = {}, videoTitle = None , showTitle = False , i = 1 ): nextPageToken , currentVideoDict = operations . get_comments ( current , filtersDict , miscData , config , currentVideoDict , scanVideoID , videosToScan = videosToScan ) if nextPageToken == \"Error\" : return \"Error\" if showTitle == True and len ( videosToScan ) > 0 : # Prints video title, progress count, adds enough spaces to cover up previous stat print line offset = 95 - len ( videoTitle ) if offset > 0 : spacesStr = \" \" * offset else : spacesStr = \"\" print ( f \"Scanning { i } / { len ( videosToScan ) } : \" + videoTitle + spacesStr + \" \\n \" ) operations . print_count_stats ( current , miscData , videosToScan , final = False ) # Prints comment scan stats, updates on same line # After getting first page, if there are more pages, goes to get comments for next page while nextPageToken != \"End\" and current . scannedCommentsCount < maxScanNumber : nextPageToken , currentVideoDict = operations . get_comments ( current , filtersDict , miscData , config , currentVideoDict , scanVideoID , nextPageToken , videosToScan = videosToScan ) if nextPageToken == \"Error\" : return \"Error\" return \"OK\" # ---------------------------------------------------------------------------------------------------------------------- if scanMode == \"entireChannel\" : status = scan_video ( miscData , config , filtersDict , scanVideoID ) if status == \"Error\" : pass elif scanMode == \"recentVideos\" or scanMode == \"chosenVideos\" : i = 1 for video in videosToScan : currentVideoDict = {} scanVideoID = str ( video [ 'videoID' ]) videoTitle = str ( video [ 'videoTitle' ]) status = scan_video ( miscData , config , filtersDict , scanVideoID , videosToScan = videosToScan , currentVideoDict = currentVideoDict , videoTitle = videoTitle , showTitle = True , i = i ) if status == \"Error\" : break i += 1 if current . errorOccurred == False : operations . print_count_stats ( current , miscData , videosToScan , final = True ) # Prints comment scan stats, finalizes else : utils . print_break_finished ( scanMode ) ########################################################## bypass = False if config [ 'enable_logging' ] != 'ask' : logSetting = config [ 'enable_logging' ] if logSetting == True : loggingEnabled = True bypass = True elif logSetting == False : loggingEnabled = False bypass = True elif logSetting == \"ask\" : bypass = False else : bypass = False print ( \"Error Code C-2: Invalid value for 'enable_logging' in config file: \" + logSetting ) # Counts number of found spam comments and prints list if not current . matchedCommentsDict and not current . duplicateCommentsDict and not current . spamThreadsDict : # If no spam comments found, exits print ( f \" { B . RED }{ F . BLACK } No matched comments or users found! { F . R }{ B . R }{ S . R } \\n \" ) print ( f \"If you see missed spam or false positives, you can submit a filter suggestion here: { F . YELLOW } TJoe.io/filter-feedback { S . R } \" ) if config [ 'auto_close' ] == False : input ( \" \\n Press Enter to return to main menu...\" ) return True elif config [ 'auto_close' ] == True : print ( \" \\n Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () print ( f \"Number of { S . BRIGHT }{ F . LIGHTRED_EX } Matched { S . R } Comments Found: { B . RED }{ F . WHITE } { str ( len ( current . matchedCommentsDict )) } { F . R }{ B . R }{ S . R } \" ) if current . spamThreadsDict : print ( f \" \\n Number of { S . BRIGHT }{ F . RED } Spam Bot Threads { S . R } Found: { S . BRIGHT }{ B . RED }{ F . WHITE } { str ( len ( current . spamThreadsDict )) } { F . R }{ B . R }{ S . R } \" ) if current . duplicateCommentsDict : print ( f \" \\n Number of { S . BRIGHT }{ F . LIGHTBLUE_EX } Non-Matched But Duplicate { S . R } Comments Found: { S . BRIGHT }{ F . WHITE }{ B . BLUE } { str ( len ( current . duplicateCommentsDict )) } { F . R }{ B . R }{ S . R } \" ) # If spam comments were found, continue if bypass == False : # Asks user if they want to save list of spam comments to a file print ( f \" \\n Comments ready to display. Also { F . LIGHTGREEN_EX } save a log file? { S . R } { B . GREEN }{ F . BLACK } Highly Recommended! { F . R }{ B . R }{ S . R } \" ) print ( f \" (It even allows you to { F . LIGHTGREEN_EX } restore { S . R } deleted comments later)\" ) loggingEnabled = choice ( f \"Save Log File (Recommended)?\" ) if loggingEnabled == None : return True # Return to main menu print ( \"\" ) # Prepare log file and json log file settings - Location and names jsonSettingsDict = {} if loggingEnabled == True : current , logMode , jsonSettingsDict = logging . prepare_logFile_settings ( current , config , miscData , jsonSettingsDict , filtersDict , bypass ) print ( \" \\n ----------------------------------------------------------------------------------------------------------------- \\n \" ) else : print ( \"Continuing without logging... \\n \" ) logMode = None jsonSettingsDict [ 'jsonLogging' ] = False # Prints list of spam comments if scanMode == \"communityPost\" : scanVideoID = communityPostID # Print comments and write to log files logFileContents , logMode = logging . print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode ) if loggingEnabled : logInfo = { 'logMode' : logMode , 'logFileContents' : logFileContents , 'jsonSettingsDict' : jsonSettingsDict , 'filtersDict' : filtersDict , } else : logInfo = None print ( f \" \\n { F . WHITE }{ B . RED } NOTE: { S . R } Check that all comments listed above are indeed spam.\" ) print ( f \" > If you see missed spam or false positives, you can submit a filter suggestion here: { F . YELLOW } TJoe.io/filter-feedback { S . R } \" ) print () ### ---------------- Decide whether to skip deletion ---------------- returnToMenu = False # Defaults deletionEnabled = False deletionMode = None # Should be changed later, but if missed it will default to heldForReview confirmDelete = None # If None, will later cause user to be asked to delete if moderator_mode == False : filterModesAllowedforNonOwners = [ \"AutoSmart\" , \"SensitiveSmart\" ] elif moderator_mode == True : filterModesAllowedforNonOwners = [ \"AutoSmart\" , \"SensitiveSmart\" , 'ID' ] # If user isn't channel owner and not using allowed filter mode, skip deletion if userNotChannelOwner == True and filterMode not in filterModesAllowedforNonOwners : confirmDelete = False deletionEnabled = False print ( f \" { F . LIGHTRED_EX } Error: { S . R } To prevent abuse, even in moderator mode, you can only use filter modes: Auto Smart, Sensitive Smart, and ID\" ) response = input ( \"Press Enter to continue, or type 'x' to return to Main Menu...\" ) if response . lower () == 'x' : return True # Test skip_deletion preference - If passes both, will either delete or ask user to delete if config [ 'skip_deletion' ] == True : print ( \" \\n Config setting skip_deletion enabled.\" ) returnToMenu = True elif config [ 'skip_deletion' ] != False : print ( \"Error Code C-3: Invalid value for 'skip_deletion' in config file. Must be 'True' or 'False'. Current Value: \" + str ( config [ 'skip_deletion' ])) print ( f \"Defaulting to ' { F . YELLOW } False { S . R } '\" ) input ( \" \\n Press Enter to continue...\" ) ### ---------------------------------------------------------------- ### ------------- Decide whether to ask before deleting ------------- # Using config to determine deletion type, block invalid settings elif config [ 'delete_without_reviewing' ] == False : deletionEnabled = \"Allowed\" if config [ 'removal_type' ] == \"reportspam\" or userNotChannelOwner == True : deletionMode = \"reportSpam\" elif config [ 'removal_type' ] == \"heldforreview\" : deletionMode = \"heldForReview\" elif config [ 'removal_type' ] == \"rejected\" : deletionMode = \"rejected\" else : print ( \"Error Code C-4: Invalid value for 'removal_type' in config file. Must be 'heldforreview', 'rejected', or 'reportSpam': \" + config [ 'removal_type' ]) input ( \" \\n Press Enter to exit...\" ) sys . exit () # User wants to automatically delete with no user intervention elif config [ 'delete_without_reviewing' ] == True : if userNotChannelOwner == True : confirmDelete = \"report\" deletionMode = \"reportSpam\" deletionEnabled = True elif config [ 'removal_type' ] == \"reportspam\" or config [ 'removal_type' ] == \"heldforreview\" : if filterMode == \"AutoSmart\" or filterMode == \"ID\" : deletionEnabled = True if config [ 'removal_type' ] == \"reportspam\" : deletionMode = \"reportSpam\" confirmDelete = \"report\" elif config [ 'removal_type' ] == \"heldforreview\" : deletionMode = \"heldForReview\" confirmDelete = \"hold\" else : # If non-permitted filter mode with delete_without_reviewing, will allow deletion, but now warns and requires usual confirmation prompt print ( \"Error Code C-5: 'delete_without_reviewing' is set to 'True' in config file. So only filter mode 'AutoSmart' allowed.. \\n \" ) print ( \"Next time use one of those filter modes, or set 'delete_without_reviewing' to 'False'.\" ) print ( \" > For this run, you will be asked to confirm removal of spam comments.\" ) input ( \" \\n Press Enter to continue...\" ) confirmDelete = None deletionEnabled = \"Allowed\" else : print ( \"Error Code C-6: 'delete_without_reviewing' is set to 'True' in config file. So 'removal_type' must be either 'heldForReview' or 'reportSpam'. \\n \" ) print ( \"Next time, either set one of those removal types, or set 'delete_without_reviewing' to 'False'.\" ) print ( \" > For this run, you will be asked to confirm removal of spam comments.\" ) input ( \" \\n Press Enter to continue...\" ) confirmDelete = None deletionEnabled = \"Allowed\" else : # Catch Invalid value print ( \"Error C-7: Invalid value for 'delete_without_reviewing' in config file. Must be 'True' or 'False': \" + config [ 'delete_without_reviewing' ]) input ( \" \\n Press Enter to exit...\" ) sys . exit () # Check if deletion is enabled, otherwise block and quit if returnToMenu == False and deletionEnabled != \"Allowed\" and deletionEnabled != True : print ( \" \\n The deletion functionality was not enabled. Cannot delete or report comments.\" ) print ( \"Possible Cause: You're scanning someone elses video with a non-supported filter mode. \\n \" ) print ( \"If you think this is a bug, you may report it on this project's GitHub page: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) if config [ 'auto_close' ] == True : print ( \" \\n Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( \" \\n Press Enter to return to main menu...\" ) return True ### ---------------- Set Up How To Handle Comments ---------------- rtfExclude = None plaintextExclude = None authorsToExcludeSet = set () commentIDExcludeSet = set () exclude = False excludedCommentsDict = {} excludeDisplayString = \"\" # If not skipped by config, ask user what to do if confirmDelete == None and returnToMenu == False : # Menu for deletion mode validResponses = [ 'delete' , 'report' , 'hold' , 'none' ] while confirmDelete == None or confirmDelete . lower () not in validResponses : # Title if current . errorOccurred == True : print ( f \" \\n --- { F . WHITE }{ B . RED } NOTE: { S . R } Options limited due to error during scanning ---\" ) if exclude == False : print ( f \" { F . YELLOW } How do you want to { F . BLACK }{ B . YELLOW } ALL { S . R }{ F . YELLOW } the listed comments above? { S . R } (Including Non-Matched Duplicates)\" ) elif exclude == True : print ( f \" { F . YELLOW } How do you want to handle the rest of the comments (not ones you { F . LIGHTGREEN_EX } excluded { F . YELLOW } )? { S . R } \" ) if userNotChannelOwner == True and moderator_mode == False : print ( f \" { F . GREEN } ~~ Not Your Channel Mode: Only Reporting is Possible ~~ { S . R } \" ) if userNotChannelOwner == True and moderator_mode == True : print ( f \" { F . GREEN } ~~ Moderator Mode: Reporting and Holding for Review is possible ~~ { S . R } \" ) # Exclude if exclude == False : print ( f \" > To { F . LIGHTGREEN_EX } exclude certain authors { S . R } : Type \\' { F . LIGHTGREEN_EX } exclude { S . R } \\' followed by a list of the numbers (or ranges of #'s) { F . LIGHTMAGENTA_EX } from the sample list { S . R } \" ) print ( \" > Example: exclude 1, 3-5, 7, 12-15\" ) print ( f \" > To { F . LIGHTGREEN_EX } only process certain authors { S . R } : Type \\' { F . LIGHTGREEN_EX } only { S . R } \\' followed by a list of the numbers (or ranges of #s) { F . LIGHTMAGENTA_EX } from the sample list { S . R } \" ) print ( \" > Example: only 1, 3-5, 7, 12-15 -- (Will effectively exclude the 'inverse' of the 'only' selected authors)\" ) # Delete & Hold if exclude == False : if userNotChannelOwner == False and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } delete ALL of the above comments { S . R } : Type ' { F . LIGHTRED_EX } DELETE { S . R } ', then hit Enter.\" ) if ( userNotChannelOwner == False or moderator_mode == True ) and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } move ALL comments above to 'Held For Review' in YT Studio { S . R } : Type ' { F . LIGHTRED_EX } HOLD { S . R } ', then hit Enter.\" ) elif exclude == True : if userNotChannelOwner == False and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } delete the rest of the comments { S . R } : Type ' { F . LIGHTRED_EX } DELETE { S . R } ', then hit Enter.\" ) if ( userNotChannelOwner == False or moderator_mode == True ) and current . errorOccurred == False : print ( f \" > To { F . LIGHTRED_EX } move rest of comments above to 'Held For Review' in YT Studio { S . R } : Type ' { F . LIGHTRED_EX } HOLD { S . R } ', then hit Enter.\" ) # Report & None if current . errorOccurred == False : print ( f \" > To { F . LIGHTCYAN_EX } report the comments for spam { S . R } , type ' { F . LIGHTCYAN_EX } REPORT { S . R } '.\" ) if loggingEnabled : print ( f \" > To do nothing and { F . YELLOW } only log { S . R } , type ' { F . YELLOW } NONE { S . R } '\" ) else : print ( f \" > To do { F . YELLOW } nothing { S . R } , type ' { F . YELLOW } NONE { S . R } '\" ) if config [ 'json_log' ] == True and config [ 'json_extra_data' ] == True and loggingEnabled : print ( f \" \\n { F . WHITE }{ B . BLUE } JSON NOTE: { S . R } You must proceed to write the JSON log file, even if you choose nothing\" ) # Take Entry confirmDelete = input ( \" \\n (Not Case Sensitive) Input: \" ) # Process Entry if confirmDelete . lower () == \"delete\" and userNotChannelOwner == False : deletionEnabled = True deletionMode = \"rejected\" elif confirmDelete . lower () == \"hold\" and ( userNotChannelOwner == False or moderator_mode == True ): deletionEnabled = True deletionMode = \"heldForReview\" elif confirmDelete . lower () == \"report\" : deletionEnabled = True deletionMode = \"reportSpam\" elif \"exclude\" in confirmDelete . lower () or \"only\" in confirmDelete . lower (): if \"exclude\" in confirmDelete . lower (): onlyBool = False elif \"only\" in confirmDelete . lower (): onlyBool = True if loggingEnabled : logInfo = { 'logMode' : logMode , 'logFileContents' : logFileContents , 'jsonSettingsDict' : jsonSettingsDict , 'filtersDict' : filtersDict } else : logInfo = None # This is very messy for now, will later consolidate the parameters current , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , rtfFormattedExcludes , plaintextFormattedExcludes = operations . exclude_authors ( current , config , miscData , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , excludeDisplayString , inputtedString = confirmDelete , logInfo = logInfo , only = onlyBool ) miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] = files . ingest_list_file ( whitelistPathWithName , keepCase = True ) exclude = True # Check that remaining comments list to remove is not empty if not current . matchedCommentsDict and not current . duplicateCommentsDict and not current . spamThreadsDict : print ( f \" \\n { F . YELLOW } All authors excluded, no comments left to remove! { S . R } \" ) input ( \" \\n Press Enter to log and/or return to main menu...\" ) returnToMenu = True break elif confirmDelete . lower () == \"none\" : returnToMenu = True else : print ( f \" \\n { F . LIGHTRED_EX } ERROR: { S . R } This entry was invalid or not allowed with current settings: { confirmDelete } \" ) input ( \" \\n Press Enter to try again...\" ) print ( \" \\n \" ) # Combine commentIDs from different match type dicts combinedCommentDict = dict ( current . matchedCommentsDict ) combinedCommentDict . update ( current . duplicateCommentsDict ) combinedCommentDict . update ( current . spamThreadsDict ) includeOtherAuthorComments = False banChoice = False if returnToMenu == False : # Set deletion mode friendly name if deletionMode == \"rejected\" : deletionModeFriendlyName = \"Removed\" elif deletionMode == \"heldForReview\" : deletionModeFriendlyName = \"Moved to 'Held for Review' Section\" elif deletionMode == \"reportSpam\" : deletionModeFriendlyName = \"Reported for spam\" # Set or choose ban mode, check if valid based on deletion mode if ( deletionMode == \"rejected\" or deletionMode == \"reportSpam\" or deletionMode == \"heldForReview\" ) and deletionEnabled == True and current . errorOccurred == False : proceedWithDeletion = True if config [ 'enable_ban' ] != \"ask\" : if config [ 'enable_ban' ] == False : pass elif config [ 'enable_ban' ] == True : print ( \"Error Code C-8: 'enable_ban' is set to 'True' in config file. Only possible config options are 'ask' or 'False' when using config. \\n \" ) input ( \"Press Enter to continue...\" ) else : print ( \"Error Code C-9: 'enable_ban' is set to an invalid value in config file. Only possible config options are 'ask' or 'False' when using config. \\n \" ) input ( \"Press Enter to continue...\" ) elif deletionMode == \"rejected\" : print ( \" \\n Also ban the spammer(s)?\" ) banChoice = choice ( f \" { F . YELLOW } Ban { S . R } the spammer(s) ?\" ) if banChoice == None : banChoice = False returnToMenu = True includeOtherAuthorComments = False if deletionMode == \"rejected\" or deletionMode == \"heldForReview\" : if config [ 'remove_all_author_comments' ] != 'ask' : includeOtherAuthorComments = config [ 'remove_all_author_comments' ] else : print ( f \" \\n Also remove { F . YELLOW } all other comments { S . R } from the selected authors, even if their other comments weren't matched?\" ) includeOtherAuthorComments = choice ( \"Choose:\" ) else : includeOtherAuthorComments = False else : proceedWithDeletion = False deletionModeFriendlyName = \"Nothing (Log Only)\" else : proceedWithDeletion = False deletionModeFriendlyName = \"Nothing (Log Only)\" # Print Final Logs if includeOtherAuthorComments == True : current = operations . get_all_author_comments ( current , config , miscData , current . allScannedCommentsDict ) combinedCommentDict . update ( current . otherCommentsByMatchedAuthorsDict ) if loggingEnabled == True : # Rewrites the contents of entire file, but now without the excluded comments in the list of comment IDs # Also if other non-matched comments by matched authors were added if exclude == True or current . otherCommentsByMatchedAuthorsDict : # This is just to redo the logFileContents to write later, not to actually write to log file logFileContents , logMode = logging . print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode , doWritePrint = False ) # Update logFile Contents after updating them logInfo [ 'logFileContents' ] = logFileContents logging . rewrite_log_file ( current , logInfo , combinedCommentDict ) print ( \"Updating log file, please wait...\" , end = \" \\r \" ) # Appends the excluded comment info to the log file that was just re-written if exclude == True : if logInfo [ 'logMode' ] == \"rtf\" : logging . write_rtf ( current . logFileName , str ( rtfFormattedExcludes )) elif logInfo [ 'logMode' ] == \"plaintext\" : logging . write_plaintext_log ( current . logFileName , str ( plaintextFormattedExcludes )) print ( \" \" ) print ( \" Finishing Log File...\" , end = \" \\r \" ) logging . write_log_completion_summary ( current , exclude , logMode , banChoice , deletionModeFriendlyName , includeOtherAuthorComments ) print ( \" \" ) # Write Json Log File if config [ 'json_log' ] == True and loggingEnabled and current . matchedCommentsDict : print ( \" \\n Writing JSON log file...\" ) if config [ 'json_extra_data' ] == True : if current . errorOccurred == False : jsonDataDict = logging . get_extra_json_data ( list ( current . matchSamplesDict . keys ()), jsonSettingsDict ) logging . write_json_log ( jsonSettingsDict , combinedCommentDict , jsonDataDict ) else : print ( f \" \\n { F . LIGHTRED_EX } NOTE: { S . R } Extra JSON data collection disabled due to error during scanning\" ) else : logging . write_json_log ( jsonSettingsDict , combinedCommentDict ) if returnToMenu == True : print ( \" \\n JSON Operation Finished.\" ) ### ---------------- Reporting / Deletion Begin ---------------- if returnToMenu == False : if proceedWithDeletion == True : operations . delete_found_comments ( list ( combinedCommentDict ), banChoice , deletionMode ) if deletionMode != \"reportSpam\" : if config [ 'check_deletion_success' ] == True : operations . check_deleted_comments ( list ( combinedCommentDict )) elif config [ 'check_deletion_success' ] == False : print ( \" \\n Skipped checking if deletion was successful. \\n \" ) if config [ 'auto_close' ] == True : print ( \" \\n Program Complete.\" ) print ( \"Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( f \" \\n Program { F . LIGHTGREEN_EX } Complete { S . R } . Press Enter to to return to main menu...\" ) return True elif current . errorOccurred == True : if config [ 'auto_close' ] == True : print ( \"Deletion disabled due to error during scanning. Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( f \" \\n Deletion disabled due to error during scanning. Press Enter to return to main menu...\" ) return True elif config [ 'skip_deletion' ] == True : if config [ 'auto_close' ] == True : print ( \" \\n Deletion disabled in config file.\" ) print ( \"Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : if confirmDelete != None and str ( confirmDelete . lower ()) == \"none\" : input ( f \" \\n Deletion { F . LIGHTCYAN_EX } Declined { S . R } . Press Enter to to return to main menu...\" ) else : input ( f \" \\n Deletion { F . LIGHTRED_EX } Cancelled { S . R } . Press Enter to to return to main menu...\" ) return True else : if config [ 'auto_close' ] == True : print ( \"Deletion Cancelled. Auto-close enabled in config. Exiting in 5 seconds...\" ) time . sleep ( 5 ) sys . exit () else : input ( f \" \\n Deletion { F . LIGHTRED_EX } Cancelled { S . R } . Press Enter to to return to main menu...\" ) return True # ------------------------------------------------------------------------------------------------------------------------------------------------- # ------------------------------------------------END PRIMARY INSTANCE----------------------------------------------------------------------------- # ------------------------------------------------------------------------------------------------------------------------------------------------- # Loops Entire Program to Main Menu continueRunning = True while continueRunning == True : continueRunning = primaryInstance ( miscData )","title":"main()"},{"location":"reference/Scripts/auth/","text":"CURRENTUSER module-attribute \u00b6 CURRENTUSER = None TOKEN_FILE_NAME module-attribute \u00b6 TOKEN_FILE_NAME = 'token.pickle' YOUTUBE module-attribute \u00b6 YOUTUBE = None ChannelIDError \u00b6 Bases: Exception Source code in Scripts/auth.py 112 113 class ChannelIDError ( Exception ): pass first_authentication \u00b6 first_authentication () Source code in Scripts/auth.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def first_authentication (): global YOUTUBE try : YOUTUBE = get_authenticated_service () # Create authentication object except JSONDecodeError as jx : print ( f \" { F . WHITE }{ B . RED } [!!!] Error: { S . R } \" + str ( jx )) print ( f \" \\n Did you make the client_secrets.json file yourself by { F . LIGHTRED_EX } copying and pasting into it { S . R } , instead of { F . LIGHTGREEN_EX } downloading it { S . R } ?\" ) print ( f \"You need to { F . YELLOW } download the json file directly from the google cloud dashboard { S . R } as shown in the instructions.\" ) print ( \"If you think this is a bug, you may report it on this project's GitHub page: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press Enter to Exit...\" ) sys . exit () except Exception as e : if \"invalid_grant\" in str ( e ): print ( f \" { F . YELLOW } [!] Invalid token { S . R } - Requires Re-Authentication\" ) os . remove ( TOKEN_FILE_NAME ) YOUTUBE = get_authenticated_service () else : print ( ' \\n ' ) traceback . print_exc () # Prints traceback print ( \"----------------\" ) print ( f \" { F . RED } [!!!] Error: { S . R } \" + str ( e )) print ( \"If you think this is a bug, you may report it on this project's GitHub page: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( f \" \\n Error Code A-1: { F . RED } Something went wrong during authentication. { S . R } { F . YELLOW } Try deleting the token.pickle file. { S . R } \\n Press Enter to exit...\" ) sys . exit () return YOUTUBE get_authenticated_service \u00b6 get_authenticated_service () Source code in Scripts/auth.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_authenticated_service (): global YOUTUBE CLIENT_SECRETS_FILE = 'client_secrets.json' YOUTUBE_READ_WRITE_SSL_SCOPE = [ 'https://www.googleapis.com/auth/youtube.force-ssl' ] API_SERVICE_NAME = 'youtube' API_VERSION = 'v3' DISCOVERY_SERVICE_URL = \"https://youtube.googleapis.com/$discovery/rest?version=v3\" # If don't specify discovery URL for build, works in python but fails when running as EXE # Check if client_secrets.json file exists, if not give error if not os . path . exists ( CLIENT_SECRETS_FILE ): # In case people don't have file extension viewing enabled, they may add a redundant json extension if os . path . exists ( f \" { CLIENT_SECRETS_FILE } .json\" ): CLIENT_SECRETS_FILE = CLIENT_SECRETS_FILE + \".json\" else : print ( f \" \\n ----- { F . WHITE }{ B . RED } [!] Error: { S . R } client_secrets.json file not found -----\" ) print ( f \" ----- Did you create a { F . YELLOW } Google Cloud Platform Project { S . R } to access the API? ----- \" ) print ( f \" > For instructions on how to get an API key, visit: { F . YELLOW } TJoe.io/api-setup { S . R } \" ) print ( f \" \\n > (Non-shortened Link: https://github.com/ThioJoe/YT-Spammer-Purge/wiki/Instructions:-Obtaining-an-API-Key)\" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () creds = None # The file token.pickle stores the user's access and refresh tokens, and is # created automatically when the authorization flow completes for the first time. if os . path . exists ( TOKEN_FILE_NAME ): creds = Credentials . from_authorized_user_file ( TOKEN_FILE_NAME , scopes = YOUTUBE_READ_WRITE_SSL_SCOPE ) # If there are no (valid) credentials available, make the user log in. if not creds or not creds . valid : if creds and creds . expired and creds . refresh_token : creds . refresh ( Request ()) else : print ( f \" \\n Please { F . YELLOW } login using the browser window { S . R } that opened just now. \\n \" ) flow = InstalledAppFlow . from_client_secrets_file ( CLIENT_SECRETS_FILE , scopes = YOUTUBE_READ_WRITE_SSL_SCOPE ) creds = flow . run_local_server ( port = 0 , authorization_prompt_message = \"Waiting for authorization. See message above.\" ) print ( f \" { F . GREEN } [OK] Authorization Complete. { S . R } \" ) # Save the credentials for the next run with open ( TOKEN_FILE_NAME , 'w' ) as token : token . write ( creds . to_json ()) YOUTUBE = build ( API_SERVICE_NAME , API_VERSION , credentials = creds , discoveryServiceUrl = DISCOVERY_SERVICE_URL ) return YOUTUBE get_current_user \u00b6 get_current_user ( config ) Source code in Scripts/auth.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def get_current_user ( config ): #Define fetch function so it can be re-used if issue and need to re-run it def fetch_user (): results = YOUTUBE . channels () . list ( part = \"snippet\" , #Can also add \"contentDetails\" or \"statistics\" mine = True , fields = \"items/id,items/snippet/title\" ) . execute () return results results = fetch_user () # Fetch the channel ID and title from the API response # Catch exceptions if problems getting info if len ( results ) == 0 : # Check if results are empty print ( \" \\n ----------------------------------------------------------------------------------------\" ) print ( f \" { F . YELLOW } Error Getting Current User { S . R } : The YouTube API responded, but did not provide a Channel ID.\" ) print ( f \" { F . CYAN } Known Possible Causes: { S . R } \" ) print ( \"> The client_secrets file does not match user authorized with token.pickle file.\" ) print ( \"> You are logging in with a Google account that does not have a YouTube channel created yet.\" ) print ( \"> When choosing the account to log into, you selected the option showing the Google Account's email address, which might not have a channel attached to it.\" ) input ( \" \\n Press Enter to try logging in again...\" ) os . remove ( TOKEN_FILE_NAME ) global YOUTUBE YOUTUBE = get_authenticated_service () results = fetch_user () # Try again try : channelID = results [ \"items\" ][ 0 ][ \"id\" ] IDCheck = validation . validate_channel_id ( channelID ) if IDCheck [ 0 ] == False : raise ChannelIDError try : channelTitle = results [ \"items\" ][ 0 ][ \"snippet\" ][ \"title\" ] # If channel ID was found, but not channel title/name except KeyError : print ( \"Error Getting Current User: Channel ID was found, but channel title was not retrieved. If this occurs again, try deleting 'token.pickle' file and re-running. If that doesn't work, consider filing a bug report on the GitHub project 'issues' page.\" ) print ( \"> NOTE: The program may still work - You can try continuing. Just check the channel ID is correct: \" + str ( channelID )) channelTitle = \"\" input ( \"Press Enter to Continue...\" ) pass except ChannelIDError : traceback . print_exc () print ( \" \\n Error: Still unable to get channel info. Big Bruh Moment. Try deleting token.pickle. The info above might help if you want to report a bug.\" ) print ( \"Note: A channel ID was retrieved but is invalid: \" + str ( channelID )) input ( \" \\n Press Enter to Exit...\" ) sys . exit () except KeyError : traceback . print_exc () print ( \" \\n Error: Still unable to get channel info. Big Bruh Moment. Try deleting token.pickle. The info above might help if you want to report a bug.\" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () if config == None : configMatch = None # Used only if channel ID is set in the config elif config [ 'your_channel_id' ] == \"ask\" : configMatch = None elif validation . validate_channel_id ( config [ 'your_channel_id' ])[ 0 ] == True : if config [ 'your_channel_id' ] == channelID : configMatch = True else : print ( \"Error: The channel ID in the config file appears to be valid, but does not match the channel ID of the currently logged in user.\" ) input ( \"Please check the config file. Press Enter to Exit...\" ) sys . exit () else : print ( \"Error: The channel ID in the config file appears to be invalid.\" ) input ( \"Please check the config file. Press Enter to Exit...\" ) sys . exit () return channelID , channelTitle , configMatch initialize \u00b6 initialize () Source code in Scripts/auth.py 22 23 def initialize (): pass remove_token \u00b6 remove_token () Source code in Scripts/auth.py 187 188 def remove_token (): os . remove ( TOKEN_FILE_NAME )","title":"auth"},{"location":"reference/Scripts/auth/#Scripts.auth.CURRENTUSER","text":"CURRENTUSER = None","title":"CURRENTUSER"},{"location":"reference/Scripts/auth/#Scripts.auth.TOKEN_FILE_NAME","text":"TOKEN_FILE_NAME = 'token.pickle'","title":"TOKEN_FILE_NAME"},{"location":"reference/Scripts/auth/#Scripts.auth.YOUTUBE","text":"YOUTUBE = None","title":"YOUTUBE"},{"location":"reference/Scripts/auth/#Scripts.auth.ChannelIDError","text":"Bases: Exception Source code in Scripts/auth.py 112 113 class ChannelIDError ( Exception ): pass","title":"ChannelIDError"},{"location":"reference/Scripts/auth/#Scripts.auth.first_authentication","text":"first_authentication () Source code in Scripts/auth.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def first_authentication (): global YOUTUBE try : YOUTUBE = get_authenticated_service () # Create authentication object except JSONDecodeError as jx : print ( f \" { F . WHITE }{ B . RED } [!!!] Error: { S . R } \" + str ( jx )) print ( f \" \\n Did you make the client_secrets.json file yourself by { F . LIGHTRED_EX } copying and pasting into it { S . R } , instead of { F . LIGHTGREEN_EX } downloading it { S . R } ?\" ) print ( f \"You need to { F . YELLOW } download the json file directly from the google cloud dashboard { S . R } as shown in the instructions.\" ) print ( \"If you think this is a bug, you may report it on this project's GitHub page: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press Enter to Exit...\" ) sys . exit () except Exception as e : if \"invalid_grant\" in str ( e ): print ( f \" { F . YELLOW } [!] Invalid token { S . R } - Requires Re-Authentication\" ) os . remove ( TOKEN_FILE_NAME ) YOUTUBE = get_authenticated_service () else : print ( ' \\n ' ) traceback . print_exc () # Prints traceback print ( \"----------------\" ) print ( f \" { F . RED } [!!!] Error: { S . R } \" + str ( e )) print ( \"If you think this is a bug, you may report it on this project's GitHub page: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( f \" \\n Error Code A-1: { F . RED } Something went wrong during authentication. { S . R } { F . YELLOW } Try deleting the token.pickle file. { S . R } \\n Press Enter to exit...\" ) sys . exit () return YOUTUBE","title":"first_authentication()"},{"location":"reference/Scripts/auth/#Scripts.auth.get_authenticated_service","text":"get_authenticated_service () Source code in Scripts/auth.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def get_authenticated_service (): global YOUTUBE CLIENT_SECRETS_FILE = 'client_secrets.json' YOUTUBE_READ_WRITE_SSL_SCOPE = [ 'https://www.googleapis.com/auth/youtube.force-ssl' ] API_SERVICE_NAME = 'youtube' API_VERSION = 'v3' DISCOVERY_SERVICE_URL = \"https://youtube.googleapis.com/$discovery/rest?version=v3\" # If don't specify discovery URL for build, works in python but fails when running as EXE # Check if client_secrets.json file exists, if not give error if not os . path . exists ( CLIENT_SECRETS_FILE ): # In case people don't have file extension viewing enabled, they may add a redundant json extension if os . path . exists ( f \" { CLIENT_SECRETS_FILE } .json\" ): CLIENT_SECRETS_FILE = CLIENT_SECRETS_FILE + \".json\" else : print ( f \" \\n ----- { F . WHITE }{ B . RED } [!] Error: { S . R } client_secrets.json file not found -----\" ) print ( f \" ----- Did you create a { F . YELLOW } Google Cloud Platform Project { S . R } to access the API? ----- \" ) print ( f \" > For instructions on how to get an API key, visit: { F . YELLOW } TJoe.io/api-setup { S . R } \" ) print ( f \" \\n > (Non-shortened Link: https://github.com/ThioJoe/YT-Spammer-Purge/wiki/Instructions:-Obtaining-an-API-Key)\" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () creds = None # The file token.pickle stores the user's access and refresh tokens, and is # created automatically when the authorization flow completes for the first time. if os . path . exists ( TOKEN_FILE_NAME ): creds = Credentials . from_authorized_user_file ( TOKEN_FILE_NAME , scopes = YOUTUBE_READ_WRITE_SSL_SCOPE ) # If there are no (valid) credentials available, make the user log in. if not creds or not creds . valid : if creds and creds . expired and creds . refresh_token : creds . refresh ( Request ()) else : print ( f \" \\n Please { F . YELLOW } login using the browser window { S . R } that opened just now. \\n \" ) flow = InstalledAppFlow . from_client_secrets_file ( CLIENT_SECRETS_FILE , scopes = YOUTUBE_READ_WRITE_SSL_SCOPE ) creds = flow . run_local_server ( port = 0 , authorization_prompt_message = \"Waiting for authorization. See message above.\" ) print ( f \" { F . GREEN } [OK] Authorization Complete. { S . R } \" ) # Save the credentials for the next run with open ( TOKEN_FILE_NAME , 'w' ) as token : token . write ( creds . to_json ()) YOUTUBE = build ( API_SERVICE_NAME , API_VERSION , credentials = creds , discoveryServiceUrl = DISCOVERY_SERVICE_URL ) return YOUTUBE","title":"get_authenticated_service()"},{"location":"reference/Scripts/auth/#Scripts.auth.get_current_user","text":"get_current_user ( config ) Source code in Scripts/auth.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def get_current_user ( config ): #Define fetch function so it can be re-used if issue and need to re-run it def fetch_user (): results = YOUTUBE . channels () . list ( part = \"snippet\" , #Can also add \"contentDetails\" or \"statistics\" mine = True , fields = \"items/id,items/snippet/title\" ) . execute () return results results = fetch_user () # Fetch the channel ID and title from the API response # Catch exceptions if problems getting info if len ( results ) == 0 : # Check if results are empty print ( \" \\n ----------------------------------------------------------------------------------------\" ) print ( f \" { F . YELLOW } Error Getting Current User { S . R } : The YouTube API responded, but did not provide a Channel ID.\" ) print ( f \" { F . CYAN } Known Possible Causes: { S . R } \" ) print ( \"> The client_secrets file does not match user authorized with token.pickle file.\" ) print ( \"> You are logging in with a Google account that does not have a YouTube channel created yet.\" ) print ( \"> When choosing the account to log into, you selected the option showing the Google Account's email address, which might not have a channel attached to it.\" ) input ( \" \\n Press Enter to try logging in again...\" ) os . remove ( TOKEN_FILE_NAME ) global YOUTUBE YOUTUBE = get_authenticated_service () results = fetch_user () # Try again try : channelID = results [ \"items\" ][ 0 ][ \"id\" ] IDCheck = validation . validate_channel_id ( channelID ) if IDCheck [ 0 ] == False : raise ChannelIDError try : channelTitle = results [ \"items\" ][ 0 ][ \"snippet\" ][ \"title\" ] # If channel ID was found, but not channel title/name except KeyError : print ( \"Error Getting Current User: Channel ID was found, but channel title was not retrieved. If this occurs again, try deleting 'token.pickle' file and re-running. If that doesn't work, consider filing a bug report on the GitHub project 'issues' page.\" ) print ( \"> NOTE: The program may still work - You can try continuing. Just check the channel ID is correct: \" + str ( channelID )) channelTitle = \"\" input ( \"Press Enter to Continue...\" ) pass except ChannelIDError : traceback . print_exc () print ( \" \\n Error: Still unable to get channel info. Big Bruh Moment. Try deleting token.pickle. The info above might help if you want to report a bug.\" ) print ( \"Note: A channel ID was retrieved but is invalid: \" + str ( channelID )) input ( \" \\n Press Enter to Exit...\" ) sys . exit () except KeyError : traceback . print_exc () print ( \" \\n Error: Still unable to get channel info. Big Bruh Moment. Try deleting token.pickle. The info above might help if you want to report a bug.\" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () if config == None : configMatch = None # Used only if channel ID is set in the config elif config [ 'your_channel_id' ] == \"ask\" : configMatch = None elif validation . validate_channel_id ( config [ 'your_channel_id' ])[ 0 ] == True : if config [ 'your_channel_id' ] == channelID : configMatch = True else : print ( \"Error: The channel ID in the config file appears to be valid, but does not match the channel ID of the currently logged in user.\" ) input ( \"Please check the config file. Press Enter to Exit...\" ) sys . exit () else : print ( \"Error: The channel ID in the config file appears to be invalid.\" ) input ( \"Please check the config file. Press Enter to Exit...\" ) sys . exit () return channelID , channelTitle , configMatch","title":"get_current_user()"},{"location":"reference/Scripts/auth/#Scripts.auth.initialize","text":"initialize () Source code in Scripts/auth.py 22 23 def initialize (): pass","title":"initialize()"},{"location":"reference/Scripts/auth/#Scripts.auth.remove_token","text":"remove_token () Source code in Scripts/auth.py 187 188 def remove_token (): os . remove ( TOKEN_FILE_NAME )","title":"remove_token()"},{"location":"reference/Scripts/community_downloader/","text":"SORT_BY_POPULAR module-attribute \u00b6 SORT_BY_POPULAR = 0 SORT_BY_RECENT module-attribute \u00b6 SORT_BY_RECENT = 1 USER_AGENT module-attribute \u00b6 USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36' YOUTUBE_COMMUNITY_TAB_URL module-attribute \u00b6 YOUTUBE_COMMUNITY_TAB_URL = 'https://www.youtube.com/channel/ {channel_id} /community' YOUTUBE_VIDEO_URL module-attribute \u00b6 YOUTUBE_VIDEO_URL = 'https://www.youtube.com/post/ {youtube_id} ' YT_CFG_RE module-attribute \u00b6 YT_CFG_RE = 'ytcfg \\\\ .set \\\\ s* \\\\ ( \\\\ s*({.+?}) \\\\ s* \\\\ ) \\\\ s*;' YT_INITIAL_DATA_RE module-attribute \u00b6 YT_INITIAL_DATA_RE = '(?:window \\\\ s* \\\\ [ \\\\ s*[\" \\\\\\' ]ytInitialData[\" \\\\\\' ] \\\\ s* \\\\ ]|ytInitialData) \\\\ s*= \\\\ s*({.+?}) \\\\ s*; \\\\ s*(?:var \\\\ s+meta|</script| \\\\ n)' ajax_request \u00b6 ajax_request ( session , endpoint , ytcfg , retries = 5 , sleep = 20 ) Source code in Scripts/community_downloader.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def ajax_request ( session , endpoint , ytcfg , retries = 5 , sleep = 20 ): url = 'https://www.youtube.com' + endpoint [ 'commandMetadata' ][ 'webCommandMetadata' ][ 'apiUrl' ] data = { 'context' : ytcfg [ 'INNERTUBE_CONTEXT' ], 'continuation' : endpoint [ 'continuationCommand' ][ 'token' ]} for _ in range ( retries ): response = session . post ( url , params = { 'key' : ytcfg [ 'INNERTUBE_API_KEY' ]}, json = data ) if response . status_code == 200 : return response . json () if response . status_code in [ 403 , 413 ]: return {} else : time . sleep ( sleep ) download_comments \u00b6 download_comments ( youtube_id , sort_by = SORT_BY_RECENT , language = None , sleep = 0.1 ) Source code in Scripts/community_downloader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 def download_comments ( youtube_id , sort_by = SORT_BY_RECENT , language = None , sleep = .1 ): session = requests . Session () session . headers [ 'User-Agent' ] = USER_AGENT response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) if 'uxe=' in response . request . url : session . cookies . set ( 'CONSENT' , 'YES+cb' , domain = '.youtube.com' ) response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) html = response . text ytcfg = json . loads ( regex_search ( html , YT_CFG_RE , default = '' )) if not ytcfg : return # Unable to extract configuration if language : ytcfg [ 'INNERTUBE_CONTEXT' ][ 'client' ][ 'hl' ] = language data = json . loads ( regex_search ( html , YT_INITIAL_DATA_RE , default = '' )) section = next ( search_dict ( data , 'itemSectionRenderer' ), None ) renderer = next ( search_dict ( section , 'continuationItemRenderer' ), None ) if section else None if not renderer : # Comments disabled? print ( \" \\n Error: 'continuationItemRenderer' not found in page data. Are comments disabled?\" ) return needs_sorting = sort_by != SORT_BY_POPULAR continuations = [ renderer [ 'continuationEndpoint' ]] while continuations : continuation = continuations . pop () response = ajax_request ( session , continuation , ytcfg ) if not response : break if list ( search_dict ( response , 'externalErrorMessage' )): raise RuntimeError ( 'Error returned from server: ' + next ( search_dict ( response , 'externalErrorMessage' ))) if needs_sorting : sort_menu = next ( search_dict ( response , 'sortFilterSubMenuRenderer' ), {}) . get ( 'subMenuItems' , []) if sort_by < len ( sort_menu ): continuations = [ sort_menu [ sort_by ][ 'serviceEndpoint' ]] needs_sorting = False continue raise RuntimeError ( 'Failed to set sorting' ) actions = list ( search_dict ( response , 'reloadContinuationItemsCommand' )) + \\ list ( search_dict ( response , 'appendContinuationItemsAction' )) for action in actions : for item in action . get ( 'continuationItems' , []): if action [ 'targetId' ] == 'comments-section' : # Process continuations for comments and replies. continuations [: 0 ] = [ ep for ep in search_dict ( item , 'continuationEndpoint' )] if action [ 'targetId' ] . startswith ( 'comment-replies-item' ) and 'continuationItemRenderer' in item : # Process the 'Show more replies' button continuations . append ( next ( search_dict ( item , 'buttonRenderer' ))[ 'command' ]) # Get total comments amount for post try : commentsHeader = list ( search_dict ( response , 'commentsHeaderRenderer' )) if commentsHeader : postCommentsText = commentsHeader [ 0 ][ 'countText' ][ 'runs' ][ 0 ][ 'text' ] . replace ( ',' , '' ) if 'k' in postCommentsText . lower (): totalPostComments = int ( postCommentsText . replace ( 'k' , '' )) * 1000 else : totalPostComments = int ( postCommentsText ) else : totalPostComments = None except ( KeyError , ValueError ): totalPostComments = - 1 for comment in reversed ( list ( search_dict ( response , 'commentRenderer' ))): # Yield instead of return, function called by for loop yield { 'cid' : comment [ 'commentId' ], 'text' : '' . join ([ c [ 'text' ] for c in comment [ 'contentText' ] . get ( 'runs' , [])]), 'time' : comment [ 'publishedTimeText' ][ 'runs' ][ 0 ][ 'text' ], 'author' : comment . get ( 'authorText' , {}) . get ( 'simpleText' , '' ), 'channel' : comment [ 'authorEndpoint' ][ 'browseEndpoint' ] . get ( 'browseId' , '' ), 'votes' : comment . get ( 'voteCount' , {}) . get ( 'simpleText' , '0' ), 'photo' : comment [ 'authorThumbnail' ][ 'thumbnails' ][ - 1 ][ 'url' ], 'heart' : next ( search_dict ( comment , 'isHearted' ), False ), # Extra data not specific to comment: 'totalPostComments' : totalPostComments } fetch_recent_community_posts \u00b6 fetch_recent_community_posts ( channel_id ) Source code in Scripts/community_downloader.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def fetch_recent_community_posts ( channel_id ): session = requests . Session () session . headers [ 'User-Agent' ] = USER_AGENT response = session . get ( YOUTUBE_COMMUNITY_TAB_URL . format ( channel_id = channel_id )) if 'uxe=' in response . request . url : session . cookies . set ( 'CONSENT' , 'YES+cb' , domain = '.youtube.com' ) response = session . get ( YOUTUBE_COMMUNITY_TAB_URL . format ( channel_id = channel_id )) html = response . text data = json . loads ( regex_search ( html , YT_INITIAL_DATA_RE , default = '' )) section = next ( search_dict ( data , 'itemSectionRenderer' ), None ) rawPosts = list ( search_dict ( section , 'backstagePostRenderer' )) recentPostsListofDicts = [] # Use list to keep in order - Puts post ID and sample of text into dictionary keypair, strips newlines # Gets the Post IDs and sample of post text for post in rawPosts : id = post [ 'postId' ] try : text = post [ 'contentText' ][ 'runs' ][ 0 ][ 'text' ] . strip () . replace ( ' \\n ' , '' ) . replace ( ' \\r ' , '' ) except KeyError : text = \"[No Text For This Post]\" recentPostsListofDicts . append ({ id : text }) recentPostsListofDicts . reverse () # Reverse list so newest posts are first return recentPostsListofDicts get_post_channel_url \u00b6 get_post_channel_url ( youtube_id ) Source code in Scripts/community_downloader.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_post_channel_url ( youtube_id ): session = requests . Session () session . headers [ 'User-Agent' ] = USER_AGENT response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) if 'uxe=' in response . request . url : session . cookies . set ( 'CONSENT' , 'YES+cb' , domain = '.youtube.com' ) response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) html = response . text ytcfg = json . loads ( regex_search ( html , YT_CFG_RE , default = '' )) if not ytcfg : return None # Unable to extract configuration data = json . loads ( regex_search ( html , YT_INITIAL_DATA_RE , default = '' )) try : channelURL = data [ 'microformat' ][ 'microformatDataRenderer' ][ 'urlCanonical' ] return channelURL except KeyError : return None main \u00b6 main ( communityPostID = None , limit = 1000 , sort = SORT_BY_RECENT , language = None , postScanProgressDict = None , postText = None ) Source code in Scripts/community_downloader.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def main ( communityPostID = None , limit = 1000 , sort = SORT_BY_RECENT , language = None , postScanProgressDict = None , postText = None ): if not communityPostID : raise ValueError ( 'you need to specify a Youtube ID' ) if postScanProgressDict : i = postScanProgressDict [ 'scanned' ] j = postScanProgressDict [ 'total' ] print ( f ' \\n\\n [ { i } / { j } ] Post ID: { communityPostID } ' ) else : print ( f ' \\n Loading Comments For Post: { communityPostID } ' ) if postText : print ( f \" > { F . LIGHTCYAN_EX } Post Text Sample: { S . R } { postText [ 0 : 90 ] } \" ) count = 0 #print(f' > Loaded {F.YELLOW}{count}{S.R} comment(s)', end='\\r') totalComments = 0 commentsDict = {} for comment in download_comments ( communityPostID , sort , language ): commentID = comment [ 'cid' ] commentText = comment [ 'text' ] authorName = comment [ 'author' ] authorChannelID = comment [ 'channel' ] commentsDict [ commentID ] = { 'commentText' : commentText , 'authorName' : authorName , 'authorChannelID' : authorChannelID } # Print Stats count += 1 # Doesn't return a number after first page, so don't update after that if comment [ 'totalPostComments' ]: totalComments = comment [ 'totalPostComments' ] if totalComments >= 0 : percent = (( count / totalComments ) * 100 ) progressStats = f \"[ { str ( count ) } / { str ( totalComments ) } ]\" . ljust ( 15 , \" \" ) + f \" ( { percent : .2f } %)\" print ( f ' > Retrieving Post Comments - { progressStats } ' , end = ' \\r ' ) else : print ( f ' > Loaded { F . YELLOW }{ count }{ S . R } comment(s)' , end = ' \\r ' ) if limit and count >= limit : print ( \" \" ) break print ( \" \" ) return commentsDict regex_search \u00b6 regex_search ( text , pattern , group = 1 , default = None ) Source code in Scripts/community_downloader.py 28 29 30 def regex_search ( text , pattern , group = 1 , default = None ): match = re . search ( pattern , text ) return match . group ( group ) if match else default search_dict \u00b6 search_dict ( partial , search_key ) Source code in Scripts/community_downloader.py 188 189 190 191 192 193 194 195 196 197 198 199 200 def search_dict ( partial , search_key ): stack = [ partial ] while stack : current_item = stack . pop () if isinstance ( current_item , dict ): for key , value in current_item . items (): if key == search_key : yield value else : stack . append ( value ) elif isinstance ( current_item , list ): for value in current_item : stack . append ( value )","title":"community_downloader"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.SORT_BY_POPULAR","text":"SORT_BY_POPULAR = 0","title":"SORT_BY_POPULAR"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.SORT_BY_RECENT","text":"SORT_BY_RECENT = 1","title":"SORT_BY_RECENT"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.USER_AGENT","text":"USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'","title":"USER_AGENT"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.YOUTUBE_COMMUNITY_TAB_URL","text":"YOUTUBE_COMMUNITY_TAB_URL = 'https://www.youtube.com/channel/ {channel_id} /community'","title":"YOUTUBE_COMMUNITY_TAB_URL"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.YOUTUBE_VIDEO_URL","text":"YOUTUBE_VIDEO_URL = 'https://www.youtube.com/post/ {youtube_id} '","title":"YOUTUBE_VIDEO_URL"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.YT_CFG_RE","text":"YT_CFG_RE = 'ytcfg \\\\ .set \\\\ s* \\\\ ( \\\\ s*({.+?}) \\\\ s* \\\\ ) \\\\ s*;'","title":"YT_CFG_RE"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.YT_INITIAL_DATA_RE","text":"YT_INITIAL_DATA_RE = '(?:window \\\\ s* \\\\ [ \\\\ s*[\" \\\\\\' ]ytInitialData[\" \\\\\\' ] \\\\ s* \\\\ ]|ytInitialData) \\\\ s*= \\\\ s*({.+?}) \\\\ s*; \\\\ s*(?:var \\\\ s+meta|</script| \\\\ n)'","title":"YT_INITIAL_DATA_RE"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.ajax_request","text":"ajax_request ( session , endpoint , ytcfg , retries = 5 , sleep = 20 ) Source code in Scripts/community_downloader.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def ajax_request ( session , endpoint , ytcfg , retries = 5 , sleep = 20 ): url = 'https://www.youtube.com' + endpoint [ 'commandMetadata' ][ 'webCommandMetadata' ][ 'apiUrl' ] data = { 'context' : ytcfg [ 'INNERTUBE_CONTEXT' ], 'continuation' : endpoint [ 'continuationCommand' ][ 'token' ]} for _ in range ( retries ): response = session . post ( url , params = { 'key' : ytcfg [ 'INNERTUBE_API_KEY' ]}, json = data ) if response . status_code == 200 : return response . json () if response . status_code in [ 403 , 413 ]: return {} else : time . sleep ( sleep )","title":"ajax_request()"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.download_comments","text":"download_comments ( youtube_id , sort_by = SORT_BY_RECENT , language = None , sleep = 0.1 ) Source code in Scripts/community_downloader.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 def download_comments ( youtube_id , sort_by = SORT_BY_RECENT , language = None , sleep = .1 ): session = requests . Session () session . headers [ 'User-Agent' ] = USER_AGENT response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) if 'uxe=' in response . request . url : session . cookies . set ( 'CONSENT' , 'YES+cb' , domain = '.youtube.com' ) response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) html = response . text ytcfg = json . loads ( regex_search ( html , YT_CFG_RE , default = '' )) if not ytcfg : return # Unable to extract configuration if language : ytcfg [ 'INNERTUBE_CONTEXT' ][ 'client' ][ 'hl' ] = language data = json . loads ( regex_search ( html , YT_INITIAL_DATA_RE , default = '' )) section = next ( search_dict ( data , 'itemSectionRenderer' ), None ) renderer = next ( search_dict ( section , 'continuationItemRenderer' ), None ) if section else None if not renderer : # Comments disabled? print ( \" \\n Error: 'continuationItemRenderer' not found in page data. Are comments disabled?\" ) return needs_sorting = sort_by != SORT_BY_POPULAR continuations = [ renderer [ 'continuationEndpoint' ]] while continuations : continuation = continuations . pop () response = ajax_request ( session , continuation , ytcfg ) if not response : break if list ( search_dict ( response , 'externalErrorMessage' )): raise RuntimeError ( 'Error returned from server: ' + next ( search_dict ( response , 'externalErrorMessage' ))) if needs_sorting : sort_menu = next ( search_dict ( response , 'sortFilterSubMenuRenderer' ), {}) . get ( 'subMenuItems' , []) if sort_by < len ( sort_menu ): continuations = [ sort_menu [ sort_by ][ 'serviceEndpoint' ]] needs_sorting = False continue raise RuntimeError ( 'Failed to set sorting' ) actions = list ( search_dict ( response , 'reloadContinuationItemsCommand' )) + \\ list ( search_dict ( response , 'appendContinuationItemsAction' )) for action in actions : for item in action . get ( 'continuationItems' , []): if action [ 'targetId' ] == 'comments-section' : # Process continuations for comments and replies. continuations [: 0 ] = [ ep for ep in search_dict ( item , 'continuationEndpoint' )] if action [ 'targetId' ] . startswith ( 'comment-replies-item' ) and 'continuationItemRenderer' in item : # Process the 'Show more replies' button continuations . append ( next ( search_dict ( item , 'buttonRenderer' ))[ 'command' ]) # Get total comments amount for post try : commentsHeader = list ( search_dict ( response , 'commentsHeaderRenderer' )) if commentsHeader : postCommentsText = commentsHeader [ 0 ][ 'countText' ][ 'runs' ][ 0 ][ 'text' ] . replace ( ',' , '' ) if 'k' in postCommentsText . lower (): totalPostComments = int ( postCommentsText . replace ( 'k' , '' )) * 1000 else : totalPostComments = int ( postCommentsText ) else : totalPostComments = None except ( KeyError , ValueError ): totalPostComments = - 1 for comment in reversed ( list ( search_dict ( response , 'commentRenderer' ))): # Yield instead of return, function called by for loop yield { 'cid' : comment [ 'commentId' ], 'text' : '' . join ([ c [ 'text' ] for c in comment [ 'contentText' ] . get ( 'runs' , [])]), 'time' : comment [ 'publishedTimeText' ][ 'runs' ][ 0 ][ 'text' ], 'author' : comment . get ( 'authorText' , {}) . get ( 'simpleText' , '' ), 'channel' : comment [ 'authorEndpoint' ][ 'browseEndpoint' ] . get ( 'browseId' , '' ), 'votes' : comment . get ( 'voteCount' , {}) . get ( 'simpleText' , '0' ), 'photo' : comment [ 'authorThumbnail' ][ 'thumbnails' ][ - 1 ][ 'url' ], 'heart' : next ( search_dict ( comment , 'isHearted' ), False ), # Extra data not specific to comment: 'totalPostComments' : totalPostComments }","title":"download_comments()"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.fetch_recent_community_posts","text":"fetch_recent_community_posts ( channel_id ) Source code in Scripts/community_downloader.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def fetch_recent_community_posts ( channel_id ): session = requests . Session () session . headers [ 'User-Agent' ] = USER_AGENT response = session . get ( YOUTUBE_COMMUNITY_TAB_URL . format ( channel_id = channel_id )) if 'uxe=' in response . request . url : session . cookies . set ( 'CONSENT' , 'YES+cb' , domain = '.youtube.com' ) response = session . get ( YOUTUBE_COMMUNITY_TAB_URL . format ( channel_id = channel_id )) html = response . text data = json . loads ( regex_search ( html , YT_INITIAL_DATA_RE , default = '' )) section = next ( search_dict ( data , 'itemSectionRenderer' ), None ) rawPosts = list ( search_dict ( section , 'backstagePostRenderer' )) recentPostsListofDicts = [] # Use list to keep in order - Puts post ID and sample of text into dictionary keypair, strips newlines # Gets the Post IDs and sample of post text for post in rawPosts : id = post [ 'postId' ] try : text = post [ 'contentText' ][ 'runs' ][ 0 ][ 'text' ] . strip () . replace ( ' \\n ' , '' ) . replace ( ' \\r ' , '' ) except KeyError : text = \"[No Text For This Post]\" recentPostsListofDicts . append ({ id : text }) recentPostsListofDicts . reverse () # Reverse list so newest posts are first return recentPostsListofDicts","title":"fetch_recent_community_posts()"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.get_post_channel_url","text":"get_post_channel_url ( youtube_id ) Source code in Scripts/community_downloader.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def get_post_channel_url ( youtube_id ): session = requests . Session () session . headers [ 'User-Agent' ] = USER_AGENT response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) if 'uxe=' in response . request . url : session . cookies . set ( 'CONSENT' , 'YES+cb' , domain = '.youtube.com' ) response = session . get ( YOUTUBE_VIDEO_URL . format ( youtube_id = youtube_id )) html = response . text ytcfg = json . loads ( regex_search ( html , YT_CFG_RE , default = '' )) if not ytcfg : return None # Unable to extract configuration data = json . loads ( regex_search ( html , YT_INITIAL_DATA_RE , default = '' )) try : channelURL = data [ 'microformat' ][ 'microformatDataRenderer' ][ 'urlCanonical' ] return channelURL except KeyError : return None","title":"get_post_channel_url()"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.main","text":"main ( communityPostID = None , limit = 1000 , sort = SORT_BY_RECENT , language = None , postScanProgressDict = None , postText = None ) Source code in Scripts/community_downloader.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def main ( communityPostID = None , limit = 1000 , sort = SORT_BY_RECENT , language = None , postScanProgressDict = None , postText = None ): if not communityPostID : raise ValueError ( 'you need to specify a Youtube ID' ) if postScanProgressDict : i = postScanProgressDict [ 'scanned' ] j = postScanProgressDict [ 'total' ] print ( f ' \\n\\n [ { i } / { j } ] Post ID: { communityPostID } ' ) else : print ( f ' \\n Loading Comments For Post: { communityPostID } ' ) if postText : print ( f \" > { F . LIGHTCYAN_EX } Post Text Sample: { S . R } { postText [ 0 : 90 ] } \" ) count = 0 #print(f' > Loaded {F.YELLOW}{count}{S.R} comment(s)', end='\\r') totalComments = 0 commentsDict = {} for comment in download_comments ( communityPostID , sort , language ): commentID = comment [ 'cid' ] commentText = comment [ 'text' ] authorName = comment [ 'author' ] authorChannelID = comment [ 'channel' ] commentsDict [ commentID ] = { 'commentText' : commentText , 'authorName' : authorName , 'authorChannelID' : authorChannelID } # Print Stats count += 1 # Doesn't return a number after first page, so don't update after that if comment [ 'totalPostComments' ]: totalComments = comment [ 'totalPostComments' ] if totalComments >= 0 : percent = (( count / totalComments ) * 100 ) progressStats = f \"[ { str ( count ) } / { str ( totalComments ) } ]\" . ljust ( 15 , \" \" ) + f \" ( { percent : .2f } %)\" print ( f ' > Retrieving Post Comments - { progressStats } ' , end = ' \\r ' ) else : print ( f ' > Loaded { F . YELLOW }{ count }{ S . R } comment(s)' , end = ' \\r ' ) if limit and count >= limit : print ( \" \" ) break print ( \" \" ) return commentsDict","title":"main()"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.regex_search","text":"regex_search ( text , pattern , group = 1 , default = None ) Source code in Scripts/community_downloader.py 28 29 30 def regex_search ( text , pattern , group = 1 , default = None ): match = re . search ( pattern , text ) return match . group ( group ) if match else default","title":"regex_search()"},{"location":"reference/Scripts/community_downloader/#Scripts.community_downloader.search_dict","text":"search_dict ( partial , search_key ) Source code in Scripts/community_downloader.py 188 189 190 191 192 193 194 195 196 197 198 199 200 def search_dict ( partial , search_key ): stack = [ partial ] while stack : current_item = stack . pop () if isinstance ( current_item , dict ): for key , value in current_item . items (): if key == search_key : yield value else : stack . append ( value ) elif isinstance ( current_item , list ): for value in current_item : stack . append ( value )","title":"search_dict()"},{"location":"reference/Scripts/files/","text":"check_existing_save \u00b6 check_existing_save () Source code in Scripts/files.py 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 def check_existing_save (): relativeSaveDir = os . path . join ( RESOURCES_FOLDER_NAME , \"Removal_List_Progress\" ) savesList = list () if os . path . isdir ( relativeSaveDir ): fileList = list () for ( _ , _ , filenames ) in os . walk ( relativeSaveDir ): fileList . extend ( filenames ) if len ( fileList ) > 0 : for fileName in fileList : if fileName [ - 5 :] == \".save\" : savesList . extend ([ fileName ]) return savesList check_for_update \u00b6 check_for_update ( currentVersion , updateReleaseChannel , silentCheck = False ) Source code in Scripts/files.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 def check_for_update ( currentVersion , updateReleaseChannel , silentCheck = False ): isUpdateAvailable = False print ( \" \\n Getting info about latest updates...\" ) try : if updateReleaseChannel == \"stable\" : response = requests . get ( \"https://api.github.com/repos/ThioJoe/YT-Spammer-Purge/releases/latest\" ) elif updateReleaseChannel == \"all\" : response = requests . get ( \"https://api.github.com/repos/ThioJoe/YT-Spammer-Purge/releases\" ) if response . status_code != 200 : if response . status_code == 403 : if silentCheck == False : print ( f \" \\n { B . RED }{ F . WHITE } Error [U-4]: { S . R } Got an 403 (ratelimit_reached) when attempting to check for update.\" ) print ( f \"This means you have been { F . YELLOW } rate limited by github.com { S . R } . Please try again in a while. \\n \" ) else : print ( f \" \\n { B . RED }{ F . WHITE } Error [U-4]: { S . R } Got an 403 (ratelimit_reached) when attempting to check for update.\" ) return None else : if silentCheck == False : print ( f \" { B . RED }{ F . WHITE } Error [U-3]: { S . R } Got non 200 status code (got: { response . status_code } ) when attempting to check for update. \\n \" ) print ( f \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) else : print ( f \" { B . RED }{ F . WHITE } Error [U-3]: { S . R } Got non 200 status code (got: { response . status_code } ) when attempting to check for update. \\n \" ) return None else : # assume 200 response (good) if updateReleaseChannel == \"stable\" : latestVersion = response . json ()[ \"name\" ] isBeta = False elif updateReleaseChannel == \"all\" : latestVersion = response . json ()[ 0 ][ \"name\" ] isBeta = response . json ()[ 0 ][ \"prerelease\" ] except OSError as ox : if \"WinError 10013\" in str ( ox ): print ( f \" { B . RED }{ F . WHITE } WinError 10013: { S . R } The OS blocked the connection to GitHub. Check your firewall settings. \\n \" ) else : print ( f \" { B . RED }{ F . WHITE } Unknown OSError { S . R } Error occurred while checking for updates \\n \" ) return None except Exception as e : if silentCheck == False : print ( e + \" \\n \" ) print ( f \" { B . RED }{ F . WHITE } Error [Code U-1]: { S . R } Problem while checking for updates. See above error for more details. \\n \" ) print ( \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) elif silentCheck == True : print ( f \" { B . RED }{ F . WHITE } Error [Code U-1]: { S . R } Unknown problem while checking for updates. See above error for more details. \\n \" ) return None if parse_version ( latestVersion ) > parse_version ( currentVersion ): if isBeta == True : isUpdateAvailable = \"beta\" else : isUpdateAvailable = True if silentCheck == False : print ( \"------------------------------------------------------------------------------------------\" ) if isBeta == True : print ( f \" { F . YELLOW } A new { F . LIGHTGREEN_EX } beta { F . YELLOW } version { S . R } is available! Visit { F . YELLOW } TJoe.io/latest { S . R } to see what's new.\" ) else : print ( f \" A { F . LIGHTGREEN_EX } new version { S . R } is available! Visit { F . YELLOW } TJoe.io/latest { S . R } to see what's new.\" ) print ( f \" > Current Version: { currentVersion } \" ) print ( f \" > Latest Version: { F . LIGHTGREEN_EX }{ latestVersion }{ S . R } \" ) if isBeta == True : print ( \"(To stop receiving beta releases, change the 'release_channel' setting in the config file)\" ) print ( \"------------------------------------------------------------------------------------------\" ) userChoice = choice ( \"Update Now?\" ) if userChoice == True : if sys . platform == 'win32' or sys . platform == 'win64' : print ( f \" \\n > { F . LIGHTCYAN_EX } Downloading Latest Version... { S . R } \" ) if updateReleaseChannel == \"stable\" : jsondata = json . dumps ( response . json ()[ \"assets\" ]) elif updateReleaseChannel == \"all\" : jsondata = json . dumps ( response . json ()[ 0 ][ \"assets\" ]) dict_json = json . loads ( jsondata ) # Get files in release, get exe and hash info i , j , k = 0 , 0 , 0 # i = index of all, j = index of exe, k = index of hash for asset in dict_json : i += 1 name = str ( asset [ 'name' ]) if '.exe' in name . lower (): filedownload = requests . get ( dict_json [ 0 ][ 'browser_download_url' ], stream = True ) j += 1 # Count number of exe files in release, in case future has multiple exe's, can cause warning if '.sha256' in name . lower (): #First removes .sha256 file extension, then removes all non-alphanumeric characters downloadHashSHA256 = re . sub ( r '[^a-zA-Z0-9]' , '' , name . lower () . replace ( '.sha256' , '' )) k += 1 ignoreHash = False # Validate Retrieved Info if j > 1 : # More than one exe file in release print ( f \" { F . YELLOW } Warning! { S . R } Multiple exe files found in release. You must be updating from the future when that was not anticipated.\" ) print ( \"You should instead manually download the latest version from: https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) print ( \"You can try continuing anyway, but it might not be successful, or might download the wrong exe file.\" ) input ( \" \\n Press enter to continue...\" ) elif j == 0 : # No exe file in release print ( f \" { F . LIGHTRED_EX } Warning! { S . R } No exe file found in release. You'll have to manually download the latest version from:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) return False if k == 0 : # No hash file in release print ( f \" { F . YELLOW } Warning! { S . R } No verification sha256 hash found in release. If download fails, you can manually download latest version here:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) input ( \" \\n Press Enter to try to continue...\" ) ignoreHash = True elif k > 0 and k != j : print ( f \" { F . YELLOW } Warning! { S . R } Too many or too few sha256 files found in release. If download fails, you should manually download latest version here:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) input ( \" \\n Press Enter to try to continue...\" ) # Get and Set Download Info total_size_in_bytes = int ( filedownload . headers . get ( 'content-length' , 0 )) block_size = 1048576 #1 MiB in bytes downloadFileName = dict_json [ 0 ][ 'name' ] # Check if file exists already, ask to overwrite if it does if os . path . exists ( downloadFileName ): print ( f \" \\n { B . RED }{ F . WHITE } WARNING! { S . R } ' { F . YELLOW }{ downloadFileName }{ S . R } ' file already exists. This would overwrite the existing file.\" ) confirm = choice ( \"Overwrite this existing file?\" ) if confirm == True : try : os . remove ( downloadFileName ) except : traceback . print_exc () print ( f \" \\n { F . LIGHTRED_EX } Error F-6: { S . R } Problem deleting existing existing file! Check if it's gone, or delete it yourself, then try again.\" ) print ( \"The info above may help if it's a bug, which you can report here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press enter to Exit...\" ) sys . exit () elif confirm == False or confirm == None : return False # Download File with open ( downloadFileName , 'wb' ) as file : numProgressBars = 30 for data in filedownload . iter_content ( block_size ): progress = os . stat ( downloadFileName ) . st_size / total_size_in_bytes * numProgressBars print ( f \" { F . LIGHTGREEN_EX } <[ { F . LIGHTCYAN_EX } \" + '=' * round ( progress ) + ' ' * ( numProgressBars - round ( progress )) + f \" { F . LIGHTGREEN_EX } ]> { S . R } \\r \" , end = \"\" ) #Print Progress bar file . write ( data ) print ( f \" \\n > { F . LIGHTCYAN_EX } Verifying Download Integrity... { S . R } \" ) # Verify Download Size if os . stat ( downloadFileName ) . st_size == total_size_in_bytes : pass elif total_size_in_bytes != 0 and os . stat ( downloadFileName ) . st_size != total_size_in_bytes : os . remove ( downloadFileName ) print ( f \" \\n > { F . RED } File did not fully download. Please try again later.\" ) return False elif total_size_in_bytes == 0 : print ( \"Something is wrong with the download on the remote end. You should manually download latest version here:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) # Verify hash if ignoreHash == False : if downloadHashSHA256 == hashlib . sha256 ( open ( downloadFileName , 'rb' ) . read ()) . hexdigest () . lower (): pass else : os . remove ( downloadFileName ) print ( f \" \\n > { F . RED } Hash did not match. Please try again later.\" ) print ( \"Or download the latest version manually from here: https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) return False # Print Success print ( f \" \\n > Download Completed: { F . LIGHTGREEN_EX }{ downloadFileName }{ S . R } \" ) if isBeta == False : print ( \" \\n You can now delete the old version. (Or keep it around in case you encounter any issues with the new version)\" ) else : print ( f \" \\n { F . LIGHTYELLOW_EX } NOTE: { S . R } Because this is a { F . CYAN } beta release { S . R } , you should keep the old version around in case you encounter any issues\" ) print ( f \" > And don't forget to report any problems you encounter here: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () elif platform . system () == \"Linux\" : # Current working directory cwd = os . getcwd () # what we want the tar file to be called on the system tarFileName = \"yt-spammer.tar.gz\" # Name of this file # Temp folder for update stagingFolder = \"temp\" # Fetch the latest update print ( f \" \\n > Downloading version: { F . GREEN }{ latestVersion }{ S . R } \" ) url = f 'https://codeload.github.com/ThioJoe/YT-Spammer-Purge/tar.gz/refs/tags/v { latestVersion } ' r = requests . get ( url , stream = True ) if ( r . status_code == 200 ): with open ( tarFileName , 'wb' ) as file : for chunk in r . iter_content ( chunk_size = 1048576 ): if chunk : file . write ( chunk ) else : print ( \"Downloading of new version failed!\" ) print ( f \" \\n > { F . RED } Error: { S . R } GitHub returned a non 200 status code while trying to download newer version. \\n Status returned: { r . status_code } \" ) input ( \"Press Enter to Exit...\" ) sys . exit () # Extract the tar file and delete it print ( \" \\n > Extracting...\" ) with tarfile . open ( tarFileName ) as file : file . extractall ( f './ { stagingFolder } ' ) os . remove ( tarFileName ) print ( f \"> Installing...\" ) # Retrieve the name of the folder containing the main file, we are assuming there will always be only one folder here extraFolderPath = os . listdir ( f \"./ { stagingFolder } \" ) # If there happens to be more then one folder if ( len ( extraFolderPath ) != 1 ): print ( f \" \\n > { F . RED } Error: { S . R } more then one folder in { stagingFolder } ! Please make a bug report.\" ) print ( f \" \\n { F . RED } Aborting Update! { S . R } \" ) print ( \" \\n > Cleaning up...\" ) rmtree ( stagingFolder ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () else : extraFolderPath = f \" { cwd } / { stagingFolder } / { extraFolderPath [ 0 ] } \" for file_name in os . listdir ( extraFolderPath ): if os . path . exists ( file_name ): try : os . remove ( file_name ) except IsADirectoryError : rmtree ( file_name ) move ( f \" { extraFolderPath } / { file_name } \" , f \" { cwd } / { file_name } \" ) rmtree ( stagingFolder ) print ( f \" \\n > Update completed: { currentVersion } ==> { F . GREEN }{ latestVersion }{ S . R } \" ) print ( \"> Restart the script to apply the update.\" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () else : print ( f \"> { F . RED } Error: { S . R } You are using an unsupported OS for the autoupdater (macos). \\n This updater only supports Windows and Linux (right now). Feel free to get the files from github: https://github.com/ThioJoe/YT-Spammer-Purge\" ) return False elif userChoice == \"False\" or userChoice == None : return False elif silentCheck == True : return isUpdateAvailable elif parse_version ( latestVersion ) == parse_version ( currentVersion ): if silentCheck == False : print ( f \" \\n You have the { F . LIGHTGREEN_EX } latest { S . R } version: { F . LIGHTGREEN_EX } \" + currentVersion ) return False else : if silentCheck == False : print ( \" \\n No newer release available - Your Version: \" + currentVersion + \" -- Latest Version: \" + latestVersion ) return False check_lists_update \u00b6 check_lists_update ( spamListDict , silentCheck = False ) Source code in Scripts/files.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def check_lists_update ( spamListDict , silentCheck = False ): SpamListFolder = spamListDict [ 'Meta' ][ 'SpamListFolder' ] currentListVersion = spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestLocalVersion' ] def update_last_checked (): currentDate = datetime . today () . strftime ( '%Y.%m. %d .%H.%M' ) #Update Dictionary with latest release gotten from API spamListDict [ 'Meta' ][ 'VersionInfo' ] . update ({ 'LatestLocalVersion' : latestRelease }) spamListDict [ 'Meta' ][ 'VersionInfo' ] . update ({ 'LastChecked' : currentDate }) # Prepare data for json file update, so only have to check once a day automatically newJsonContents = json . dumps ({ 'LatestRelease' : latestRelease , 'LastChecked' : currentDate }) with open ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ], 'w' , encoding = \"utf-8\" ) as file : json . dump ( newJsonContents , file , indent = 4 ) if silentCheck == False : print ( \" \\n Checking for updates to spam lists...\" ) if os . path . isdir ( SpamListFolder ): pass else : try : os . mkdir ( SpamListFolder ) except : print ( \"Error: Could not create folder. Try creating a folder called 'spam_lists' to update the spam lists.\" ) try : response = requests . get ( \"https://api.github.com/repos/ThioJoe/YT-Spam-Domains-List/releases/latest\" ) if response . status_code != 200 : if response . status_code == 403 : if silentCheck == False : print ( f \" \\n { B . RED }{ F . WHITE } Error [U-4L]: { S . R } Got an 403 (ratelimit_reached) when attempting to check for spam list update.\" ) print ( f \"This means you have been { F . YELLOW } rate limited by github.com { S . R } . Please try again in a while. \\n \" ) return False else : return spamListDict else : if silentCheck == False : print ( f \" { B . RED }{ F . WHITE } Error [U-3L]: { S . R } Got non 200 status code (got: { response . status_code } ) when attempting to check for spam list update. \\n \" ) print ( f \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) if silentCheck == False : return False else : return spamListDict latestRelease = response . json ()[ \"tag_name\" ] except OSError as ox : if silentCheck == True : return spamListDict else : if \"WinError 10013\" in str ( ox ): print ( f \" { B . RED }{ F . WHITE } WinError 10013: { S . R } The OS blocked the connection to GitHub. Check your firewall settings. \\n \" ) return False except : if silentCheck == True : return spamListDict else : print ( \"Error: Could not get latest release info from GitHub. Please try again later.\" ) return False # If update available if currentListVersion == None or ( parse_version ( latestRelease ) > parse_version ( currentListVersion )): print ( \" \\n > A new spam list update is available. Downloading...\" ) fileName = response . json ()[ \"assets\" ][ 0 ][ 'name' ] total_size_in_bytes = response . json ()[ \"assets\" ][ 0 ][ 'size' ] downloadFilePath = SpamListFolder + fileName downloadURL = response . json ()[ \"assets\" ][ 0 ][ 'browser_download_url' ] filedownload = getRemoteFile ( downloadURL , stream = True ) # These headers required to get correct file size block_size = 1048576 #1 MiB in bytes with open ( downloadFilePath , 'wb' ) as file : for data in filedownload . iter_content ( block_size ): file . write ( data ) if os . stat ( downloadFilePath ) . st_size == total_size_in_bytes : # Unzip files into folder and delete zip file attempts = 0 print ( \"Extracting updated lists...\" ) # While loop continues until file no longer exists, or too many errors while True : try : attempts += 1 time . sleep ( 0.5 ) with zipfile . ZipFile ( downloadFilePath , \"r\" ) as zip_ref : zip_ref . extractall ( SpamListFolder ) os . remove ( downloadFilePath ) except PermissionError as e : if attempts <= 10 : continue else : traceback . print_exc () print ( f \" \\n > { F . RED } Error: { S . R } The zip file containing the spam lists was downloaded, but there was a problem extracting the files because of a permission error. \" ) print ( f \"This can happen if an antivirus takes a while to scan the file. You may need to manually extract the zip file.\" ) input ( \" \\n Press enter to Continue anyway...\" ) break # THIS MEANS SUCCESS, the zip file was deleted after extracting, so returns except FileNotFoundError : update_last_checked () return spamListDict elif total_size_in_bytes != 0 and os . stat ( downloadFilePath ) . st_size != total_size_in_bytes : os . remove ( downloadFilePath ) print ( f \" > { F . RED } File did not fully download. Please try again later. \\n \" ) return spamListDict else : update_last_checked () return spamListDict check_update_config_file \u00b6 check_update_config_file ( newVersion , existingConfig , configFileName ) Source code in Scripts/files.py 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 def check_update_config_file ( newVersion , existingConfig , configFileName ): backupDestinationFolder = os . path . join ( RESOURCES_FOLDER_NAME , \"User_Config_Backups\" ) try : existingConfigVersion = int ( existingConfig [ 'config_version' ]) if existingConfigVersion < newVersion : configOutOfDate = True else : configOutOfDate = False except : configOutOfDate = True if configOutOfDate == True : print ( f \" \\n { F . YELLOW } WARNING! { S . R } Your config file is { F . YELLOW } out of date { S . R } . \" ) print ( f \" > Program will { F . LIGHTGREEN_EX } update your config { S . R } now, { F . LIGHTGREEN_EX } back up the old file { S . R } , and { F . LIGHTGREEN_EX } copy your settings over { S . R } )\" ) input ( \" \\n Press Enter to update config file...\" ) else : return existingConfig # If user config file exists, keep path. Otherwise use default config file path if os . path . exists ( configFileName ): pass else : print ( \"No existing config file found!\" ) return False # Load data of old config file with open ( configFileName , 'r' , encoding = \"utf-8\" ) as oldFile : oldConfigData = oldFile . readlines () oldFile . close () # Rename config to backup and copy to backup folder if not os . path . exists ( backupDestinationFolder ): os . mkdir ( backupDestinationFolder ) backupConfigFileName = f \" { configFileName } .backup_v { existingConfigVersion } \" backupNameAndPath = os . path . join ( backupDestinationFolder , backupConfigFileName ) if os . path . isfile ( backupNameAndPath ): print ( \"Existing backup config file found. Random number will be added to new backup file name.\" ) while os . path . isfile ( backupNameAndPath ): backupConfigFileName = backupConfigFileName + \"_\" + str ( randrange ( 999 )) backupNameAndPath = os . path . join ( backupDestinationFolder , backupConfigFileName ) # Attempt to copy backup to backup folder, otherwise just rename try : copyfile ( configFileName , os . path . abspath ( backupNameAndPath )) print ( f \" \\n Old config file renamed to { F . CYAN }{ backupConfigFileName }{ S . R } and placed in { F . CYAN }{ backupDestinationFolder }{ S . R } \" ) except : os . rename ( configFileName , backupConfigFileName ) print ( f \" \\n Old config file renamed to { F . CYAN }{ backupConfigFileName }{ S . R } . Note: Backup file could not be moved to backup folder, so it was just renamed.\" ) # Creates new config file from default create_config_file ( updating = True , configFileName = configFileName ) try : with open ( configFileName , 'r' , encoding = \"utf-8\" ) as newFile : newConfigData = newFile . readlines () newDataList = [] # Go through all new config lines for newLine in newConfigData : if not newLine . strip () . startswith ( '#' ) and not newLine . strip () == \"\" and \"version\" not in newLine : for setting in existingConfig . keys (): # Check if any old settings are in new config file if newLine . startswith ( setting ): for oldLine in oldConfigData : if not oldLine . strip () . startswith ( '#' ) and not oldLine . strip () == \"\" and \"version\" not in oldLine : # Sets new line to be the old line if oldLine . startswith ( setting ): newLine = oldLine break break # The new config file writes itself again, but with the modified newLine's newDataList . append ( newLine ) success = False attempts = 0 while success == False : try : attempts += 1 with open ( configFileName , \"w\" , encoding = \"utf-8\" ) as newFile : newFile . writelines ( newDataList ) success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Updating Config (May Cause Errors)? { S . R } (N)\" ) if choice ( \"Choice:\" ) == False : break return load_config_file ( configVersion = None , skipConfigChoice = True , configFileName = configFileName ) except : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when copying your config settings. You'll have to manually copy them from backup.\" ) input ( \" \\n Press Enter to exit...\" ) sys . exit () choose_config_file \u00b6 choose_config_file ( configDict , newestConfigVersion ) Source code in Scripts/files.py 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 def choose_config_file ( configDict , newestConfigVersion ): configNumExpression = r '(?<=spampurgeconfig)(\\d+?)(?=\\.ini)' configFileList = list_config_files () # If only one config file exists, prompt to use if len ( configFileList ) == 0 : if choice ( f \" \\n Found { F . YELLOW } config file { S . R } , use those settings?\" ) == False : return load_config_file ( forceDefault = True ) else : return configDict # If more than one config exists, list and ask which if len ( configFileList ) > 0 : configChoiceDict = {} print ( f \" \\n =================== Found Multiple Config Files ===================\" ) if os . path . exists ( \"SpamPurgeConfig.ini\" ): print ( f \" \\n { F . YELLOW } ------------- Use primary config file or another one? ------------- { S . R } \" ) print ( F \" { F . LIGHTCYAN_EX } Y: { S . R } Use primary config file\" ) print ( F \" { F . LIGHTCYAN_EX } N: { S . R } Use default settings, don't load any config\" ) print ( f \" \\n { F . YELLOW } ------------------ Other Available Config Files ------------------- { S . R } \" ) else : print ( \" \\n Available Config Files:\" ) # Print Available Configs, and add to dictionary for file in configFileList : configNum = re . search ( configNumExpression , file . lower ()) . group ( 0 ) configDescription = load_config_file ( configFileName = file , skipConfigChoice = True )[ 'this_config_description' ] configChoiceDict [ configNum ] = file print ( f \" { F . LIGHTCYAN_EX }{ configNum } : { S . R } { configDescription } \" ) valid = False while valid == False : configChoice = input ( \" \\n Config Choice (Y/N or #): \" ) if configChoice . lower () == \"y\" : return configDict elif configChoice . lower () == \"n\" : return load_config_file ( forceDefault = True ) elif configChoice . lower () == \"\" or configChoice . lower () not in configChoiceDict . keys (): print ( f \" \\n { F . YELLOW } Invalid Choice! Please enter a valid choice. { S . R } \" ) else : # Load an available config, update it, then return it chosenConfigDict = load_config_file ( skipConfigChoice = True , configFileName = configChoiceDict [ configChoice ]) chosenConfigDict = check_update_config_file ( newestConfigVersion , chosenConfigDict , configChoiceDict [ configChoice ]) return load_config_file ( skipConfigChoice = True , configFileName = configChoiceDict [ configChoice ]) copy_asset_file \u00b6 copy_asset_file ( fileName , destination ) Source code in Scripts/files.py 674 675 676 677 678 679 def copy_asset_file ( fileName , destination ): def assetFilesPath ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets copyfile ( assetFilesPath ( fileName ), os . path . abspath ( destination )) create_config_file \u00b6 create_config_file ( updating = False , dontWarn = False , configFileName = 'SpamPurgeConfig.ini' ) Source code in Scripts/files.py 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 def create_config_file ( updating = False , dontWarn = False , configFileName = \"SpamPurgeConfig.ini\" ): def config_path ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets if os . path . exists ( configFileName ): if updating == False and dontWarn == False : # First get list of existing secondary config files, to know what to name the new one configNumExpression = r '(?<=spampurgeconfig)(\\d+?)(?=\\.ini)' configFileList = list_config_files () if len ( configFileList ) > 0 : configNumList = list () for file in configFileList : configNum = re . search ( configNumExpression , file . lower ()) . group ( 0 ) configNumList . append ( int ( configNum )) newConfigNum = max ( configNumList ) + 1 else : newConfigNum = 2 print ( \"-------------------------------------------------------------------------------------\" ) print ( f \" \\n Config File { F . YELLOW }{ configFileName }{ S . R } already exists. You can { F . LIGHTCYAN_EX } reset it to default { S . R } , or { F . LIGHTCYAN_EX } create another secondary config { S . R } .\" ) print ( \" \\n What do you want to do?\" ) print ( f \" 1: { F . LIGHTRED_EX } Reset { S . R } main config ( { F . LIGHTRED_EX }{ configFileName }{ S . R } ) to fresh default config\" ) print ( f \" 2: { F . YELLOW } Create { S . R } another secondary config file (SpamPurgeConfig { F . YELLOW }{ newConfigNum }{ S . R } .ini)\" ) userChoice = input ( \" \\n Choose (1/2): \" ) if userChoice . lower () == \"x\" : return \"MainMenu\" elif userChoice == \"1\" : # Removes existing file to make room for fresh default config try : os . remove ( configFileName ) except : traceback . print_exc () print ( \"Error Code F-1: Problem deleting existing existing file! Check if it's gone. The info above may help if it's a bug.\" ) print ( \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press enter to Exit...\" ) sys . exit () elif userChoice == \"2\" : configFileName = f \"SpamPurgeConfig { newConfigNum } .ini\" input ( f \" \\n Press Enter to create additional config file: { F . YELLOW }{ configFileName }{ S . R } \" ) # Creates fresh new config file # Get default config file contents try : with open ( config_path ( 'default_config.ini' ), 'r' , encoding = \"utf-8\" ) as defaultConfigFile : data = defaultConfigFile . read () defaultConfigFile . close () except : traceback . print_exc () print ( f \" { B . RED }{ F . WHITE } Error Code: F-2 { S . R } - Problem reading default config file! The info above may help if it's a bug.\" ) input ( \"Press enter to Exit...\" ) sys . exit () # Create config file attempts = 0 success = False while success == False : try : attempts += 1 with open ( configFileName , \"w\" , encoding = \"utf-8\" ) as configFile : configFile . write ( data ) configFile . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Abandon Writing Config? { S . R } (N)\" ) if choice ( \"Choice:\" ) == False : break except : traceback . print_exc () print ( f \" { B . RED }{ F . WHITE } Error Code: F-3 { S . R } Problem creating config file! The info above may help if it's a bug.\" ) input ( \"Press enter to Exit...\" ) sys . exit () if os . path . exists ( configFileName ): parser = ConfigParser () try : parser . read ( \"SpamPurgeConfig.ini\" , encoding = \"utf-8\" ) if parser . get ( \"info\" , \"config_version\" ): if updating == False : print ( f \" \\n { B . GREEN }{ F . BLACK } SUCCESS! { S . R } { F . YELLOW }{ configFileName }{ S . R } file created successfully.\" ) print ( f \" \\n You can now edit the file to your liking. You can also { F . YELLOW } create additional { S . R } configs using this same menu. \\n \" ) input ( \"Press Enter to return to main menu...\" ) return \"MainMenu\" else : return True else : print ( \"Something might have gone wrong. Check if SpamPurgeConfig.ini file exists and has contents.\" ) input ( \"Press enter to Exit...\" ) sys . exit () except : traceback . print_exc () print ( \"Something went wrong when checking the created file. Check if SpamPurgeConfig.ini exists and has text. The info above may help if it's a bug.\" ) input ( \"Press enter to Exit...\" ) sys . exit () getRemoteFile \u00b6 getRemoteFile ( url , stream , silent = False , headers = None ) Source code in Scripts/files.py 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 def getRemoteFile ( url , stream , silent = False , headers = None ): try : if stream == False : response = requests . get ( url , headers = headers ) elif stream == True : response = requests . get ( url , headers = headers , stream = True ) if response . status_code != 200 : if silent == False : print ( \"Error fetching remote file or resource: \" + url ) print ( \"Response Code: \" + str ( response . status_code )) else : return response except Exception as e : if silent == False : print ( e + \" \\n \" ) print ( f \" { B . RED }{ F . WHITE } Error { S . R } While Fetching Remote File or Resource: \" + url ) print ( \"See above messages for details. \\n \" ) print ( \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) return None get_list_file_version \u00b6 get_list_file_version ( relativeFilePath ) Source code in Scripts/files.py 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 def get_list_file_version ( relativeFilePath ): listVersion = None if os . path . exists ( relativeFilePath ): matchBetweenBrackets = '(?<=\\[)(.*?)(?=\\])' # Matches text between first set of two square brackets with open ( relativeFilePath , 'r' , encoding = \"utf-8\" ) as file : for line in islice ( file , 0 , 5 ): try : matchItem = re . search ( matchBetweenBrackets , line ) if matchItem : listVersion = str ( matchItem . group ( 0 )) break except AttributeError : pass return listVersion else : return None ingest_asset_file \u00b6 ingest_asset_file ( fileName ) Source code in Scripts/files.py 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 def ingest_asset_file ( fileName ): def assetFilesPath ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets # Open list of root zone domain extensions with open ( assetFilesPath ( fileName ), 'r' , encoding = \"utf-8\" ) as file : data = file . readlines () dataList = [] for line in data : if not line . strip () . startswith ( '#' ): line = line . strip () dataList . append ( line . lower ()) return dataList ingest_list_file \u00b6 ingest_list_file ( relativeFilePath , keepCase = True ) Source code in Scripts/files.py 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 def ingest_list_file ( relativeFilePath , keepCase = True ): if os . path . exists ( relativeFilePath ): with open ( relativeFilePath , 'r' , encoding = \"utf-8\" ) as listFile : # If file doesn't end with newline, add one listData = listFile . readlines () lastline = listData [ - 1 ] with open ( relativeFilePath , 'a' , encoding = \"utf-8\" ) as listFile : if not lastline . endswith ( ' \\n ' ): listFile . write ( ' \\n ' ) processedList = [] for line in listData : line = line . strip () if not line . startswith ( '#' ) and line != \"\" : if keepCase == False : processedList . append ( line . lower ()) else : processedList . append ( line ) return processedList else : return None list_config_files \u00b6 list_config_files ( relativePath = None ) Source code in Scripts/files.py 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 def list_config_files ( relativePath = None ): configNumExpression = r '(?<=spampurgeconfig)(\\d+?)(?=\\.ini)' fileList = list () if relativePath == None : path = os . getcwd () else : path = os . path . abspath ( relativePath ) # Only get non-primary log files for file in os . listdir ( path ): if \"spampurgeconfig\" in file . lower () and file . lower () != \"spampurgeconfig.ini\" : try : match = re . search ( configNumExpression , file . lower ()) . group ( 0 ) # Only exact matches, no backups if file . lower () == \"spampurgeconfig\" + match + \".ini\" : fileList . append ( file ) except AttributeError as ax : if \"NoneType\" in str ( ax ): pass else : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when getting list of config files. Check your regex.\" ) input ( \" \\n Press Enter to exit...\" ) sys . exit () return fileList load_config_file \u00b6 load_config_file ( configVersion = None , forceDefault = False , skipConfigChoice = False , configFileName = 'SpamPurgeConfig.ini' ) Source code in Scripts/files.py 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 def load_config_file ( configVersion = None , forceDefault = False , skipConfigChoice = False , configFileName = \"SpamPurgeConfig.ini\" ): configDict = {} def default_config_path ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets # If user config file exists, keep path. Otherwise use default config file path if os . path . exists ( configFileName ) and forceDefault == False : default = False configFileNameWithPath = str ( configFileName ) else : configFileNameWithPath = default_config_path ( \"default_config.ini\" ) default = True # Load Contents of config file try : with open ( configFileNameWithPath , 'r' , encoding = \"utf-8\" ) as configFile : configData = configFile . read () configFile . close () except : traceback . print_exc () print ( f \" { B . RED }{ F . WHITE } Error Code: F-4 { S . R } - Config file found, but there was a problem loading it! The info above may help if it's a bug.\" ) print ( \" \\n You can manually delete SpamPurgeConfig.ini and use the program to create a new default config.\" ) input ( \"Press enter to Exit...\" ) sys . exit () # Sanitize config Data by removing quotes configData = configData . replace ( \" \\' \" , \"\" ) configData = configData . replace ( \" \\\" \" , \"\" ) # Converts string from config file, wraps it to make it behave like file so it can be read by parser # Must use .read_file, .read doesn't work wrappedConfigData = io . StringIO ( configData ) parser = ConfigParser () parser . read_file ( wrappedConfigData ) # Convert raw config dictionary into easier to use dictionary settingsToKeepCase = [ \"your_channel_id\" , \"videos_to_scan\" , \"channel_ids_to_filter\" , \"regex_to_filter\" , \"channel_to_scan\" , \"log_path\" , \"this_config_description\" ] validWordVars = [ 'ask' , 'mine' , 'default' ] for section in parser . sections (): for setting in parser . items ( section ): # Setting[0] is name of the setting, Setting[1] is the value of the setting if setting [ 0 ] in settingsToKeepCase and setting [ 1 ] . lower () not in validWordVars : configDict [ setting [ 0 ]] = setting [ 1 ] else : # Take values out of raw dictionary structure and put into easy dictionary with processed values configDict [ setting [ 0 ]] = setting [ 1 ] . lower () if setting [ 1 ] . lower () == \"false\" : configDict [ setting [ 0 ]] = False elif setting [ 1 ] . lower () == \"true\" : configDict [ setting [ 0 ]] = True # Prevent prompt about config file if it's the default config file if default == True : configDict [ 'use_this_config' ] = True # ---------------------------------------------------------------------------------------------------------------------- # Check if config out of date, update, ask to use config or not else : if configDict [ 'use_this_config' ] == False : configDict = load_config_file ( forceDefault = True ) elif configDict [ 'use_this_config' ] == 'ask' or configDict [ 'use_this_config' ] == True : if configVersion != None : configDict = check_update_config_file ( configVersion , configDict , configFileName ) if configDict [ 'use_this_config' ] == True or skipConfigChoice == True : pass else : configDict = choose_config_file ( configDict , configVersion ) else : print ( \"Error C-1: Invalid value in config file for setting 'use_this_config' - Must be 'True', 'False', or 'Ask'\" ) input ( \"Press Enter to exit...\" ) sys . exit () return configDict parse_comment_list \u00b6 parse_comment_list ( config , recovery = False , removal = False , returnFileName = False ) Source code in Scripts/files.py 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 def parse_comment_list ( config , recovery = False , removal = False , returnFileName = False ): if recovery == True : actionVerb = \"recover\" actionNoun = \"recovery\" elif removal == True : actionVerb = \"remove\" actionNoun = \"removal\" validFile = False manuallyEnter = False while validFile == False and manuallyEnter == False : print ( \"--------------------------------------------------------------------------------\" ) print ( f \" \\n Enter the { F . YELLOW } name of the log file { S . R } with the comments to { actionVerb } (you can rename it to something easier like \\' log.rtf \\' )\" ) print ( f \" > { F . BLACK }{ B . LIGHTGREEN_EX } TIP: { S . R } You can just drag the file into this window instead of typing it\" ) print ( F \" { F . YELLOW } Or: { S . R } Just hit Enter to manually paste in the list of IDs next)\" ) listFileName = input ( \" \\n Log File Name (Example: \\\" log.rtf \\\" or \\\" log \\\" ): \" ) if str ( listFileName ) . lower () == \"x\" : return \"MainMenu\" , None listFileName = listFileName . strip ( \" \\\" \" ) . strip ( \"'\" ) # Remove quotes, if added by dragging and dropping or pasting path if len ( listFileName ) > 0 : if os . path . exists ( listFileName ): pass elif os . path . exists ( listFileName + \".rtf\" ): listFileName = listFileName + \".rtf\" elif os . path . exists ( listFileName + \".txt\" ): listFileName = listFileName + \".txt\" else : # Try in the log folder listFileName = os . path . join ( config [ 'log_path' ], listFileName ) if os . path . exists ( listFileName ): pass elif os . path . exists ( listFileName + \".rtf\" ): listFileName = listFileName + \".rtf\" elif os . path . exists ( listFileName + \".txt\" ): listFileName = listFileName + \".txt\" # Get file path if os . path . exists ( listFileName ): try : with open ( listFileName , 'r' , encoding = \"utf-8\" ) as listFile : data = listFile . read () listFile . close () validFile = True except : print ( f \" { F . RED } Error Code F-5: { S . R } Log File was found but there was a problem reading it.\" ) else : print ( f \" \\n { F . LIGHTRED_EX } Error: File not found. { S . R } Make sure it is in the same folder as the program. \\n \" ) print ( f \"Enter ' { F . YELLOW } Y { S . R } ' to try again, or ' { F . YELLOW } N { S . R } ' to manually paste in the comment IDs.\" ) userChoice = choice ( \"Try entering file name again?\" ) if userChoice == True : pass elif userChoice == False : manuallyEnter = True elif userChoice == None : return \"MainMenu\" , None else : manuallyEnter = True if manuallyEnter == True : print ( \" \\n\\n --- Manual Comment ID Entry Instructions ---\" ) print ( f \"1. { F . YELLOW } Open the log file { S . R } and look for where it shows the list of { F . YELLOW } \\\" IDs of Matched Comments \\\" . { S . R } \" ) print ( f \"2. { F . YELLOW } Copy that list { S . R } , and { F . YELLOW } paste it below { S . R } (In windows console try pasting by right clicking).\" ) print ( \"3. If not using a log file, instead enter the ID list in this format: FirstID, SecondID, ThirdID, ... \\n \" ) data = str ( input ( \"Paste the list here, then hit Enter: \" )) if str ( data ) . lower () == \"x\" : return \"MainMenu\" , None print ( \" \\n \" ) # Parse data into list if manuallyEnter == False and '[' in data and ']' in data : matchBetweenBrackets = '(?<=\\[)(.*?)(?=\\])' # Matches text between first set of two square brackets #matchIncludeBracktes = '\\[(.*?)\\]' # Matches between square brackets, including brackets resultList = str ( re . search ( matchBetweenBrackets , data ) . group ( 0 )) else : resultList = data resultList = resultList . replace ( \" \\' \" , \"\" ) resultList = resultList . replace ( \"[\" , \"\" ) resultList = resultList . replace ( \"]\" , \"\" ) resultList = resultList . replace ( \" \" , \"\" ) resultList = resultList . split ( \",\" ) if len ( resultList ) == 0 : print ( f \" \\n { F . RED } Error Code R-1: { S . R } No comment IDs detected, try entering them manually and make sure they are formatted correctly.\" ) input ( \" \\n Press Enter to return to main menu...\" ) return \"MainMenu\" , None # Check for valid comment IDs validCount = 0 notValidCount = 0 notValidList = [] for id in resultList : if id [ 0 : 2 ] == \"Ug\" : validCount += 1 else : notValidCount += 1 notValidList . append ( id ) if notValidCount > 0 : print ( f \" { F . YELLOW } Possibly Invalid Comment IDs: { S . R } \" + str ( notValidList ) + \" \\n \" ) if notValidCount == 0 : print ( f \" \\n { F . GREEN } Loaded all { str ( validCount ) } comment IDs successfully! { S . R } \" ) input ( f \" \\n Press Enter to begin { actionNoun } ... \" ) elif validCount > 0 and notValidCount > 0 : print ( f \" { F . RED } Warning! { S . R } { str ( validCount ) } valid comment IDs loaded successfully, but { str ( notValidCount ) } may be invalid. See them above.\" ) input ( f \" \\n Press Enter to try { actionNoun } anyway... \\n \" ) elif validCount == 0 and notValidCount > 0 : print ( f \" \\n { F . RED } Warning! { S . R } All loaded comment IDs appear to be invalid. See them above.\" ) input ( f \"Press Enter to try { actionNoun } anyway... \\n \" ) if returnFileName == False : return resultList , None else : return resultList , pathlib . Path ( os . path . relpath ( listFileName )) . stem read_dict_pickle_file \u00b6 read_dict_pickle_file ( fileNameNoPath , relativeFolderPath = RESOURCES_FOLDER_NAME ) Source code in Scripts/files.py 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 def read_dict_pickle_file ( fileNameNoPath , relativeFolderPath = RESOURCES_FOLDER_NAME ): failedAttemptCount = 0 fileNameWithPath = os . path . join ( relativeFolderPath , fileNameNoPath ) while True and not failedAttemptCount > 2 : if os . path . exists ( fileNameWithPath ): failedAttemptCount = 0 while True and not failedAttemptCount > 2 : try : with open ( fileNameWithPath , 'rb' ) as pickleFile : #dictToRead = json.load(jsonFile) dictToRead = pickle . load ( pickleFile ) pickleFile . close () return dictToRead except : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when reading your pickle file. Is it in use? Try closing it.\" ) input ( f \" \\n Press Enter to try loading file again: { fileNameWithPath } \" ) failedAttemptCount += 1 return False else : print ( f \" \\n File ' { fileNameNoPath } ' not found! Try entering the name manually.\" ) input ( f \" \\n Press Enter to try loading file again: { fileNameWithPath } \" ) failedAttemptCount += 1 return False try_remove_file \u00b6 try_remove_file ( fileNameWithPath ) Source code in Scripts/files.py 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 def try_remove_file ( fileNameWithPath ): attempts = 1 while attempts < 3 : try : os . remove ( fileNameWithPath ) return True except : print ( f \" \\n { F . RED } \\n ERROR: { S . R } Could not remove file: ' { fileNameWithPath } '. Is it open? If so, try closing it.\" ) input ( \" \\n Press Enter to try again...\" ) attempts += 1 print ( f \" \\n { F . RED } \\n ERROR: { S . R } The File ' { fileNameWithPath } ' still could not be removed. You may have to delete it yourself.\" ) input ( \" \\n Press Enter to continue...\" ) return False write_dict_pickle_file \u00b6 write_dict_pickle_file ( dictToWrite , fileName , relativeFolderPath = RESOURCES_FOLDER_NAME , forceOverwrite = False ) Source code in Scripts/files.py 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 def write_dict_pickle_file ( dictToWrite , fileName , relativeFolderPath = RESOURCES_FOLDER_NAME , forceOverwrite = False ): fileNameWithPath = os . path . join ( relativeFolderPath , fileName ) success = False while success == False : if os . path . isdir ( relativeFolderPath ): success = True else : try : os . mkdir ( relativeFolderPath ) success = True except : print ( f \"Error: Could not create folder. Try creating the folder { relativeFolderPath } to continue.\" ) input ( \"Press Enter to try again...\" ) if os . path . exists ( fileNameWithPath ): if forceOverwrite == False : print ( f \" \\n File ' { fileName } ' already exists! Either overwrite, or you'll need to enter a new name.\" ) if choice ( \"Overwrite File?\" ) == True : pass else : confirm = False while confirm == False : newFileName = input ( \" \\n Enter a new file name, NOT including the extension: \" ) + \".save\" print ( \" \\n New file name: \" + newFileName ) confirm = choice ( \"Is this correct?\" ) fileNameWithPath = os . path . join ( relativeFolderPath , newFileName ) success = False while success == False : try : with open ( fileNameWithPath , 'wb' ) as pickleFile : pickle . dump ( dictToWrite , pickleFile ) #json.dump(dictToWrite, jsonFile, indent=4) pickleFile . close () success = True except : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when writing your pickle file. Did you open it or something?\" ) input ( f \" \\n Press Enter to try loading file again: { fileNameWithPath } \" ) return True","title":"files"},{"location":"reference/Scripts/files/#Scripts.files.check_existing_save","text":"check_existing_save () Source code in Scripts/files.py 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 def check_existing_save (): relativeSaveDir = os . path . join ( RESOURCES_FOLDER_NAME , \"Removal_List_Progress\" ) savesList = list () if os . path . isdir ( relativeSaveDir ): fileList = list () for ( _ , _ , filenames ) in os . walk ( relativeSaveDir ): fileList . extend ( filenames ) if len ( fileList ) > 0 : for fileName in fileList : if fileName [ - 5 :] == \".save\" : savesList . extend ([ fileName ]) return savesList","title":"check_existing_save()"},{"location":"reference/Scripts/files/#Scripts.files.check_for_update","text":"check_for_update ( currentVersion , updateReleaseChannel , silentCheck = False ) Source code in Scripts/files.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 def check_for_update ( currentVersion , updateReleaseChannel , silentCheck = False ): isUpdateAvailable = False print ( \" \\n Getting info about latest updates...\" ) try : if updateReleaseChannel == \"stable\" : response = requests . get ( \"https://api.github.com/repos/ThioJoe/YT-Spammer-Purge/releases/latest\" ) elif updateReleaseChannel == \"all\" : response = requests . get ( \"https://api.github.com/repos/ThioJoe/YT-Spammer-Purge/releases\" ) if response . status_code != 200 : if response . status_code == 403 : if silentCheck == False : print ( f \" \\n { B . RED }{ F . WHITE } Error [U-4]: { S . R } Got an 403 (ratelimit_reached) when attempting to check for update.\" ) print ( f \"This means you have been { F . YELLOW } rate limited by github.com { S . R } . Please try again in a while. \\n \" ) else : print ( f \" \\n { B . RED }{ F . WHITE } Error [U-4]: { S . R } Got an 403 (ratelimit_reached) when attempting to check for update.\" ) return None else : if silentCheck == False : print ( f \" { B . RED }{ F . WHITE } Error [U-3]: { S . R } Got non 200 status code (got: { response . status_code } ) when attempting to check for update. \\n \" ) print ( f \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) else : print ( f \" { B . RED }{ F . WHITE } Error [U-3]: { S . R } Got non 200 status code (got: { response . status_code } ) when attempting to check for update. \\n \" ) return None else : # assume 200 response (good) if updateReleaseChannel == \"stable\" : latestVersion = response . json ()[ \"name\" ] isBeta = False elif updateReleaseChannel == \"all\" : latestVersion = response . json ()[ 0 ][ \"name\" ] isBeta = response . json ()[ 0 ][ \"prerelease\" ] except OSError as ox : if \"WinError 10013\" in str ( ox ): print ( f \" { B . RED }{ F . WHITE } WinError 10013: { S . R } The OS blocked the connection to GitHub. Check your firewall settings. \\n \" ) else : print ( f \" { B . RED }{ F . WHITE } Unknown OSError { S . R } Error occurred while checking for updates \\n \" ) return None except Exception as e : if silentCheck == False : print ( e + \" \\n \" ) print ( f \" { B . RED }{ F . WHITE } Error [Code U-1]: { S . R } Problem while checking for updates. See above error for more details. \\n \" ) print ( \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) elif silentCheck == True : print ( f \" { B . RED }{ F . WHITE } Error [Code U-1]: { S . R } Unknown problem while checking for updates. See above error for more details. \\n \" ) return None if parse_version ( latestVersion ) > parse_version ( currentVersion ): if isBeta == True : isUpdateAvailable = \"beta\" else : isUpdateAvailable = True if silentCheck == False : print ( \"------------------------------------------------------------------------------------------\" ) if isBeta == True : print ( f \" { F . YELLOW } A new { F . LIGHTGREEN_EX } beta { F . YELLOW } version { S . R } is available! Visit { F . YELLOW } TJoe.io/latest { S . R } to see what's new.\" ) else : print ( f \" A { F . LIGHTGREEN_EX } new version { S . R } is available! Visit { F . YELLOW } TJoe.io/latest { S . R } to see what's new.\" ) print ( f \" > Current Version: { currentVersion } \" ) print ( f \" > Latest Version: { F . LIGHTGREEN_EX }{ latestVersion }{ S . R } \" ) if isBeta == True : print ( \"(To stop receiving beta releases, change the 'release_channel' setting in the config file)\" ) print ( \"------------------------------------------------------------------------------------------\" ) userChoice = choice ( \"Update Now?\" ) if userChoice == True : if sys . platform == 'win32' or sys . platform == 'win64' : print ( f \" \\n > { F . LIGHTCYAN_EX } Downloading Latest Version... { S . R } \" ) if updateReleaseChannel == \"stable\" : jsondata = json . dumps ( response . json ()[ \"assets\" ]) elif updateReleaseChannel == \"all\" : jsondata = json . dumps ( response . json ()[ 0 ][ \"assets\" ]) dict_json = json . loads ( jsondata ) # Get files in release, get exe and hash info i , j , k = 0 , 0 , 0 # i = index of all, j = index of exe, k = index of hash for asset in dict_json : i += 1 name = str ( asset [ 'name' ]) if '.exe' in name . lower (): filedownload = requests . get ( dict_json [ 0 ][ 'browser_download_url' ], stream = True ) j += 1 # Count number of exe files in release, in case future has multiple exe's, can cause warning if '.sha256' in name . lower (): #First removes .sha256 file extension, then removes all non-alphanumeric characters downloadHashSHA256 = re . sub ( r '[^a-zA-Z0-9]' , '' , name . lower () . replace ( '.sha256' , '' )) k += 1 ignoreHash = False # Validate Retrieved Info if j > 1 : # More than one exe file in release print ( f \" { F . YELLOW } Warning! { S . R } Multiple exe files found in release. You must be updating from the future when that was not anticipated.\" ) print ( \"You should instead manually download the latest version from: https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) print ( \"You can try continuing anyway, but it might not be successful, or might download the wrong exe file.\" ) input ( \" \\n Press enter to continue...\" ) elif j == 0 : # No exe file in release print ( f \" { F . LIGHTRED_EX } Warning! { S . R } No exe file found in release. You'll have to manually download the latest version from:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) return False if k == 0 : # No hash file in release print ( f \" { F . YELLOW } Warning! { S . R } No verification sha256 hash found in release. If download fails, you can manually download latest version here:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) input ( \" \\n Press Enter to try to continue...\" ) ignoreHash = True elif k > 0 and k != j : print ( f \" { F . YELLOW } Warning! { S . R } Too many or too few sha256 files found in release. If download fails, you should manually download latest version here:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) input ( \" \\n Press Enter to try to continue...\" ) # Get and Set Download Info total_size_in_bytes = int ( filedownload . headers . get ( 'content-length' , 0 )) block_size = 1048576 #1 MiB in bytes downloadFileName = dict_json [ 0 ][ 'name' ] # Check if file exists already, ask to overwrite if it does if os . path . exists ( downloadFileName ): print ( f \" \\n { B . RED }{ F . WHITE } WARNING! { S . R } ' { F . YELLOW }{ downloadFileName }{ S . R } ' file already exists. This would overwrite the existing file.\" ) confirm = choice ( \"Overwrite this existing file?\" ) if confirm == True : try : os . remove ( downloadFileName ) except : traceback . print_exc () print ( f \" \\n { F . LIGHTRED_EX } Error F-6: { S . R } Problem deleting existing existing file! Check if it's gone, or delete it yourself, then try again.\" ) print ( \"The info above may help if it's a bug, which you can report here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press enter to Exit...\" ) sys . exit () elif confirm == False or confirm == None : return False # Download File with open ( downloadFileName , 'wb' ) as file : numProgressBars = 30 for data in filedownload . iter_content ( block_size ): progress = os . stat ( downloadFileName ) . st_size / total_size_in_bytes * numProgressBars print ( f \" { F . LIGHTGREEN_EX } <[ { F . LIGHTCYAN_EX } \" + '=' * round ( progress ) + ' ' * ( numProgressBars - round ( progress )) + f \" { F . LIGHTGREEN_EX } ]> { S . R } \\r \" , end = \"\" ) #Print Progress bar file . write ( data ) print ( f \" \\n > { F . LIGHTCYAN_EX } Verifying Download Integrity... { S . R } \" ) # Verify Download Size if os . stat ( downloadFileName ) . st_size == total_size_in_bytes : pass elif total_size_in_bytes != 0 and os . stat ( downloadFileName ) . st_size != total_size_in_bytes : os . remove ( downloadFileName ) print ( f \" \\n > { F . RED } File did not fully download. Please try again later.\" ) return False elif total_size_in_bytes == 0 : print ( \"Something is wrong with the download on the remote end. You should manually download latest version here:\" ) print ( \"https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) # Verify hash if ignoreHash == False : if downloadHashSHA256 == hashlib . sha256 ( open ( downloadFileName , 'rb' ) . read ()) . hexdigest () . lower (): pass else : os . remove ( downloadFileName ) print ( f \" \\n > { F . RED } Hash did not match. Please try again later.\" ) print ( \"Or download the latest version manually from here: https://github.com/ThioJoe/YT-Spammer-Purge/releases\" ) return False # Print Success print ( f \" \\n > Download Completed: { F . LIGHTGREEN_EX }{ downloadFileName }{ S . R } \" ) if isBeta == False : print ( \" \\n You can now delete the old version. (Or keep it around in case you encounter any issues with the new version)\" ) else : print ( f \" \\n { F . LIGHTYELLOW_EX } NOTE: { S . R } Because this is a { F . CYAN } beta release { S . R } , you should keep the old version around in case you encounter any issues\" ) print ( f \" > And don't forget to report any problems you encounter here: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () elif platform . system () == \"Linux\" : # Current working directory cwd = os . getcwd () # what we want the tar file to be called on the system tarFileName = \"yt-spammer.tar.gz\" # Name of this file # Temp folder for update stagingFolder = \"temp\" # Fetch the latest update print ( f \" \\n > Downloading version: { F . GREEN }{ latestVersion }{ S . R } \" ) url = f 'https://codeload.github.com/ThioJoe/YT-Spammer-Purge/tar.gz/refs/tags/v { latestVersion } ' r = requests . get ( url , stream = True ) if ( r . status_code == 200 ): with open ( tarFileName , 'wb' ) as file : for chunk in r . iter_content ( chunk_size = 1048576 ): if chunk : file . write ( chunk ) else : print ( \"Downloading of new version failed!\" ) print ( f \" \\n > { F . RED } Error: { S . R } GitHub returned a non 200 status code while trying to download newer version. \\n Status returned: { r . status_code } \" ) input ( \"Press Enter to Exit...\" ) sys . exit () # Extract the tar file and delete it print ( \" \\n > Extracting...\" ) with tarfile . open ( tarFileName ) as file : file . extractall ( f './ { stagingFolder } ' ) os . remove ( tarFileName ) print ( f \"> Installing...\" ) # Retrieve the name of the folder containing the main file, we are assuming there will always be only one folder here extraFolderPath = os . listdir ( f \"./ { stagingFolder } \" ) # If there happens to be more then one folder if ( len ( extraFolderPath ) != 1 ): print ( f \" \\n > { F . RED } Error: { S . R } more then one folder in { stagingFolder } ! Please make a bug report.\" ) print ( f \" \\n { F . RED } Aborting Update! { S . R } \" ) print ( \" \\n > Cleaning up...\" ) rmtree ( stagingFolder ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () else : extraFolderPath = f \" { cwd } / { stagingFolder } / { extraFolderPath [ 0 ] } \" for file_name in os . listdir ( extraFolderPath ): if os . path . exists ( file_name ): try : os . remove ( file_name ) except IsADirectoryError : rmtree ( file_name ) move ( f \" { extraFolderPath } / { file_name } \" , f \" { cwd } / { file_name } \" ) rmtree ( stagingFolder ) print ( f \" \\n > Update completed: { currentVersion } ==> { F . GREEN }{ latestVersion }{ S . R } \" ) print ( \"> Restart the script to apply the update.\" ) input ( \" \\n Press Enter to Exit...\" ) sys . exit () else : print ( f \"> { F . RED } Error: { S . R } You are using an unsupported OS for the autoupdater (macos). \\n This updater only supports Windows and Linux (right now). Feel free to get the files from github: https://github.com/ThioJoe/YT-Spammer-Purge\" ) return False elif userChoice == \"False\" or userChoice == None : return False elif silentCheck == True : return isUpdateAvailable elif parse_version ( latestVersion ) == parse_version ( currentVersion ): if silentCheck == False : print ( f \" \\n You have the { F . LIGHTGREEN_EX } latest { S . R } version: { F . LIGHTGREEN_EX } \" + currentVersion ) return False else : if silentCheck == False : print ( \" \\n No newer release available - Your Version: \" + currentVersion + \" -- Latest Version: \" + latestVersion ) return False","title":"check_for_update()"},{"location":"reference/Scripts/files/#Scripts.files.check_lists_update","text":"check_lists_update ( spamListDict , silentCheck = False ) Source code in Scripts/files.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 def check_lists_update ( spamListDict , silentCheck = False ): SpamListFolder = spamListDict [ 'Meta' ][ 'SpamListFolder' ] currentListVersion = spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'LatestLocalVersion' ] def update_last_checked (): currentDate = datetime . today () . strftime ( '%Y.%m. %d .%H.%M' ) #Update Dictionary with latest release gotten from API spamListDict [ 'Meta' ][ 'VersionInfo' ] . update ({ 'LatestLocalVersion' : latestRelease }) spamListDict [ 'Meta' ][ 'VersionInfo' ] . update ({ 'LastChecked' : currentDate }) # Prepare data for json file update, so only have to check once a day automatically newJsonContents = json . dumps ({ 'LatestRelease' : latestRelease , 'LastChecked' : currentDate }) with open ( spamListDict [ 'Meta' ][ 'VersionInfo' ][ 'Path' ], 'w' , encoding = \"utf-8\" ) as file : json . dump ( newJsonContents , file , indent = 4 ) if silentCheck == False : print ( \" \\n Checking for updates to spam lists...\" ) if os . path . isdir ( SpamListFolder ): pass else : try : os . mkdir ( SpamListFolder ) except : print ( \"Error: Could not create folder. Try creating a folder called 'spam_lists' to update the spam lists.\" ) try : response = requests . get ( \"https://api.github.com/repos/ThioJoe/YT-Spam-Domains-List/releases/latest\" ) if response . status_code != 200 : if response . status_code == 403 : if silentCheck == False : print ( f \" \\n { B . RED }{ F . WHITE } Error [U-4L]: { S . R } Got an 403 (ratelimit_reached) when attempting to check for spam list update.\" ) print ( f \"This means you have been { F . YELLOW } rate limited by github.com { S . R } . Please try again in a while. \\n \" ) return False else : return spamListDict else : if silentCheck == False : print ( f \" { B . RED }{ F . WHITE } Error [U-3L]: { S . R } Got non 200 status code (got: { response . status_code } ) when attempting to check for spam list update. \\n \" ) print ( f \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) if silentCheck == False : return False else : return spamListDict latestRelease = response . json ()[ \"tag_name\" ] except OSError as ox : if silentCheck == True : return spamListDict else : if \"WinError 10013\" in str ( ox ): print ( f \" { B . RED }{ F . WHITE } WinError 10013: { S . R } The OS blocked the connection to GitHub. Check your firewall settings. \\n \" ) return False except : if silentCheck == True : return spamListDict else : print ( \"Error: Could not get latest release info from GitHub. Please try again later.\" ) return False # If update available if currentListVersion == None or ( parse_version ( latestRelease ) > parse_version ( currentListVersion )): print ( \" \\n > A new spam list update is available. Downloading...\" ) fileName = response . json ()[ \"assets\" ][ 0 ][ 'name' ] total_size_in_bytes = response . json ()[ \"assets\" ][ 0 ][ 'size' ] downloadFilePath = SpamListFolder + fileName downloadURL = response . json ()[ \"assets\" ][ 0 ][ 'browser_download_url' ] filedownload = getRemoteFile ( downloadURL , stream = True ) # These headers required to get correct file size block_size = 1048576 #1 MiB in bytes with open ( downloadFilePath , 'wb' ) as file : for data in filedownload . iter_content ( block_size ): file . write ( data ) if os . stat ( downloadFilePath ) . st_size == total_size_in_bytes : # Unzip files into folder and delete zip file attempts = 0 print ( \"Extracting updated lists...\" ) # While loop continues until file no longer exists, or too many errors while True : try : attempts += 1 time . sleep ( 0.5 ) with zipfile . ZipFile ( downloadFilePath , \"r\" ) as zip_ref : zip_ref . extractall ( SpamListFolder ) os . remove ( downloadFilePath ) except PermissionError as e : if attempts <= 10 : continue else : traceback . print_exc () print ( f \" \\n > { F . RED } Error: { S . R } The zip file containing the spam lists was downloaded, but there was a problem extracting the files because of a permission error. \" ) print ( f \"This can happen if an antivirus takes a while to scan the file. You may need to manually extract the zip file.\" ) input ( \" \\n Press enter to Continue anyway...\" ) break # THIS MEANS SUCCESS, the zip file was deleted after extracting, so returns except FileNotFoundError : update_last_checked () return spamListDict elif total_size_in_bytes != 0 and os . stat ( downloadFilePath ) . st_size != total_size_in_bytes : os . remove ( downloadFilePath ) print ( f \" > { F . RED } File did not fully download. Please try again later. \\n \" ) return spamListDict else : update_last_checked () return spamListDict","title":"check_lists_update()"},{"location":"reference/Scripts/files/#Scripts.files.check_update_config_file","text":"check_update_config_file ( newVersion , existingConfig , configFileName ) Source code in Scripts/files.py 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 def check_update_config_file ( newVersion , existingConfig , configFileName ): backupDestinationFolder = os . path . join ( RESOURCES_FOLDER_NAME , \"User_Config_Backups\" ) try : existingConfigVersion = int ( existingConfig [ 'config_version' ]) if existingConfigVersion < newVersion : configOutOfDate = True else : configOutOfDate = False except : configOutOfDate = True if configOutOfDate == True : print ( f \" \\n { F . YELLOW } WARNING! { S . R } Your config file is { F . YELLOW } out of date { S . R } . \" ) print ( f \" > Program will { F . LIGHTGREEN_EX } update your config { S . R } now, { F . LIGHTGREEN_EX } back up the old file { S . R } , and { F . LIGHTGREEN_EX } copy your settings over { S . R } )\" ) input ( \" \\n Press Enter to update config file...\" ) else : return existingConfig # If user config file exists, keep path. Otherwise use default config file path if os . path . exists ( configFileName ): pass else : print ( \"No existing config file found!\" ) return False # Load data of old config file with open ( configFileName , 'r' , encoding = \"utf-8\" ) as oldFile : oldConfigData = oldFile . readlines () oldFile . close () # Rename config to backup and copy to backup folder if not os . path . exists ( backupDestinationFolder ): os . mkdir ( backupDestinationFolder ) backupConfigFileName = f \" { configFileName } .backup_v { existingConfigVersion } \" backupNameAndPath = os . path . join ( backupDestinationFolder , backupConfigFileName ) if os . path . isfile ( backupNameAndPath ): print ( \"Existing backup config file found. Random number will be added to new backup file name.\" ) while os . path . isfile ( backupNameAndPath ): backupConfigFileName = backupConfigFileName + \"_\" + str ( randrange ( 999 )) backupNameAndPath = os . path . join ( backupDestinationFolder , backupConfigFileName ) # Attempt to copy backup to backup folder, otherwise just rename try : copyfile ( configFileName , os . path . abspath ( backupNameAndPath )) print ( f \" \\n Old config file renamed to { F . CYAN }{ backupConfigFileName }{ S . R } and placed in { F . CYAN }{ backupDestinationFolder }{ S . R } \" ) except : os . rename ( configFileName , backupConfigFileName ) print ( f \" \\n Old config file renamed to { F . CYAN }{ backupConfigFileName }{ S . R } . Note: Backup file could not be moved to backup folder, so it was just renamed.\" ) # Creates new config file from default create_config_file ( updating = True , configFileName = configFileName ) try : with open ( configFileName , 'r' , encoding = \"utf-8\" ) as newFile : newConfigData = newFile . readlines () newDataList = [] # Go through all new config lines for newLine in newConfigData : if not newLine . strip () . startswith ( '#' ) and not newLine . strip () == \"\" and \"version\" not in newLine : for setting in existingConfig . keys (): # Check if any old settings are in new config file if newLine . startswith ( setting ): for oldLine in oldConfigData : if not oldLine . strip () . startswith ( '#' ) and not oldLine . strip () == \"\" and \"version\" not in oldLine : # Sets new line to be the old line if oldLine . startswith ( setting ): newLine = oldLine break break # The new config file writes itself again, but with the modified newLine's newDataList . append ( newLine ) success = False attempts = 0 while success == False : try : attempts += 1 with open ( configFileName , \"w\" , encoding = \"utf-8\" ) as newFile : newFile . writelines ( newDataList ) success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Updating Config (May Cause Errors)? { S . R } (N)\" ) if choice ( \"Choice:\" ) == False : break return load_config_file ( configVersion = None , skipConfigChoice = True , configFileName = configFileName ) except : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when copying your config settings. You'll have to manually copy them from backup.\" ) input ( \" \\n Press Enter to exit...\" ) sys . exit ()","title":"check_update_config_file()"},{"location":"reference/Scripts/files/#Scripts.files.choose_config_file","text":"choose_config_file ( configDict , newestConfigVersion ) Source code in Scripts/files.py 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 def choose_config_file ( configDict , newestConfigVersion ): configNumExpression = r '(?<=spampurgeconfig)(\\d+?)(?=\\.ini)' configFileList = list_config_files () # If only one config file exists, prompt to use if len ( configFileList ) == 0 : if choice ( f \" \\n Found { F . YELLOW } config file { S . R } , use those settings?\" ) == False : return load_config_file ( forceDefault = True ) else : return configDict # If more than one config exists, list and ask which if len ( configFileList ) > 0 : configChoiceDict = {} print ( f \" \\n =================== Found Multiple Config Files ===================\" ) if os . path . exists ( \"SpamPurgeConfig.ini\" ): print ( f \" \\n { F . YELLOW } ------------- Use primary config file or another one? ------------- { S . R } \" ) print ( F \" { F . LIGHTCYAN_EX } Y: { S . R } Use primary config file\" ) print ( F \" { F . LIGHTCYAN_EX } N: { S . R } Use default settings, don't load any config\" ) print ( f \" \\n { F . YELLOW } ------------------ Other Available Config Files ------------------- { S . R } \" ) else : print ( \" \\n Available Config Files:\" ) # Print Available Configs, and add to dictionary for file in configFileList : configNum = re . search ( configNumExpression , file . lower ()) . group ( 0 ) configDescription = load_config_file ( configFileName = file , skipConfigChoice = True )[ 'this_config_description' ] configChoiceDict [ configNum ] = file print ( f \" { F . LIGHTCYAN_EX }{ configNum } : { S . R } { configDescription } \" ) valid = False while valid == False : configChoice = input ( \" \\n Config Choice (Y/N or #): \" ) if configChoice . lower () == \"y\" : return configDict elif configChoice . lower () == \"n\" : return load_config_file ( forceDefault = True ) elif configChoice . lower () == \"\" or configChoice . lower () not in configChoiceDict . keys (): print ( f \" \\n { F . YELLOW } Invalid Choice! Please enter a valid choice. { S . R } \" ) else : # Load an available config, update it, then return it chosenConfigDict = load_config_file ( skipConfigChoice = True , configFileName = configChoiceDict [ configChoice ]) chosenConfigDict = check_update_config_file ( newestConfigVersion , chosenConfigDict , configChoiceDict [ configChoice ]) return load_config_file ( skipConfigChoice = True , configFileName = configChoiceDict [ configChoice ])","title":"choose_config_file()"},{"location":"reference/Scripts/files/#Scripts.files.copy_asset_file","text":"copy_asset_file ( fileName , destination ) Source code in Scripts/files.py 674 675 676 677 678 679 def copy_asset_file ( fileName , destination ): def assetFilesPath ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets copyfile ( assetFilesPath ( fileName ), os . path . abspath ( destination ))","title":"copy_asset_file()"},{"location":"reference/Scripts/files/#Scripts.files.create_config_file","text":"create_config_file ( updating = False , dontWarn = False , configFileName = 'SpamPurgeConfig.ini' ) Source code in Scripts/files.py 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 def create_config_file ( updating = False , dontWarn = False , configFileName = \"SpamPurgeConfig.ini\" ): def config_path ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets if os . path . exists ( configFileName ): if updating == False and dontWarn == False : # First get list of existing secondary config files, to know what to name the new one configNumExpression = r '(?<=spampurgeconfig)(\\d+?)(?=\\.ini)' configFileList = list_config_files () if len ( configFileList ) > 0 : configNumList = list () for file in configFileList : configNum = re . search ( configNumExpression , file . lower ()) . group ( 0 ) configNumList . append ( int ( configNum )) newConfigNum = max ( configNumList ) + 1 else : newConfigNum = 2 print ( \"-------------------------------------------------------------------------------------\" ) print ( f \" \\n Config File { F . YELLOW }{ configFileName }{ S . R } already exists. You can { F . LIGHTCYAN_EX } reset it to default { S . R } , or { F . LIGHTCYAN_EX } create another secondary config { S . R } .\" ) print ( \" \\n What do you want to do?\" ) print ( f \" 1: { F . LIGHTRED_EX } Reset { S . R } main config ( { F . LIGHTRED_EX }{ configFileName }{ S . R } ) to fresh default config\" ) print ( f \" 2: { F . YELLOW } Create { S . R } another secondary config file (SpamPurgeConfig { F . YELLOW }{ newConfigNum }{ S . R } .ini)\" ) userChoice = input ( \" \\n Choose (1/2): \" ) if userChoice . lower () == \"x\" : return \"MainMenu\" elif userChoice == \"1\" : # Removes existing file to make room for fresh default config try : os . remove ( configFileName ) except : traceback . print_exc () print ( \"Error Code F-1: Problem deleting existing existing file! Check if it's gone. The info above may help if it's a bug.\" ) print ( \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press enter to Exit...\" ) sys . exit () elif userChoice == \"2\" : configFileName = f \"SpamPurgeConfig { newConfigNum } .ini\" input ( f \" \\n Press Enter to create additional config file: { F . YELLOW }{ configFileName }{ S . R } \" ) # Creates fresh new config file # Get default config file contents try : with open ( config_path ( 'default_config.ini' ), 'r' , encoding = \"utf-8\" ) as defaultConfigFile : data = defaultConfigFile . read () defaultConfigFile . close () except : traceback . print_exc () print ( f \" { B . RED }{ F . WHITE } Error Code: F-2 { S . R } - Problem reading default config file! The info above may help if it's a bug.\" ) input ( \"Press enter to Exit...\" ) sys . exit () # Create config file attempts = 0 success = False while success == False : try : attempts += 1 with open ( configFileName , \"w\" , encoding = \"utf-8\" ) as configFile : configFile . write ( data ) configFile . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ configFileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Abandon Writing Config? { S . R } (N)\" ) if choice ( \"Choice:\" ) == False : break except : traceback . print_exc () print ( f \" { B . RED }{ F . WHITE } Error Code: F-3 { S . R } Problem creating config file! The info above may help if it's a bug.\" ) input ( \"Press enter to Exit...\" ) sys . exit () if os . path . exists ( configFileName ): parser = ConfigParser () try : parser . read ( \"SpamPurgeConfig.ini\" , encoding = \"utf-8\" ) if parser . get ( \"info\" , \"config_version\" ): if updating == False : print ( f \" \\n { B . GREEN }{ F . BLACK } SUCCESS! { S . R } { F . YELLOW }{ configFileName }{ S . R } file created successfully.\" ) print ( f \" \\n You can now edit the file to your liking. You can also { F . YELLOW } create additional { S . R } configs using this same menu. \\n \" ) input ( \"Press Enter to return to main menu...\" ) return \"MainMenu\" else : return True else : print ( \"Something might have gone wrong. Check if SpamPurgeConfig.ini file exists and has contents.\" ) input ( \"Press enter to Exit...\" ) sys . exit () except : traceback . print_exc () print ( \"Something went wrong when checking the created file. Check if SpamPurgeConfig.ini exists and has text. The info above may help if it's a bug.\" ) input ( \"Press enter to Exit...\" ) sys . exit ()","title":"create_config_file()"},{"location":"reference/Scripts/files/#Scripts.files.getRemoteFile","text":"getRemoteFile ( url , stream , silent = False , headers = None ) Source code in Scripts/files.py 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 def getRemoteFile ( url , stream , silent = False , headers = None ): try : if stream == False : response = requests . get ( url , headers = headers ) elif stream == True : response = requests . get ( url , headers = headers , stream = True ) if response . status_code != 200 : if silent == False : print ( \"Error fetching remote file or resource: \" + url ) print ( \"Response Code: \" + str ( response . status_code )) else : return response except Exception as e : if silent == False : print ( e + \" \\n \" ) print ( f \" { B . RED }{ F . WHITE } Error { S . R } While Fetching Remote File or Resource: \" + url ) print ( \"See above messages for details. \\n \" ) print ( \"If this keeps happening, you may want to report the issue here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) return None","title":"getRemoteFile()"},{"location":"reference/Scripts/files/#Scripts.files.get_list_file_version","text":"get_list_file_version ( relativeFilePath ) Source code in Scripts/files.py 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 def get_list_file_version ( relativeFilePath ): listVersion = None if os . path . exists ( relativeFilePath ): matchBetweenBrackets = '(?<=\\[)(.*?)(?=\\])' # Matches text between first set of two square brackets with open ( relativeFilePath , 'r' , encoding = \"utf-8\" ) as file : for line in islice ( file , 0 , 5 ): try : matchItem = re . search ( matchBetweenBrackets , line ) if matchItem : listVersion = str ( matchItem . group ( 0 )) break except AttributeError : pass return listVersion else : return None","title":"get_list_file_version()"},{"location":"reference/Scripts/files/#Scripts.files.ingest_asset_file","text":"ingest_asset_file ( fileName ) Source code in Scripts/files.py 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 def ingest_asset_file ( fileName ): def assetFilesPath ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets # Open list of root zone domain extensions with open ( assetFilesPath ( fileName ), 'r' , encoding = \"utf-8\" ) as file : data = file . readlines () dataList = [] for line in data : if not line . strip () . startswith ( '#' ): line = line . strip () dataList . append ( line . lower ()) return dataList","title":"ingest_asset_file()"},{"location":"reference/Scripts/files/#Scripts.files.ingest_list_file","text":"ingest_list_file ( relativeFilePath , keepCase = True ) Source code in Scripts/files.py 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 def ingest_list_file ( relativeFilePath , keepCase = True ): if os . path . exists ( relativeFilePath ): with open ( relativeFilePath , 'r' , encoding = \"utf-8\" ) as listFile : # If file doesn't end with newline, add one listData = listFile . readlines () lastline = listData [ - 1 ] with open ( relativeFilePath , 'a' , encoding = \"utf-8\" ) as listFile : if not lastline . endswith ( ' \\n ' ): listFile . write ( ' \\n ' ) processedList = [] for line in listData : line = line . strip () if not line . startswith ( '#' ) and line != \"\" : if keepCase == False : processedList . append ( line . lower ()) else : processedList . append ( line ) return processedList else : return None","title":"ingest_list_file()"},{"location":"reference/Scripts/files/#Scripts.files.list_config_files","text":"list_config_files ( relativePath = None ) Source code in Scripts/files.py 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 def list_config_files ( relativePath = None ): configNumExpression = r '(?<=spampurgeconfig)(\\d+?)(?=\\.ini)' fileList = list () if relativePath == None : path = os . getcwd () else : path = os . path . abspath ( relativePath ) # Only get non-primary log files for file in os . listdir ( path ): if \"spampurgeconfig\" in file . lower () and file . lower () != \"spampurgeconfig.ini\" : try : match = re . search ( configNumExpression , file . lower ()) . group ( 0 ) # Only exact matches, no backups if file . lower () == \"spampurgeconfig\" + match + \".ini\" : fileList . append ( file ) except AttributeError as ax : if \"NoneType\" in str ( ax ): pass else : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when getting list of config files. Check your regex.\" ) input ( \" \\n Press Enter to exit...\" ) sys . exit () return fileList","title":"list_config_files()"},{"location":"reference/Scripts/files/#Scripts.files.load_config_file","text":"load_config_file ( configVersion = None , forceDefault = False , skipConfigChoice = False , configFileName = 'SpamPurgeConfig.ini' ) Source code in Scripts/files.py 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 def load_config_file ( configVersion = None , forceDefault = False , skipConfigChoice = False , configFileName = \"SpamPurgeConfig.ini\" ): configDict = {} def default_config_path ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle return os . path . join ( sys . _MEIPASS , relative_path ) return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets # If user config file exists, keep path. Otherwise use default config file path if os . path . exists ( configFileName ) and forceDefault == False : default = False configFileNameWithPath = str ( configFileName ) else : configFileNameWithPath = default_config_path ( \"default_config.ini\" ) default = True # Load Contents of config file try : with open ( configFileNameWithPath , 'r' , encoding = \"utf-8\" ) as configFile : configData = configFile . read () configFile . close () except : traceback . print_exc () print ( f \" { B . RED }{ F . WHITE } Error Code: F-4 { S . R } - Config file found, but there was a problem loading it! The info above may help if it's a bug.\" ) print ( \" \\n You can manually delete SpamPurgeConfig.ini and use the program to create a new default config.\" ) input ( \"Press enter to Exit...\" ) sys . exit () # Sanitize config Data by removing quotes configData = configData . replace ( \" \\' \" , \"\" ) configData = configData . replace ( \" \\\" \" , \"\" ) # Converts string from config file, wraps it to make it behave like file so it can be read by parser # Must use .read_file, .read doesn't work wrappedConfigData = io . StringIO ( configData ) parser = ConfigParser () parser . read_file ( wrappedConfigData ) # Convert raw config dictionary into easier to use dictionary settingsToKeepCase = [ \"your_channel_id\" , \"videos_to_scan\" , \"channel_ids_to_filter\" , \"regex_to_filter\" , \"channel_to_scan\" , \"log_path\" , \"this_config_description\" ] validWordVars = [ 'ask' , 'mine' , 'default' ] for section in parser . sections (): for setting in parser . items ( section ): # Setting[0] is name of the setting, Setting[1] is the value of the setting if setting [ 0 ] in settingsToKeepCase and setting [ 1 ] . lower () not in validWordVars : configDict [ setting [ 0 ]] = setting [ 1 ] else : # Take values out of raw dictionary structure and put into easy dictionary with processed values configDict [ setting [ 0 ]] = setting [ 1 ] . lower () if setting [ 1 ] . lower () == \"false\" : configDict [ setting [ 0 ]] = False elif setting [ 1 ] . lower () == \"true\" : configDict [ setting [ 0 ]] = True # Prevent prompt about config file if it's the default config file if default == True : configDict [ 'use_this_config' ] = True # ---------------------------------------------------------------------------------------------------------------------- # Check if config out of date, update, ask to use config or not else : if configDict [ 'use_this_config' ] == False : configDict = load_config_file ( forceDefault = True ) elif configDict [ 'use_this_config' ] == 'ask' or configDict [ 'use_this_config' ] == True : if configVersion != None : configDict = check_update_config_file ( configVersion , configDict , configFileName ) if configDict [ 'use_this_config' ] == True or skipConfigChoice == True : pass else : configDict = choose_config_file ( configDict , configVersion ) else : print ( \"Error C-1: Invalid value in config file for setting 'use_this_config' - Must be 'True', 'False', or 'Ask'\" ) input ( \"Press Enter to exit...\" ) sys . exit () return configDict","title":"load_config_file()"},{"location":"reference/Scripts/files/#Scripts.files.parse_comment_list","text":"parse_comment_list ( config , recovery = False , removal = False , returnFileName = False ) Source code in Scripts/files.py 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 def parse_comment_list ( config , recovery = False , removal = False , returnFileName = False ): if recovery == True : actionVerb = \"recover\" actionNoun = \"recovery\" elif removal == True : actionVerb = \"remove\" actionNoun = \"removal\" validFile = False manuallyEnter = False while validFile == False and manuallyEnter == False : print ( \"--------------------------------------------------------------------------------\" ) print ( f \" \\n Enter the { F . YELLOW } name of the log file { S . R } with the comments to { actionVerb } (you can rename it to something easier like \\' log.rtf \\' )\" ) print ( f \" > { F . BLACK }{ B . LIGHTGREEN_EX } TIP: { S . R } You can just drag the file into this window instead of typing it\" ) print ( F \" { F . YELLOW } Or: { S . R } Just hit Enter to manually paste in the list of IDs next)\" ) listFileName = input ( \" \\n Log File Name (Example: \\\" log.rtf \\\" or \\\" log \\\" ): \" ) if str ( listFileName ) . lower () == \"x\" : return \"MainMenu\" , None listFileName = listFileName . strip ( \" \\\" \" ) . strip ( \"'\" ) # Remove quotes, if added by dragging and dropping or pasting path if len ( listFileName ) > 0 : if os . path . exists ( listFileName ): pass elif os . path . exists ( listFileName + \".rtf\" ): listFileName = listFileName + \".rtf\" elif os . path . exists ( listFileName + \".txt\" ): listFileName = listFileName + \".txt\" else : # Try in the log folder listFileName = os . path . join ( config [ 'log_path' ], listFileName ) if os . path . exists ( listFileName ): pass elif os . path . exists ( listFileName + \".rtf\" ): listFileName = listFileName + \".rtf\" elif os . path . exists ( listFileName + \".txt\" ): listFileName = listFileName + \".txt\" # Get file path if os . path . exists ( listFileName ): try : with open ( listFileName , 'r' , encoding = \"utf-8\" ) as listFile : data = listFile . read () listFile . close () validFile = True except : print ( f \" { F . RED } Error Code F-5: { S . R } Log File was found but there was a problem reading it.\" ) else : print ( f \" \\n { F . LIGHTRED_EX } Error: File not found. { S . R } Make sure it is in the same folder as the program. \\n \" ) print ( f \"Enter ' { F . YELLOW } Y { S . R } ' to try again, or ' { F . YELLOW } N { S . R } ' to manually paste in the comment IDs.\" ) userChoice = choice ( \"Try entering file name again?\" ) if userChoice == True : pass elif userChoice == False : manuallyEnter = True elif userChoice == None : return \"MainMenu\" , None else : manuallyEnter = True if manuallyEnter == True : print ( \" \\n\\n --- Manual Comment ID Entry Instructions ---\" ) print ( f \"1. { F . YELLOW } Open the log file { S . R } and look for where it shows the list of { F . YELLOW } \\\" IDs of Matched Comments \\\" . { S . R } \" ) print ( f \"2. { F . YELLOW } Copy that list { S . R } , and { F . YELLOW } paste it below { S . R } (In windows console try pasting by right clicking).\" ) print ( \"3. If not using a log file, instead enter the ID list in this format: FirstID, SecondID, ThirdID, ... \\n \" ) data = str ( input ( \"Paste the list here, then hit Enter: \" )) if str ( data ) . lower () == \"x\" : return \"MainMenu\" , None print ( \" \\n \" ) # Parse data into list if manuallyEnter == False and '[' in data and ']' in data : matchBetweenBrackets = '(?<=\\[)(.*?)(?=\\])' # Matches text between first set of two square brackets #matchIncludeBracktes = '\\[(.*?)\\]' # Matches between square brackets, including brackets resultList = str ( re . search ( matchBetweenBrackets , data ) . group ( 0 )) else : resultList = data resultList = resultList . replace ( \" \\' \" , \"\" ) resultList = resultList . replace ( \"[\" , \"\" ) resultList = resultList . replace ( \"]\" , \"\" ) resultList = resultList . replace ( \" \" , \"\" ) resultList = resultList . split ( \",\" ) if len ( resultList ) == 0 : print ( f \" \\n { F . RED } Error Code R-1: { S . R } No comment IDs detected, try entering them manually and make sure they are formatted correctly.\" ) input ( \" \\n Press Enter to return to main menu...\" ) return \"MainMenu\" , None # Check for valid comment IDs validCount = 0 notValidCount = 0 notValidList = [] for id in resultList : if id [ 0 : 2 ] == \"Ug\" : validCount += 1 else : notValidCount += 1 notValidList . append ( id ) if notValidCount > 0 : print ( f \" { F . YELLOW } Possibly Invalid Comment IDs: { S . R } \" + str ( notValidList ) + \" \\n \" ) if notValidCount == 0 : print ( f \" \\n { F . GREEN } Loaded all { str ( validCount ) } comment IDs successfully! { S . R } \" ) input ( f \" \\n Press Enter to begin { actionNoun } ... \" ) elif validCount > 0 and notValidCount > 0 : print ( f \" { F . RED } Warning! { S . R } { str ( validCount ) } valid comment IDs loaded successfully, but { str ( notValidCount ) } may be invalid. See them above.\" ) input ( f \" \\n Press Enter to try { actionNoun } anyway... \\n \" ) elif validCount == 0 and notValidCount > 0 : print ( f \" \\n { F . RED } Warning! { S . R } All loaded comment IDs appear to be invalid. See them above.\" ) input ( f \"Press Enter to try { actionNoun } anyway... \\n \" ) if returnFileName == False : return resultList , None else : return resultList , pathlib . Path ( os . path . relpath ( listFileName )) . stem","title":"parse_comment_list()"},{"location":"reference/Scripts/files/#Scripts.files.read_dict_pickle_file","text":"read_dict_pickle_file ( fileNameNoPath , relativeFolderPath = RESOURCES_FOLDER_NAME ) Source code in Scripts/files.py 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 def read_dict_pickle_file ( fileNameNoPath , relativeFolderPath = RESOURCES_FOLDER_NAME ): failedAttemptCount = 0 fileNameWithPath = os . path . join ( relativeFolderPath , fileNameNoPath ) while True and not failedAttemptCount > 2 : if os . path . exists ( fileNameWithPath ): failedAttemptCount = 0 while True and not failedAttemptCount > 2 : try : with open ( fileNameWithPath , 'rb' ) as pickleFile : #dictToRead = json.load(jsonFile) dictToRead = pickle . load ( pickleFile ) pickleFile . close () return dictToRead except : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when reading your pickle file. Is it in use? Try closing it.\" ) input ( f \" \\n Press Enter to try loading file again: { fileNameWithPath } \" ) failedAttemptCount += 1 return False else : print ( f \" \\n File ' { fileNameNoPath } ' not found! Try entering the name manually.\" ) input ( f \" \\n Press Enter to try loading file again: { fileNameWithPath } \" ) failedAttemptCount += 1 return False","title":"read_dict_pickle_file()"},{"location":"reference/Scripts/files/#Scripts.files.try_remove_file","text":"try_remove_file ( fileNameWithPath ) Source code in Scripts/files.py 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 def try_remove_file ( fileNameWithPath ): attempts = 1 while attempts < 3 : try : os . remove ( fileNameWithPath ) return True except : print ( f \" \\n { F . RED } \\n ERROR: { S . R } Could not remove file: ' { fileNameWithPath } '. Is it open? If so, try closing it.\" ) input ( \" \\n Press Enter to try again...\" ) attempts += 1 print ( f \" \\n { F . RED } \\n ERROR: { S . R } The File ' { fileNameWithPath } ' still could not be removed. You may have to delete it yourself.\" ) input ( \" \\n Press Enter to continue...\" ) return False","title":"try_remove_file()"},{"location":"reference/Scripts/files/#Scripts.files.write_dict_pickle_file","text":"write_dict_pickle_file ( dictToWrite , fileName , relativeFolderPath = RESOURCES_FOLDER_NAME , forceOverwrite = False ) Source code in Scripts/files.py 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 def write_dict_pickle_file ( dictToWrite , fileName , relativeFolderPath = RESOURCES_FOLDER_NAME , forceOverwrite = False ): fileNameWithPath = os . path . join ( relativeFolderPath , fileName ) success = False while success == False : if os . path . isdir ( relativeFolderPath ): success = True else : try : os . mkdir ( relativeFolderPath ) success = True except : print ( f \"Error: Could not create folder. Try creating the folder { relativeFolderPath } to continue.\" ) input ( \"Press Enter to try again...\" ) if os . path . exists ( fileNameWithPath ): if forceOverwrite == False : print ( f \" \\n File ' { fileName } ' already exists! Either overwrite, or you'll need to enter a new name.\" ) if choice ( \"Overwrite File?\" ) == True : pass else : confirm = False while confirm == False : newFileName = input ( \" \\n Enter a new file name, NOT including the extension: \" ) + \".save\" print ( \" \\n New file name: \" + newFileName ) confirm = choice ( \"Is this correct?\" ) fileNameWithPath = os . path . join ( relativeFolderPath , newFileName ) success = False while success == False : try : with open ( fileNameWithPath , 'wb' ) as pickleFile : pickle . dump ( dictToWrite , pickleFile ) #json.dump(dictToWrite, jsonFile, indent=4) pickleFile . close () success = True except : traceback . print_exc () print ( \"--------------------------------------------------------------------------------\" ) print ( \"Something went wrong when writing your pickle file. Did you open it or something?\" ) input ( f \" \\n Press Enter to try loading file again: { fileNameWithPath } \" ) return True","title":"write_dict_pickle_file()"},{"location":"reference/Scripts/gui/","text":"ASSETS_PATH module-attribute \u00b6 ASSETS_PATH = OUTPUT_PATH / Path ( './assets' ) OUTPUT_PATH module-attribute \u00b6 OUTPUT_PATH = Path ( __file__ ) . parent CanvasObject \u00b6 Source code in Scripts/gui.py 40 41 42 43 44 45 46 47 48 49 class CanvasObject : id = 0 def __init__ ( self , canvas , canvas_id ): self . canvas = canvas # keep a reference of the canvas self . canvas_id = canvas_id # keep a reference of the item id on the canvas self . id = CanvasObject . id # each CanvasObject has its own unique id CanvasObject . id += 1 def itemconfig ( self , ** kwargs ): self . canvas . itemconfig ( self . canvas_id , kwargs ) canvas instance-attribute \u00b6 canvas = canvas canvas_id instance-attribute \u00b6 canvas_id = canvas_id id instance-attribute \u00b6 id = CanvasObject . id __init__ \u00b6 __init__ ( self , canvas , canvas_id ) Source code in Scripts/gui.py 42 43 44 45 46 def __init__ ( self , canvas , canvas_id ): self . canvas = canvas # keep a reference of the canvas self . canvas_id = canvas_id # keep a reference of the item id on the canvas self . id = CanvasObject . id # each CanvasObject has its own unique id CanvasObject . id += 1 itemconfig \u00b6 itemconfig ( self , ** kwargs ) Source code in Scripts/gui.py 48 49 def itemconfig ( self , ** kwargs ): self . canvas . itemconfig ( self . canvas_id , kwargs ) rClickbinder \u00b6 rClickbinder ( r ) Source code in Scripts/gui.py 88 89 90 91 92 93 94 95 def rClickbinder ( r ): try : for b in [ 'Text' , 'Entry' , 'Listbox' , 'Label' ]: # r . bind_class ( b , sequence = '<Button-3>' , func = rClicker , add = '' ) except TclError : print ( ' - rClickbinder, something wrong' ) pass rClicker \u00b6 rClicker ( e ) Source code in Scripts/gui.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def rClicker ( e ): #''' right click context menu for all Tk Entry and Text widgets''' try : def rClick_Copy ( e , apnd = 0 ): e . widget . event_generate ( '<Control-c>' ) def rClick_Cut ( e ): e . widget . event_generate ( '<Control-x>' ) def rClick_Paste ( e ): e . widget . event_generate ( '<Control-v>' ) e . widget . focus () nclst = [ ( ' Cut' , lambda e = e : rClick_Cut ( e )), ( ' Copy' , lambda e = e : rClick_Copy ( e )), ( ' Paste' , lambda e = e : rClick_Paste ( e )), ] rmenu = Menu ( None , tearoff = 0 , takefocus = 0 ) for ( txt , cmd ) in nclst : rmenu . add_command ( label = txt , command = cmd ) rmenu . tk_popup ( e . x_root + 40 , e . y_root + 10 , entry = \"0\" ) except TclError : print ( ' - rClick menu, something wrong' ) pass return \"break\" relative_to_assets \u00b6 relative_to_assets ( path ) Source code in Scripts/gui.py 24 25 def relative_to_assets ( path : str ) -> Path : return ASSETS_PATH / Path ( path ) resource_path \u00b6 resource_path ( relative_path ) Source code in Scripts/gui.py 29 30 31 32 33 34 35 36 def resource_path ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle #print(\"Test1\") # For Debugging #print(os.path.join(sys._MEIPASS, relative_path)) # For Debugging return os . path . join ( sys . _MEIPASS , relative_path ) #print(\"Test2\") # for Debugging #print(os.path.join(os.path.abspath(\"assets\"), relative_path)) # For debugging return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets take_input_gui \u00b6 take_input_gui ( mode , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ) Source code in Scripts/gui.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def take_input_gui ( mode , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ): validModes = [ \"string\" , \"chars\" ] if mode not in validModes : raise ValueError ( \"Invalid mode. Possible values: 'string' or 'chars'.\" ) window = Tk () window . title ( \"YT Spammer Purge\" ) window . iconphoto ( False , PhotoImage ( file = resource_path ( \"icon.png\" ))) window . geometry ( \"276x279\" ) window . configure ( bg = \"#FFFFFF\" ) #################### Functions #################### # Get text from textbox and then clear the box def submit ( boxName ): global returnText text = boxName . get () boxName . delete ( '0' , END ) if mode == \"chars\" : # Convert characters string to 'set' of characters returnText = make_char_set ( text , stripLettersNumbers = stripLettersNumbers , stripKeyboardSpecialChars = stripKeyboardSpecialChars , stripPunctuation = stripPunctuation ) outputTextBox . config ( state = 'normal' ) outputTextBox . delete ( '1.0' , END ) outputTextBox . insert ( END , returnText ) outputTextBox . config ( state = 'disabled' ) if len ( returnText ) > 0 : warningMessage . itemconfig ( state = \"hidden\" ) elif len ( returnText ) == 0 : warningMessage . itemconfig ( state = \"normal\" ) def quit (): global returnText returnText = [] window . destroy () def execute (): try : if len ( returnText ) == 0 : warningMessage . itemconfig ( state = \"normal\" ) pass elif len ( returnText ) > 0 : window . destroy () except NameError : warningMessage . itemconfig ( state = \"normal\" ) canvas = Canvas ( window , #bg = \"#FFFFFF\", bg = \"#f0f0f0\" , height = 279 , width = 276 , bd = 0 , highlightthickness = 0 , relief = \"ridge\" ) canvas . place ( x = 0 , y = 0 ) canvas . create_text ( 19.0 , 48.0 , anchor = \"nw\" , text = \"Enter Search Terms:\" , fill = \"#000000\" , font = ( \"Roboto\" , 12 * - 1 ) ) canvas . create_text ( 19.0 , 148.0 , anchor = \"nw\" , text = \"Terms will be displayed back here:\" , fill = \"#000000\" , font = ( \"Roboto\" , 12 * - 1 ) ) # Bottom text box entry_image_1 = PhotoImage ( file = resource_path ( \"outputTextBox.png\" )) entry_bg_1 = canvas . create_image ( 138.5 , 186.0 , image = entry_image_1 ) outputTextBox = Text ( bd = 0 , bg = \"#F8F8F8\" , state = \"disabled\" , highlightthickness = 0 , #tag=\"False\" ) outputTextBox . place ( x = 27.0 , y = 164.0 , width = 223.0 , height = 38.0 ) entry_image_2 = PhotoImage ( file = resource_path ( \"inputTextBox.png\" )) entry_bg_2 = canvas . create_image ( 138.5 , 85.0 , image = entry_image_2 ) inputTextBox = Entry ( bd = 0 , bg = \"#FCFCFC\" , highlightthickness = 0 ) inputTextBox . place ( x = 27.0 , y = 67.0 , width = 223.0 , height = 30.0 ) button_image_1 = PhotoImage ( file = resource_path ( \"cancelButton.png\" )) cancelButton = Button ( image = button_image_1 , borderwidth = 0 , highlightthickness = 0 , command = quit , relief = \"flat\" ) cancelButton . place ( x = 152.0 , y = 225.0 , #width=78.0, #height=32.0, width = 86.0 , height = 40.0 ) button_image_2 = PhotoImage ( file = resource_path ( \"executeButton.png\" )) executeButton = Button ( image = button_image_2 , borderwidth = 0 , highlightthickness = 0 , command = execute , relief = \"flat\" ) executeButton . place ( x = 42.0 , y = 225.0 , #width=78.0, #height=32.0 width = 86.0 , height = 40.0 ) canvas . create_text ( 32.0 , 8.0 , anchor = \"nw\" , text = \"Filter Terms Input\" , fill = \"#000000\" , font = ( \"Roboto\" , 24 * - 1 ) ) # Submit Button button_image_3 = PhotoImage ( file = resource_path ( \"inputSubmitButton.png\" )) inputSubmitButton = Button ( image = button_image_3 , borderwidth = 0 , highlightthickness = 0 , command = partial ( submit , inputTextBox ), relief = \"flat\" ) inputSubmitButton . place ( x = 174.0 , y = 110.0 , #width=71.0, #height=22.0 width = 78.0 , height = 28.0 ) # Warning about no input # Object wrapper for canvas text object, so can update it with warningMessage.itemconfig(state=warningState) warningMessage = CanvasObject ( canvas , canvas . create_text ( 19.0 , 105.0 , anchor = \"nw\" , text = \"No valid terms entered!\" , fill = \"red\" , font = ( \"Roboto\" , 12 * - 1 ), state = \"hidden\" )) inputTextBox . bind ( '<Button-3>' , rClicker , add = '' ) # Binds right click menu to inputTextBox only window . resizable ( False , False ) window . mainloop () try : window . update () except Exception as e : if \"destroyed\" in str ( e ): pass return returnText","title":"gui"},{"location":"reference/Scripts/gui/#Scripts.gui.ASSETS_PATH","text":"ASSETS_PATH = OUTPUT_PATH / Path ( './assets' )","title":"ASSETS_PATH"},{"location":"reference/Scripts/gui/#Scripts.gui.OUTPUT_PATH","text":"OUTPUT_PATH = Path ( __file__ ) . parent","title":"OUTPUT_PATH"},{"location":"reference/Scripts/gui/#Scripts.gui.CanvasObject","text":"Source code in Scripts/gui.py 40 41 42 43 44 45 46 47 48 49 class CanvasObject : id = 0 def __init__ ( self , canvas , canvas_id ): self . canvas = canvas # keep a reference of the canvas self . canvas_id = canvas_id # keep a reference of the item id on the canvas self . id = CanvasObject . id # each CanvasObject has its own unique id CanvasObject . id += 1 def itemconfig ( self , ** kwargs ): self . canvas . itemconfig ( self . canvas_id , kwargs )","title":"CanvasObject"},{"location":"reference/Scripts/gui/#Scripts.gui.CanvasObject.canvas","text":"canvas = canvas","title":"canvas"},{"location":"reference/Scripts/gui/#Scripts.gui.CanvasObject.canvas_id","text":"canvas_id = canvas_id","title":"canvas_id"},{"location":"reference/Scripts/gui/#Scripts.gui.CanvasObject.id","text":"id = CanvasObject . id","title":"id"},{"location":"reference/Scripts/gui/#Scripts.gui.CanvasObject.__init__","text":"__init__ ( self , canvas , canvas_id ) Source code in Scripts/gui.py 42 43 44 45 46 def __init__ ( self , canvas , canvas_id ): self . canvas = canvas # keep a reference of the canvas self . canvas_id = canvas_id # keep a reference of the item id on the canvas self . id = CanvasObject . id # each CanvasObject has its own unique id CanvasObject . id += 1","title":"__init__()"},{"location":"reference/Scripts/gui/#Scripts.gui.CanvasObject.itemconfig","text":"itemconfig ( self , ** kwargs ) Source code in Scripts/gui.py 48 49 def itemconfig ( self , ** kwargs ): self . canvas . itemconfig ( self . canvas_id , kwargs )","title":"itemconfig()"},{"location":"reference/Scripts/gui/#Scripts.gui.rClickbinder","text":"rClickbinder ( r ) Source code in Scripts/gui.py 88 89 90 91 92 93 94 95 def rClickbinder ( r ): try : for b in [ 'Text' , 'Entry' , 'Listbox' , 'Label' ]: # r . bind_class ( b , sequence = '<Button-3>' , func = rClicker , add = '' ) except TclError : print ( ' - rClickbinder, something wrong' ) pass","title":"rClickbinder()"},{"location":"reference/Scripts/gui/#Scripts.gui.rClicker","text":"rClicker ( e ) Source code in Scripts/gui.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def rClicker ( e ): #''' right click context menu for all Tk Entry and Text widgets''' try : def rClick_Copy ( e , apnd = 0 ): e . widget . event_generate ( '<Control-c>' ) def rClick_Cut ( e ): e . widget . event_generate ( '<Control-x>' ) def rClick_Paste ( e ): e . widget . event_generate ( '<Control-v>' ) e . widget . focus () nclst = [ ( ' Cut' , lambda e = e : rClick_Cut ( e )), ( ' Copy' , lambda e = e : rClick_Copy ( e )), ( ' Paste' , lambda e = e : rClick_Paste ( e )), ] rmenu = Menu ( None , tearoff = 0 , takefocus = 0 ) for ( txt , cmd ) in nclst : rmenu . add_command ( label = txt , command = cmd ) rmenu . tk_popup ( e . x_root + 40 , e . y_root + 10 , entry = \"0\" ) except TclError : print ( ' - rClick menu, something wrong' ) pass return \"break\"","title":"rClicker()"},{"location":"reference/Scripts/gui/#Scripts.gui.relative_to_assets","text":"relative_to_assets ( path ) Source code in Scripts/gui.py 24 25 def relative_to_assets ( path : str ) -> Path : return ASSETS_PATH / Path ( path )","title":"relative_to_assets()"},{"location":"reference/Scripts/gui/#Scripts.gui.resource_path","text":"resource_path ( relative_path ) Source code in Scripts/gui.py 29 30 31 32 33 34 35 36 def resource_path ( relative_path ): if hasattr ( sys , '_MEIPASS' ): # If running as a pyinstaller bundle #print(\"Test1\") # For Debugging #print(os.path.join(sys._MEIPASS, relative_path)) # For Debugging return os . path . join ( sys . _MEIPASS , relative_path ) #print(\"Test2\") # for Debugging #print(os.path.join(os.path.abspath(\"assets\"), relative_path)) # For debugging return os . path . join ( os . path . abspath ( \"assets\" ), relative_path ) # If running as script, specifies resource folder as /assets","title":"resource_path()"},{"location":"reference/Scripts/gui/#Scripts.gui.take_input_gui","text":"take_input_gui ( mode , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ) Source code in Scripts/gui.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def take_input_gui ( mode , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ): validModes = [ \"string\" , \"chars\" ] if mode not in validModes : raise ValueError ( \"Invalid mode. Possible values: 'string' or 'chars'.\" ) window = Tk () window . title ( \"YT Spammer Purge\" ) window . iconphoto ( False , PhotoImage ( file = resource_path ( \"icon.png\" ))) window . geometry ( \"276x279\" ) window . configure ( bg = \"#FFFFFF\" ) #################### Functions #################### # Get text from textbox and then clear the box def submit ( boxName ): global returnText text = boxName . get () boxName . delete ( '0' , END ) if mode == \"chars\" : # Convert characters string to 'set' of characters returnText = make_char_set ( text , stripLettersNumbers = stripLettersNumbers , stripKeyboardSpecialChars = stripKeyboardSpecialChars , stripPunctuation = stripPunctuation ) outputTextBox . config ( state = 'normal' ) outputTextBox . delete ( '1.0' , END ) outputTextBox . insert ( END , returnText ) outputTextBox . config ( state = 'disabled' ) if len ( returnText ) > 0 : warningMessage . itemconfig ( state = \"hidden\" ) elif len ( returnText ) == 0 : warningMessage . itemconfig ( state = \"normal\" ) def quit (): global returnText returnText = [] window . destroy () def execute (): try : if len ( returnText ) == 0 : warningMessage . itemconfig ( state = \"normal\" ) pass elif len ( returnText ) > 0 : window . destroy () except NameError : warningMessage . itemconfig ( state = \"normal\" ) canvas = Canvas ( window , #bg = \"#FFFFFF\", bg = \"#f0f0f0\" , height = 279 , width = 276 , bd = 0 , highlightthickness = 0 , relief = \"ridge\" ) canvas . place ( x = 0 , y = 0 ) canvas . create_text ( 19.0 , 48.0 , anchor = \"nw\" , text = \"Enter Search Terms:\" , fill = \"#000000\" , font = ( \"Roboto\" , 12 * - 1 ) ) canvas . create_text ( 19.0 , 148.0 , anchor = \"nw\" , text = \"Terms will be displayed back here:\" , fill = \"#000000\" , font = ( \"Roboto\" , 12 * - 1 ) ) # Bottom text box entry_image_1 = PhotoImage ( file = resource_path ( \"outputTextBox.png\" )) entry_bg_1 = canvas . create_image ( 138.5 , 186.0 , image = entry_image_1 ) outputTextBox = Text ( bd = 0 , bg = \"#F8F8F8\" , state = \"disabled\" , highlightthickness = 0 , #tag=\"False\" ) outputTextBox . place ( x = 27.0 , y = 164.0 , width = 223.0 , height = 38.0 ) entry_image_2 = PhotoImage ( file = resource_path ( \"inputTextBox.png\" )) entry_bg_2 = canvas . create_image ( 138.5 , 85.0 , image = entry_image_2 ) inputTextBox = Entry ( bd = 0 , bg = \"#FCFCFC\" , highlightthickness = 0 ) inputTextBox . place ( x = 27.0 , y = 67.0 , width = 223.0 , height = 30.0 ) button_image_1 = PhotoImage ( file = resource_path ( \"cancelButton.png\" )) cancelButton = Button ( image = button_image_1 , borderwidth = 0 , highlightthickness = 0 , command = quit , relief = \"flat\" ) cancelButton . place ( x = 152.0 , y = 225.0 , #width=78.0, #height=32.0, width = 86.0 , height = 40.0 ) button_image_2 = PhotoImage ( file = resource_path ( \"executeButton.png\" )) executeButton = Button ( image = button_image_2 , borderwidth = 0 , highlightthickness = 0 , command = execute , relief = \"flat\" ) executeButton . place ( x = 42.0 , y = 225.0 , #width=78.0, #height=32.0 width = 86.0 , height = 40.0 ) canvas . create_text ( 32.0 , 8.0 , anchor = \"nw\" , text = \"Filter Terms Input\" , fill = \"#000000\" , font = ( \"Roboto\" , 24 * - 1 ) ) # Submit Button button_image_3 = PhotoImage ( file = resource_path ( \"inputSubmitButton.png\" )) inputSubmitButton = Button ( image = button_image_3 , borderwidth = 0 , highlightthickness = 0 , command = partial ( submit , inputTextBox ), relief = \"flat\" ) inputSubmitButton . place ( x = 174.0 , y = 110.0 , #width=71.0, #height=22.0 width = 78.0 , height = 28.0 ) # Warning about no input # Object wrapper for canvas text object, so can update it with warningMessage.itemconfig(state=warningState) warningMessage = CanvasObject ( canvas , canvas . create_text ( 19.0 , 105.0 , anchor = \"nw\" , text = \"No valid terms entered!\" , fill = \"red\" , font = ( \"Roboto\" , 12 * - 1 ), state = \"hidden\" )) inputTextBox . bind ( '<Button-3>' , rClicker , add = '' ) # Binds right click menu to inputTextBox only window . resizable ( False , False ) window . mainloop () try : window . update () except Exception as e : if \"destroyed\" in str ( e ): pass return returnText","title":"take_input_gui()"},{"location":"reference/Scripts/logging/","text":"add_sample \u00b6 add_sample ( current , authorID , authorNameRaw , commentText , matchReason ) Source code in Scripts/logging.py 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 def add_sample ( current , authorID , authorNameRaw , commentText , matchReason ): # Make index number and string formatted version index = len ( current . matchSamplesDict ) + 1 iString = f \" { str ( index ) } . \" . ljust ( 4 ) authorNumComments = current . authorMatchCountDict [ authorID ] cString = f \"[x { str ( authorNumComments ) } ] \" . ljust ( 7 ) # Left Justify Author Name and Comment Text if len ( authorNameRaw ) > 20 : authorName = authorNameRaw [ 0 : 17 ] + \"...\" authorName = authorName [ 0 : 20 ] . ljust ( 20 ) + \": \" else : authorName = authorNameRaw [ 0 : 20 ] . ljust ( 20 ) + \": \" commentText = str ( commentText ) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) if len ( commentText ) > 82 : commentText = commentText [ 0 : 79 ] + \"...\" commentText = commentText [ 0 : 82 ] . ljust ( 82 ) # Add comment sample, author ID, name, and counter current . matchSamplesDict [ authorID ] = { 'index' : index , 'cString' : cString , 'iString' : iString , 'count' : authorNumComments , 'authorID' : authorID , 'authorName' : authorNameRaw , 'nameAndText' : authorName + commentText , 'matchReason' : matchReason } download_profile_pictures \u00b6 download_profile_pictures ( pictureUrlsDict , jsonSettingsDict ) Source code in Scripts/logging.py 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 def download_profile_pictures ( pictureUrlsDict , jsonSettingsDict ): fileName = jsonSettingsDict [ 'jsonLogFileName' ] logtime = jsonSettingsDict [ 'logTime' ] # To have the same name as the log file imageFolderName = \"ProfileImages_\" + logtime logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) imageFolderPath = os . path . join ( logFolderPath , imageFolderName ) logtime = jsonSettingsDict [ 'logTime' ] # To have the same name as the log file block_size = 1048576 # 1 MiB if not os . path . isdir ( imageFolderPath ): try : os . mkdir ( imageFolderPath ) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Unable to create image folder. Try creating a folder called 'ProfileImages' in the log file folder.\" ) return False , None attempts = 0 success = False print ( \" \\n Fetching Profile Pictures...\" ) # Download and save pictures while success == False : try : attempts += 1 for channelID , pictureURL in pictureUrlsDict . items (): filedownload = requests . get ( pictureURL , stream = True ) downloadFileName = channelID + \".jpg\" # Make absolute path downloadFileName = os . path . join ( imageFolderPath , channelID + \".jpg\" ) with open ( downloadFileName , 'wb' ) as file : for data in filedownload . iter_content ( block_size ): file . write ( data ) success = True print ( \"Successfully downloaded profile pictures.\" ) except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Downloading Profile Pictures? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break get_extra_json_data \u00b6 get_extra_json_data ( channelIDs , jsonSettingsDict ) Source code in Scripts/logging.py 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 def get_extra_json_data ( channelIDs , jsonSettingsDict ): channelOwnerID = jsonSettingsDict [ 'channelOwnerID' ] channelOwnerName = jsonSettingsDict [ 'channelOwnerName' ] getPicsBool = False # Construct extra json data dictionary jsonExtraDataDict = { \"Comments\" : {}, \"CommentAuthorInfo\" : {}, \"UploaderInfo\" : {} } if jsonSettingsDict [ 'json_profile_picture' ] != False : getPicsBool = True pictureUrlsDict = {} resolution = jsonSettingsDict [ 'json_profile_picture' ] possibleResolutions = [ 'default' , 'medium' , 'high' ] if resolution not in possibleResolutions : print ( f \" { B . RED }{ F . BLACK } Invalid Resolution! { S . R } Defaulting to 'default' (smallest)\" ) resolution = 'default' total = len ( channelIDs ) fieldsToFetch = ( \"items/id,\" \"items/snippet/publishedAt,\" \"items/statistics\" ) if jsonSettingsDict [ 'json_profile_picture' ] != False : fieldsToFetch += f \",items/snippet/thumbnails/ { resolution } /url,items/id\" def fetch_data ( channelIdGroup ): try : response = auth . YOUTUBE . channels () . list ( part = \"snippet,statistics\" , id = channelIdGroup , fields = fieldsToFetch ) . execute () if response [ 'items' ]: for j in range ( len ( channelIdGroup )): tempDict = {} channelID = response [ 'items' ][ j ][ 'id' ] tempDict [ 'PublishedAt' ] = response [ 'items' ][ j ][ 'snippet' ][ 'publishedAt' ] tempDict [ 'Statistics' ] = response [ 'items' ][ j ][ 'statistics' ] if getPicsBool == True : picURL = response [ 'items' ][ j ][ 'snippet' ][ 'thumbnails' ][ resolution ][ 'url' ] pictureUrlsDict [ channelID ] = picURL jsonExtraDataDict [ 'CommentAuthorInfo' ][ channelID ] = tempDict except : traceback . print_exc () print ( \"Error occurred when fetching extra json data.\" ) return False # Get Extra Info About Commenters print ( \"Fetching Extra JSON Data...\" ) if total > 50 : remainder = total % 50 numDivisions = int (( total - remainder ) / 50 ) for i in range ( numDivisions ): fetch_data ( channelIDs [ i * 50 : i * 50 + 50 ]) if remainder > 0 : fetch_data ( channelIDs [ numDivisions * 50 :]) else : fetch_data ( channelIDs ) # Get info about uploader response = auth . YOUTUBE . channels () . list ( part = \"snippet,statistics\" , id = channelOwnerID , fields = fieldsToFetch ) . execute () if response [ 'items' ]: tempDict = {} tempDict [ 'PublishedAt' ] = response [ 'items' ][ 0 ][ 'snippet' ][ 'publishedAt' ] tempDict [ 'Statistics' ] = response [ 'items' ][ 0 ][ 'statistics' ] tempDict [ 'ChannelID' ] = channelOwnerID tempDict [ 'ChannelName' ] = channelOwnerName if getPicsBool == True : pictureUrlsDict [ channelOwnerID ] = response [ 'items' ][ 0 ][ 'snippet' ][ 'thumbnails' ][ resolution ][ 'url' ] jsonExtraDataDict [ 'UploaderInfo' ] = tempDict if getPicsBool == True : download_profile_pictures ( pictureUrlsDict , jsonSettingsDict ) return jsonExtraDataDict make_rtf_compatible \u00b6 make_rtf_compatible ( text ) Source code in Scripts/logging.py 290 291 292 293 294 295 296 297 298 def make_rtf_compatible ( text ): try : return text . encode ( 'rtfunicode' ) . decode ( 'utf-8' ) except : intermediate = \"\" . join ( char for char in text if unicode_category ( char ) not in [ \"Mn\" , \"Cc\" , \"Cf\" , \"Cs\" , \"Co\" , \"Cn\" ]) try : return intermediate . encode ( 'rtfunicode' ) . decode ( 'utf-8' ) except : return intermediate prepare_logFile_settings \u00b6 prepare_logFile_settings ( current , config , miscData , jsonSettingsDict , filtersDict , bypass ) Source code in Scripts/logging.py 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 def prepare_logFile_settings ( current , config , miscData , jsonSettingsDict , filtersDict , bypass ): logMode = None logFileType = None jsonLogging = False logMode = config [ 'log_mode' ] if logMode == \"rtf\" : logFileType = \".rtf\" elif logMode == \"plaintext\" : logFileType = \".txt\" else : print ( \"Invalid value for 'log_mode' in config file: \" + logMode ) print ( \"Defaulting to .rtf file\" ) logMode = \"rtf\" # Prepare log file names fileNameBase = \"Spam_Log_\" + current . logTime fileName = fileNameBase + logFileType try : # Get json logging settings if config [ 'json_log' ] == True : jsonLogging = True jsonLogFileName = fileNameBase + \".json\" jsonSettingsDict [ 'channelOwnerID' ] = miscData . channelOwnerID jsonSettingsDict [ 'channelOwnerName' ] = miscData . channelOwnerName #Encoding allowedEncodingModes = [ 'utf-8' , 'utf-16' , 'utf-32' , 'rtfunicode' ] if config [ 'json_encoding' ] in allowedEncodingModes : jsonSettingsDict [ 'encoding' ] = config [ 'json_encoding' ] elif config [ 'json_log' ] == False : jsonLogging = False else : print ( \"Invalid value for 'json_log' in config file: \" + config [ 'json_log' ]) print ( \"Defaulting to False (no json log file will be created)\" ) jsonLogging = False if config [ 'json_extra_data' ] == True : jsonSettingsDict [ 'json_extra_data' ] = True elif config [ 'json_extra_data' ] == False : jsonSettingsDict [ 'json_extra_data' ] = False if config [ 'json_profile_picture' ] != False : jsonSettingsDict [ 'json_profile_picture' ] = config [ 'json_profile_picture' ] jsonSettingsDict [ 'logTime' ] = current . logTime elif config [ 'json_profile_picture' ] == False : jsonSettingsDict [ 'json_profile_picture' ] = False except KeyError : print ( \"Problem getting json settings, is your config file correct?\" ) # Set where to put log files defaultLogPath = \"logs\" if config [ 'log_path' ]: if config [ 'log_path' ] == \"default\" : # For backwards compatibility, can remove later on logPath = defaultLogPath else : logPath = config [ 'log_path' ] current . logFileName = os . path . normpath ( logPath + \"/\" + fileName ) print ( f \"Log file will be located at { F . YELLOW } \" + current . logFileName + f \" { S . R } \\n \" ) if jsonLogging == True : jsonLogFileName = os . path . normpath ( logPath + \"/\" + jsonLogFileName ) jsonSettingsDict [ 'jsonLogFileName' ] = jsonLogFileName print ( f \"JSON log file will be located at { F . YELLOW } \" + jsonLogFileName + f \" { S . R } \\n \" ) else : current . logFileName = os . path . normpath ( defaultLogPath + \"/\" + fileName ) print ( f \"Log file will be called { F . YELLOW } \" + current . logFileName + f \" { S . R } \\n \" ) if bypass == False : input ( f \"Press { F . YELLOW } Enter { S . R } to display comments...\" ) # Write heading info to log file write_log_heading ( current , logMode , filtersDict ) jsonSettingsDict [ 'jsonLogging' ] = jsonLogging return current , logMode , jsonSettingsDict print_comments \u00b6 print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode = None , doWritePrint = True ) Source code in Scripts/logging.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode = None , doWritePrint = True ): j = 0 # Counting index when going through comments all comment segments commentsContents = \"\" # Print filter matched comments j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . matchedCommentsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Filter Match\" ) # Print comments of other match types if current . spamThreadsDict : j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . spamThreadsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Spam Bot Thread\" ) if current . otherCommentsByMatchedAuthorsDict : j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . otherCommentsByMatchedAuthorsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Also By Matched Author\" ) if current . duplicateCommentsDict : j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . duplicateCommentsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Duplicate\" ) # Writes everything to the log file if loggingEnabled == True and doWritePrint : print ( \" Writing to log file, please wait...\" , end = \" \\r \" ) if logMode == \"rtf\" : write_rtf ( current . logFileName , commentsContents ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , commentsContents ) print ( \" \" ) # Print Sample Match List valuesPreparedToWrite = \"\" valuesPreparedToPrint = \"\" matchSamplesContent = \"\" spamThreadValuesPreparedToWrite = \"\" spamThreadValuesPreparedToPrint = \"\" spamThreadSamplesContent = \"\" duplicateValuesToWrite = \"\" duplicateValuesToPrint = \"\" duplicateSamplesContent = \"\" hasDuplicates = False hasSpamThreads = False def print_and_write ( value , writeValues , printValues ): if loggingEnabled == True and logMode == \"rtf\" : writeValues = writeValues + value [ 'iString' ] + value [ 'cString' ] + f \" { str ( value [ 'authorID' ]) } | { make_rtf_compatible ( str ( value [ 'nameAndText' ])) } \\\\ line \\n \" elif loggingEnabled == True and logMode == \"plaintext\" : writeValues = writeValues + value [ 'iString' ] + value [ 'cString' ] + f \" { str ( value [ 'authorID' ]) } | { str ( value [ 'nameAndText' ]) } \\n \" if doWritePrint : printValues = printValues + value [ 'iString' ] + value [ 'cString' ] + f \" { str ( value [ 'nameAndText' ]) } \\n \" return writeValues , printValues if doWritePrint : print ( f \" { F . LIGHTMAGENTA_EX } ============================ Match Samples: One comment per matched-comment author ============================ { S . R } \" ) for value in current . matchSamplesDict . values (): if value [ 'matchReason' ] != \"Duplicate\" and value [ 'matchReason' ] != \"Spam Bot Thread\" : valuesPreparedToWrite , valuesPreparedToPrint = print_and_write ( value , valuesPreparedToWrite , valuesPreparedToPrint ) # If there are duplicates, save those to print later, but get ready by calculating some duplicate info elif value [ 'matchReason' ] == \"Duplicate\" : hasDuplicates = True similarity = str ( round ( float ( config [ 'levenshtein_distance' ]) * 100 )) + \"%\" minDupes = str ( config [ 'minimum_duplicates' ]) elif value [ 'matchReason' ] == \"Spam Bot Thread\" : hasSpamThreads = True if doWritePrint : print ( valuesPreparedToPrint ) # Print Spam Thread Match Samples if hasSpamThreads == True : if doWritePrint : print ( f \" { S . BRIGHT }{ F . MAGENTA } ============================ Match Samples: Spam Bot Threads ============================ { S . R } \" ) for value in current . matchSamplesDict . values (): if value [ 'matchReason' ] == \"Spam Bot Thread\" : spamThreadValuesPreparedToWrite , spamThreadValuesPreparedToPrint = print_and_write ( value , spamThreadValuesPreparedToWrite , spamThreadValuesPreparedToPrint ) if doWritePrint : print ( spamThreadValuesPreparedToPrint ) # Print Duplicates Match Samples if hasDuplicates == True : if doWritePrint : print ( f \" { F . LIGHTMAGENTA_EX } ------------------------- { S . BRIGHT }{ F . WHITE }{ B . BLUE } Non-Matched { S . R }{ F . LIGHTCYAN_EX } Commenters, But Who Wrote Many Similar Comments { F . LIGHTMAGENTA_EX } ------------------------- { S . R } \" ) print ( f \" { F . MAGENTA } ---------------------------- ( { F . LIGHTBLUE_EX } Similarity Threshold: { similarity } | Minimum Duplicates: { minDupes }{ F . MAGENTA } ) ---------------------------- { S . R } \" ) for value in current . matchSamplesDict . values (): if value [ 'matchReason' ] == \"Duplicate\" : duplicateValuesToWrite , duplicateValuesToPrint = print_and_write ( value , duplicateValuesToWrite , duplicateValuesToPrint ) if doWritePrint : print ( duplicateValuesToPrint ) # -------------------------------------------------- # Write just match Samples to log, after header and comment contents already in place if loggingEnabled == True : if logMode == \"rtf\" : matchSamplesContent = \"==================== Match Samples: One comment per matched-comment author ==================== \\\\ line \\\\ line \\n \" + valuesPreparedToWrite if doWritePrint : write_rtf ( current . logFileName , matchSamplesContent ) if current . spamThreadsDict : spamThreadSamplesContent = \" \\n \\\\ line \\\\ line ============================ Match Samples: Spam Bot Threads ============================ \\\\ line \\\\ line \\n \" + spamThreadValuesPreparedToWrite if doWritePrint : write_rtf ( current . logFileName , spamThreadSamplesContent ) if hasDuplicates == True : duplicateSamplesContent = \" \\n \\\\ line \\\\ line -------------------- Non-Matched Commenters, but who wrote many similar comments -------------------- \\\\ line \\n \" duplicateSamplesContent += f \"---------------------- ( Similarity Threshold: { similarity } | Minimum Duplicates: { minDupes } ) ---------------------- \\\\ line \\\\ line \\n \" + duplicateValuesToWrite if doWritePrint : write_rtf ( current . logFileName , duplicateSamplesContent ) elif logMode == \"plaintext\" : matchSamplesContent = \"==================== Match Samples: One comment per matched-comment author ==================== \\n \" + valuesPreparedToWrite if doWritePrint : write_plaintext_log ( current . logFileName , matchSamplesContent ) if current . spamThreadsDict : spamThreadSamplesContent = \" \\n ============================ Match Samples: Spam Bot Threads ============================ \\n \" + spamThreadValuesPreparedToWrite if doWritePrint : write_plaintext_log ( current . logFileName , spamThreadSamplesContent ) if hasDuplicates == True : duplicateSamplesContent = \" \\n -------------------- Non-Matched Commenters, but who wrote many similar comments -------------------- \\n \" duplicateSamplesContent += f \"---------------------- ( Similarity Threshold: { similarity } | Minimum Duplicates: { minDupes } ) ---------------------- \\n \" + duplicateValuesToWrite if doWritePrint : write_plaintext_log ( current . logFileName , duplicateSamplesContent ) # Entire Contents of Log File logFileContents = commentsContents + matchSamplesContent + spamThreadSamplesContent + duplicateSamplesContent else : logFileContents = None logMode = None if doWritePrint : print ( f \" { F . LIGHTMAGENTA_EX } ==================== (See log file for channel IDs of matched authors above) ==================== { S . R } \" ) return logFileContents , logMode print_prepared_comments \u00b6 print_prepared_comments ( current , commentsContents , scanVideoID , comments , j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason ) Source code in Scripts/logging.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def print_prepared_comments ( current , commentsContents , scanVideoID , comments , j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason ): if matchReason != \"Filter Match\" : dividerString = \"============================================================================================\" if matchReason == \"Also By Matched Author\" : reasonString = \"======================== All Non-matched Comments by Authors Above ========================\" elif matchReason == \"Duplicate\" : reasonString = \"=========================== Non-Matched, But Duplicate Comments ===========================\" elif matchReason == \"Spam Bot Thread\" : reasonString = \"============================ Spam Bot Thread Top-Level Comments ===========================\" # -------------------- Print Section Header -------------------- # Print top divider if doWritePrint : print ( f \" \\n\\n { dividerString } \" ) if logMode == \"rtf\" : commentsContents = commentsContents + f \" \\\\ line \\\\ line \\n\\n { dividerString } \" elif logMode == \"plaintext\" : commentsContents = commentsContents + f \" \\n\\n { dividerString } \" # Print header text if doWritePrint : print ( f \" { reasonString } \" ) if logMode == \"rtf\" : commentsContents = commentsContents + f \" \\\\ line \\n { reasonString } \" elif logMode == \"plaintext\" : commentsContents = commentsContents + f \" \\n { reasonString } \" # Print bottom divider if doWritePrint : print ( f \" { dividerString } \\n \" ) if logMode == \"rtf\" : commentsContents = commentsContents + f \" \\\\ line \\n { dividerString } \\\\ line \\\\ line \\n\\n \" elif logMode == \"plaintext\" : commentsContents = commentsContents + f \" \\n { dividerString } \\n\\n \" # ----------------------------------------------------------------- for comment in comments : if matchReason == \"Filter Match\" : metadata = current . matchedCommentsDict [ comment ] elif matchReason == \"Duplicate\" : metadata = current . duplicateCommentsDict [ comment ] elif matchReason == \"Also By Matched Author\" : metadata = current . otherCommentsByMatchedAuthorsDict [ comment ] elif matchReason == \"Spam Bot Thread\" : metadata = current . spamThreadsDict [ comment ] # For printing and regular logging text = metadata [ 'text' ] author = metadata [ 'authorName' ] author_id_local = metadata [ 'authorID' ] comment_id_local = comment videoID = metadata [ 'videoID' ] matchReason = metadata [ 'matchReason' ] # Truncates very long comments, and removes excessive multiple lines if len ( text ) > 1500 : text = text [ 0 : 1500 ] + \"[Comment Truncated by YT SPammer Purge]\" if text . count ( \" \\n \" ) > 0 : text = text . replace ( \" \\n \" , \" \" ) # Add one sample from each matching author to current.matchSamplesDict, containing author ID, name, and text if matchReason != \"Also By Matched Author\" and author_id_local not in current . matchSamplesDict . keys (): add_sample ( current , author_id_local , author , text , matchReason ) # Build comment direct link if scanMode == \"communityPost\" or scanMode == \"recentCommunityPosts\" : directLink = \"https://www.youtube.com/post/\" + videoID + \"?lc=\" + comment_id_local else : directLink = \"https://www.youtube.com/watch?v=\" + videoID + \"&lc=\" + comment_id_local # Prints comment info to console if doWritePrint : print ( str ( j + 1 ) + f \". { F . LIGHTCYAN_EX } \" + author + f \" { S . R } : { F . YELLOW } \" + text + f \" { S . R } \" ) print ( \"\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\" ) print ( \" > Reason: \" + matchReason ) if scanVideoID is None : # Only print video title if searching entire channel title = utils . get_video_title ( current , videoID ) # Get Video Title if doWritePrint : print ( \" > Video: \" + title ) if doWritePrint : print ( \" > Direct Link: \" + directLink ) print ( f \" > Author Channel ID: { F . LIGHTBLUE_EX } \" + author_id_local + f \" { S . R } \" ) print ( \"============================================================================================= \\n \" ) # If logging enabled, also prints to log file if loggingEnabled == True : # Only print video title info if searching entire channel if scanVideoID is None : if logMode == \"rtf\" : titleInfoLine = \" > Video: \" + title + \" \\\\ line \" + \" \\n \" elif logMode == \"plaintext\" : titleInfoLine = \" > Video: \" + title + \" \\n \" else : titleInfoLine = \"\" if logMode == \"rtf\" : commentInfo = ( # Author Info str ( j + 1 ) + r \". \\cf4\" + make_rtf_compatible ( author ) + r \"\\cf1 : \\cf5\" + make_rtf_compatible ( text ) + r \"\\cf1 \\line \" + \" \\n \" + \"--------------------------------------------------------------------------------------------- \\\\ line \" + \" \\n \" # Rest of Comment Info + \" > Reason: \" + matchReason + \" \\\\ line \" + \" \\n \" + titleInfoLine + \" > Direct Link: \" + directLink + \" \\\\ line \" + \" \\n \" + \" > Author Channel ID: \\cf6\" + author_id_local + r \"\\cf1 \\line \" + \" \\n \" + \"============================================================================================= \\\\ line \\\\ line \\\\ line\" + \" \\n\\n\\n \" ) elif logMode == \"plaintext\" : commentInfo = ( # Author Info str ( j + 1 ) + \". \" + author + \": \" + text + \" \\n \" + \"--------------------------------------------------------------------------------------------- \\n \" # Rest of Comment Info + \" > Reason: \" + matchReason + \" \\n \" + titleInfoLine + \" > Direct Link: \" + directLink + \" \\n \" + \" > Author Channel ID: \" + author_id_local + \" \\n \" + \"============================================================================================= \\n\\n\\n \" ) commentsContents = commentsContents + commentInfo # Appends comment ID to new list of comments so it's in the correct order going forward, as provided by API and presented to user # Must use append here, not extend, or else it would add each character separately j += 1 return j , commentsContents rewrite_log_file \u00b6 rewrite_log_file ( current , logInfo , combinedCommentsDict = None ) Source code in Scripts/logging.py 777 778 779 780 781 782 783 784 785 786 787 788 789 790 def rewrite_log_file ( current , logInfo , combinedCommentsDict = None ): logMode = logInfo [ 'logMode' ] logFileContents = logInfo [ 'logFileContents' ] #jsonSettingsDict = logInfo['jsonSettingsDict'] filtersDict = logInfo [ 'filtersDict' ] # Rewrites the heading, which includes list of matched Comment IDs write_log_heading ( current , logMode , filtersDict , afterExclude = True , combinedCommentsDict = combinedCommentsDict ) # Rewrites the rest of the log file contents after the heading if logMode == \"rtf\" : write_rtf ( current . logFileName , logFileContents ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , logFileContents ) write_json_log \u00b6 write_json_log ( jsonSettingsDict , commentsDict , jsonDataDict = None ) Source code in Scripts/logging.py 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 def write_json_log ( jsonSettingsDict , commentsDict , jsonDataDict = None ): success = False attempts = 0 if jsonDataDict : jsonDataDict [ 'Comments' ] = commentsDict dictionaryToWrite = jsonDataDict else : dictionaryToWrite = commentsDict fileName = jsonSettingsDict [ 'jsonLogFileName' ] jsonEncoding = jsonSettingsDict [ 'encoding' ] # If directory does not exist for desired log file path, create it logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) if not os . path . isdir ( logFolderPath ): try : os . mkdir ( logFolderPath ) # If relative path, make it absolute if not os . path . isabs ( fileName ): fileName = os . path . join ( logFolderPath , os . path . basename ( fileName )) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Could not create desired directory for log files. Will place them in current directory.\" ) fileName = os . path . basename ( fileName ) while success == False : try : attempts += 1 with open ( fileName , \"w\" , encoding = jsonEncoding ) as file : file . write ( json . dumps ( dictionaryToWrite , indent = 4 , ensure_ascii = False )) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break write_log_completion_summary \u00b6 write_log_completion_summary ( current , exclude , logMode , banChoice , deletionModeFriendlyName , removeOtherAuthorComments ) Source code in Scripts/logging.py 765 766 767 768 769 770 771 772 773 774 def write_log_completion_summary ( current , exclude , logMode , banChoice , deletionModeFriendlyName , removeOtherAuthorComments ): if logMode == \"rtf\" : write_rtf ( current . logFileName , \" \\n\\n\\\\ line \\\\ line Spammers Banned: \" + str ( banChoice )) write_rtf ( current . logFileName , \" \\n\\n\\\\ line \\\\ line Action Taken on Comments: \" + str ( deletionModeFriendlyName ) + \" \\\\ line \\\\ line \\n\\n \" ) write_rtf ( current . logFileName , \" \\n\\n\\\\ line \\\\ line Also Retrieved All Other Comments by Matched Authors: \" + str ( removeOtherAuthorComments ) + \" \\\\ line \\\\ line \\n\\n \" ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , \" \\n\\n Spammers Banned: \" + str ( banChoice ) + \" \\n\\n \" ) write_plaintext_log ( current . logFileName , \"Action Taken on Comments: \" + str ( deletionModeFriendlyName ) + \" \\n\\n \" ) write_plaintext_log ( current . logFileName , \"Also Retrieved All Other Comments by Matched Authors: \" + str ( removeOtherAuthorComments ) + \" \\n\\n \" ) write_log_heading \u00b6 write_log_heading ( current , logMode , filtersDict , afterExclude = False , combinedCommentsDict = None ) Source code in Scripts/logging.py 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 def write_log_heading ( current , logMode , filtersDict , afterExclude = False , combinedCommentsDict = None ): if combinedCommentsDict == None : combinedCommentsDict = dict ( current . matchedCommentsDict ) combinedCommentsDict . update ( current . spamThreadsDict ) combinedCommentsDict . update ( current . duplicateCommentsDict ) filterMode = filtersDict [ 'filterMode' ] inputtedSpammerChannelID = filtersDict [ 'CustomChannelIdFilter' ] inputtedUsernameFilter = filtersDict [ 'CustomUsernameFilter' ] inputtedCommentTextFilter = filtersDict [ 'CustomCommentTextFilter' ] filterSettings = filtersDict [ 'filterSettings' ] def write_func ( logFileName , string , logMode , numLines ): rtfLineEnd = ( \" \\\\ line\" * numLines ) + \" \" newLines = \" \\n \" * numLines # Just the amount of new lines to put for this line if logMode == \"rtf\" : write_rtf ( logFileName , make_rtf_compatible ( string ) + rtfLineEnd ) elif logMode == \"plaintext\" : write_plaintext_log ( logFileName , string + newLines ) # Creates log file and writes first line if logMode == \"rtf\" : write_rtf ( current . logFileName , firstWrite = True ) write_func ( current . logFileName , \"----------- YouTube Spammer Purge Log File -----------\" , logMode , 2 ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , firstWrite = True ) write_func ( current . logFileName , \"----------- YouTube Spammer Purge Log File -----------\" , logMode , 2 ) if filterMode == \"ID\" : write_func ( current . logFileName , \"Channel IDs of spammer searched: \" + \", \" . join ( inputtedSpammerChannelID ), logMode , 2 ) elif filterMode == \"Username\" : write_func ( current . logFileName , \"Characters searched in Usernames: \" + \", \" . join ( inputtedUsernameFilter ), logMode , 2 ) elif filterMode == \"Text\" : write_func ( current . logFileName , \"Characters searched in Comment Text: \" + \", \" . join ( inputtedCommentTextFilter ), logMode , 2 ) elif filterMode == \"NameAndText\" : write_func ( current . logFileName , \"Characters searched in Usernames and Comment Text: \" + \", \" . join ( inputtedCommentTextFilter ), logMode , 2 ) elif filterMode == \"AutoASCII\" : write_func ( current . logFileName , \"Automatic Search Mode: \" + str ( filterSettings [ 1 ]), logMode , 2 ) elif filterMode == \"AutoSmart\" : write_func ( current . logFileName , \"Automatic Search Mode: Smart Mode \" , logMode , 2 ) elif filterMode == \"SensitiveSmart\" : write_func ( current . logFileName , \"Automatic Search Mode: Sensitive Smart \" , logMode , 2 ) # Write number of comments for each type write_func ( current . logFileName , \"Number of Matched Comments Found: \" + str ( len ( current . matchedCommentsDict )), logMode , 2 ) write_func ( current . logFileName , \"Number of Spam Bot Threads Found: \" + str ( len ( current . spamThreadsDict )), logMode , 2 ) write_func ( current . logFileName , \"Number of Non-Matched, but Duplicate Comments Found: \" + str ( len ( current . duplicateCommentsDict )), logMode , 2 ) # How to label the comment ID list if current . duplicateCommentsDict : commentListLabel = \"IDs of Matched & Duplicate Comments\" else : commentListLabel = \"IDs of Matched Comments\" if afterExclude == True : excludeString = \" (Excluded Comments Removed)\" else : excludeString = \"\" write_func ( current . logFileName , f \" { commentListLabel }{ excludeString } : \\n [ { ', ' . join ( combinedCommentsDict ) } ] \" , logMode , 3 ) write_plaintext_log \u00b6 write_plaintext_log ( fileName , newText = None , firstWrite = False , fullWrite = False ) Source code in Scripts/logging.py 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 def write_plaintext_log ( fileName , newText = None , firstWrite = False , fullWrite = False ): success = False attempts = 0 if firstWrite == True or fullWrite == True : # If directory does not exist for desired log file path, create it logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) if not os . path . isdir ( logFolderPath ): try : os . mkdir ( logFolderPath ) # If relative path, make it absolute if not os . path . isabs ( fileName ): fileName = os . path . join ( logFolderPath , os . path . basename ( fileName )) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Could not create desired directory for log files. Will place them in current directory.\" ) fileName = os . path . basename ( fileName ) while success == False : try : attempts += 1 with open ( fileName , \"w\" , encoding = \"utf-8\" ) as file : if fullWrite == True : file . write ( newText ) else : file . write ( \"\" ) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break else : while success == False : try : attempts += 1 with open ( fileName , 'a' , encoding = \"utf-8\" ) as file : for line in newText : file . write ( line ) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break write_rtf \u00b6 write_rtf ( fileName , newText = None , firstWrite = False , fullWrite = False ) Source code in Scripts/logging.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 def write_rtf ( fileName , newText = None , firstWrite = False , fullWrite = False ): success = False attempts = 0 if firstWrite == True or fullWrite == True : # If directory does not exist for desired log file path, create it logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) if not os . path . isdir ( logFolderPath ): try : os . mkdir ( logFolderPath ) # If relative path, make it absolute if not os . path . isabs ( fileName ): fileName = os . path . join ( logFolderPath , os . path . basename ( fileName )) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Could not create desired directory for log files. Will place them in current directory.\" ) fileName = os . path . basename ( fileName ) while success == False : try : attempts += 1 with open ( fileName , 'w' , encoding = \"utf-8\" ) as file : # Some header information for RTF file, sets courier as font file . write ( r \"{\\rtf1\\ansi\\deff0 {\\fonttbl {\\f0 Courier;}}\" + \" \\n \" ) # Sets color table to be able to set colors for text, each color set with RGB values in raw string # To use color, use '\\cf1 ' (with space) for black, cf2 = red, cf3 = green, cf4 = blue, cf5 = orange, cf6 = purple # cf1 cf2 cf3 cf4 cf5 cf6 file . write ( r \"{\\colortbl;\\red0\\green0\\blue0;\\red255\\green0\\blue0;\\red0\\green255\\blue0;\\red0\\green0\\blue255;\\red143\\green81\\blue0;\\red102\\green0\\blue214;}\" + \" \\n\\n \" ) if fullWrite == True : file . write ( newText ) file . write ( r \"}\" ) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break # If the string might have unicode, use unicode mode to convert for rtf else : # Writes to line just before last, to preserve required ending bracket in rtf file # Slightly modified from: https://stackoverflow.com/a/50567967/17312053 while success == False : try : attempts += 1 with open ( fileName , 'r+' , encoding = \"utf-8\" ) as file : pos , text = 0 , '' while True : # save last line value and cursor position prev_pos , pos = pos , file . tell () prev_text , text = text , file . readline () if text == '' : # Checks for last line with only ending bracket break file . seek ( prev_pos , 0 ) # replace cursor to the last line for line in newText : # write new lines. If any brackets, add escape backslash line . replace ( \"}\" , \" \\\\ }\" ) line . replace ( \"{\" , \" \\\\ {\" ) file . write ( line ) file . write ( \" \\n }\" ) # Re-write new line with ending bracket again. Could put prev_text in here if being dynamic file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break","title":"logging"},{"location":"reference/Scripts/logging/#Scripts.logging.add_sample","text":"add_sample ( current , authorID , authorNameRaw , commentText , matchReason ) Source code in Scripts/logging.py 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 def add_sample ( current , authorID , authorNameRaw , commentText , matchReason ): # Make index number and string formatted version index = len ( current . matchSamplesDict ) + 1 iString = f \" { str ( index ) } . \" . ljust ( 4 ) authorNumComments = current . authorMatchCountDict [ authorID ] cString = f \"[x { str ( authorNumComments ) } ] \" . ljust ( 7 ) # Left Justify Author Name and Comment Text if len ( authorNameRaw ) > 20 : authorName = authorNameRaw [ 0 : 17 ] + \"...\" authorName = authorName [ 0 : 20 ] . ljust ( 20 ) + \": \" else : authorName = authorNameRaw [ 0 : 20 ] . ljust ( 20 ) + \": \" commentText = str ( commentText ) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) if len ( commentText ) > 82 : commentText = commentText [ 0 : 79 ] + \"...\" commentText = commentText [ 0 : 82 ] . ljust ( 82 ) # Add comment sample, author ID, name, and counter current . matchSamplesDict [ authorID ] = { 'index' : index , 'cString' : cString , 'iString' : iString , 'count' : authorNumComments , 'authorID' : authorID , 'authorName' : authorNameRaw , 'nameAndText' : authorName + commentText , 'matchReason' : matchReason }","title":"add_sample()"},{"location":"reference/Scripts/logging/#Scripts.logging.download_profile_pictures","text":"download_profile_pictures ( pictureUrlsDict , jsonSettingsDict ) Source code in Scripts/logging.py 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 def download_profile_pictures ( pictureUrlsDict , jsonSettingsDict ): fileName = jsonSettingsDict [ 'jsonLogFileName' ] logtime = jsonSettingsDict [ 'logTime' ] # To have the same name as the log file imageFolderName = \"ProfileImages_\" + logtime logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) imageFolderPath = os . path . join ( logFolderPath , imageFolderName ) logtime = jsonSettingsDict [ 'logTime' ] # To have the same name as the log file block_size = 1048576 # 1 MiB if not os . path . isdir ( imageFolderPath ): try : os . mkdir ( imageFolderPath ) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Unable to create image folder. Try creating a folder called 'ProfileImages' in the log file folder.\" ) return False , None attempts = 0 success = False print ( \" \\n Fetching Profile Pictures...\" ) # Download and save pictures while success == False : try : attempts += 1 for channelID , pictureURL in pictureUrlsDict . items (): filedownload = requests . get ( pictureURL , stream = True ) downloadFileName = channelID + \".jpg\" # Make absolute path downloadFileName = os . path . join ( imageFolderPath , channelID + \".jpg\" ) with open ( downloadFileName , 'wb' ) as file : for data in filedownload . iter_content ( block_size ): file . write ( data ) success = True print ( \"Successfully downloaded profile pictures.\" ) except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Downloading Profile Pictures? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break","title":"download_profile_pictures()"},{"location":"reference/Scripts/logging/#Scripts.logging.get_extra_json_data","text":"get_extra_json_data ( channelIDs , jsonSettingsDict ) Source code in Scripts/logging.py 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 def get_extra_json_data ( channelIDs , jsonSettingsDict ): channelOwnerID = jsonSettingsDict [ 'channelOwnerID' ] channelOwnerName = jsonSettingsDict [ 'channelOwnerName' ] getPicsBool = False # Construct extra json data dictionary jsonExtraDataDict = { \"Comments\" : {}, \"CommentAuthorInfo\" : {}, \"UploaderInfo\" : {} } if jsonSettingsDict [ 'json_profile_picture' ] != False : getPicsBool = True pictureUrlsDict = {} resolution = jsonSettingsDict [ 'json_profile_picture' ] possibleResolutions = [ 'default' , 'medium' , 'high' ] if resolution not in possibleResolutions : print ( f \" { B . RED }{ F . BLACK } Invalid Resolution! { S . R } Defaulting to 'default' (smallest)\" ) resolution = 'default' total = len ( channelIDs ) fieldsToFetch = ( \"items/id,\" \"items/snippet/publishedAt,\" \"items/statistics\" ) if jsonSettingsDict [ 'json_profile_picture' ] != False : fieldsToFetch += f \",items/snippet/thumbnails/ { resolution } /url,items/id\" def fetch_data ( channelIdGroup ): try : response = auth . YOUTUBE . channels () . list ( part = \"snippet,statistics\" , id = channelIdGroup , fields = fieldsToFetch ) . execute () if response [ 'items' ]: for j in range ( len ( channelIdGroup )): tempDict = {} channelID = response [ 'items' ][ j ][ 'id' ] tempDict [ 'PublishedAt' ] = response [ 'items' ][ j ][ 'snippet' ][ 'publishedAt' ] tempDict [ 'Statistics' ] = response [ 'items' ][ j ][ 'statistics' ] if getPicsBool == True : picURL = response [ 'items' ][ j ][ 'snippet' ][ 'thumbnails' ][ resolution ][ 'url' ] pictureUrlsDict [ channelID ] = picURL jsonExtraDataDict [ 'CommentAuthorInfo' ][ channelID ] = tempDict except : traceback . print_exc () print ( \"Error occurred when fetching extra json data.\" ) return False # Get Extra Info About Commenters print ( \"Fetching Extra JSON Data...\" ) if total > 50 : remainder = total % 50 numDivisions = int (( total - remainder ) / 50 ) for i in range ( numDivisions ): fetch_data ( channelIDs [ i * 50 : i * 50 + 50 ]) if remainder > 0 : fetch_data ( channelIDs [ numDivisions * 50 :]) else : fetch_data ( channelIDs ) # Get info about uploader response = auth . YOUTUBE . channels () . list ( part = \"snippet,statistics\" , id = channelOwnerID , fields = fieldsToFetch ) . execute () if response [ 'items' ]: tempDict = {} tempDict [ 'PublishedAt' ] = response [ 'items' ][ 0 ][ 'snippet' ][ 'publishedAt' ] tempDict [ 'Statistics' ] = response [ 'items' ][ 0 ][ 'statistics' ] tempDict [ 'ChannelID' ] = channelOwnerID tempDict [ 'ChannelName' ] = channelOwnerName if getPicsBool == True : pictureUrlsDict [ channelOwnerID ] = response [ 'items' ][ 0 ][ 'snippet' ][ 'thumbnails' ][ resolution ][ 'url' ] jsonExtraDataDict [ 'UploaderInfo' ] = tempDict if getPicsBool == True : download_profile_pictures ( pictureUrlsDict , jsonSettingsDict ) return jsonExtraDataDict","title":"get_extra_json_data()"},{"location":"reference/Scripts/logging/#Scripts.logging.make_rtf_compatible","text":"make_rtf_compatible ( text ) Source code in Scripts/logging.py 290 291 292 293 294 295 296 297 298 def make_rtf_compatible ( text ): try : return text . encode ( 'rtfunicode' ) . decode ( 'utf-8' ) except : intermediate = \"\" . join ( char for char in text if unicode_category ( char ) not in [ \"Mn\" , \"Cc\" , \"Cf\" , \"Cs\" , \"Co\" , \"Cn\" ]) try : return intermediate . encode ( 'rtfunicode' ) . decode ( 'utf-8' ) except : return intermediate","title":"make_rtf_compatible()"},{"location":"reference/Scripts/logging/#Scripts.logging.prepare_logFile_settings","text":"prepare_logFile_settings ( current , config , miscData , jsonSettingsDict , filtersDict , bypass ) Source code in Scripts/logging.py 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 def prepare_logFile_settings ( current , config , miscData , jsonSettingsDict , filtersDict , bypass ): logMode = None logFileType = None jsonLogging = False logMode = config [ 'log_mode' ] if logMode == \"rtf\" : logFileType = \".rtf\" elif logMode == \"plaintext\" : logFileType = \".txt\" else : print ( \"Invalid value for 'log_mode' in config file: \" + logMode ) print ( \"Defaulting to .rtf file\" ) logMode = \"rtf\" # Prepare log file names fileNameBase = \"Spam_Log_\" + current . logTime fileName = fileNameBase + logFileType try : # Get json logging settings if config [ 'json_log' ] == True : jsonLogging = True jsonLogFileName = fileNameBase + \".json\" jsonSettingsDict [ 'channelOwnerID' ] = miscData . channelOwnerID jsonSettingsDict [ 'channelOwnerName' ] = miscData . channelOwnerName #Encoding allowedEncodingModes = [ 'utf-8' , 'utf-16' , 'utf-32' , 'rtfunicode' ] if config [ 'json_encoding' ] in allowedEncodingModes : jsonSettingsDict [ 'encoding' ] = config [ 'json_encoding' ] elif config [ 'json_log' ] == False : jsonLogging = False else : print ( \"Invalid value for 'json_log' in config file: \" + config [ 'json_log' ]) print ( \"Defaulting to False (no json log file will be created)\" ) jsonLogging = False if config [ 'json_extra_data' ] == True : jsonSettingsDict [ 'json_extra_data' ] = True elif config [ 'json_extra_data' ] == False : jsonSettingsDict [ 'json_extra_data' ] = False if config [ 'json_profile_picture' ] != False : jsonSettingsDict [ 'json_profile_picture' ] = config [ 'json_profile_picture' ] jsonSettingsDict [ 'logTime' ] = current . logTime elif config [ 'json_profile_picture' ] == False : jsonSettingsDict [ 'json_profile_picture' ] = False except KeyError : print ( \"Problem getting json settings, is your config file correct?\" ) # Set where to put log files defaultLogPath = \"logs\" if config [ 'log_path' ]: if config [ 'log_path' ] == \"default\" : # For backwards compatibility, can remove later on logPath = defaultLogPath else : logPath = config [ 'log_path' ] current . logFileName = os . path . normpath ( logPath + \"/\" + fileName ) print ( f \"Log file will be located at { F . YELLOW } \" + current . logFileName + f \" { S . R } \\n \" ) if jsonLogging == True : jsonLogFileName = os . path . normpath ( logPath + \"/\" + jsonLogFileName ) jsonSettingsDict [ 'jsonLogFileName' ] = jsonLogFileName print ( f \"JSON log file will be located at { F . YELLOW } \" + jsonLogFileName + f \" { S . R } \\n \" ) else : current . logFileName = os . path . normpath ( defaultLogPath + \"/\" + fileName ) print ( f \"Log file will be called { F . YELLOW } \" + current . logFileName + f \" { S . R } \\n \" ) if bypass == False : input ( f \"Press { F . YELLOW } Enter { S . R } to display comments...\" ) # Write heading info to log file write_log_heading ( current , logMode , filtersDict ) jsonSettingsDict [ 'jsonLogging' ] = jsonLogging return current , logMode , jsonSettingsDict","title":"prepare_logFile_settings()"},{"location":"reference/Scripts/logging/#Scripts.logging.print_comments","text":"print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode = None , doWritePrint = True ) Source code in Scripts/logging.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def print_comments ( current , config , scanVideoID , loggingEnabled , scanMode , logMode = None , doWritePrint = True ): j = 0 # Counting index when going through comments all comment segments commentsContents = \"\" # Print filter matched comments j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . matchedCommentsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Filter Match\" ) # Print comments of other match types if current . spamThreadsDict : j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . spamThreadsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Spam Bot Thread\" ) if current . otherCommentsByMatchedAuthorsDict : j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . otherCommentsByMatchedAuthorsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Also By Matched Author\" ) if current . duplicateCommentsDict : j , commentsContents = print_prepared_comments ( current , commentsContents , scanVideoID , list ( current . duplicateCommentsDict . keys ()), j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason = \"Duplicate\" ) # Writes everything to the log file if loggingEnabled == True and doWritePrint : print ( \" Writing to log file, please wait...\" , end = \" \\r \" ) if logMode == \"rtf\" : write_rtf ( current . logFileName , commentsContents ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , commentsContents ) print ( \" \" ) # Print Sample Match List valuesPreparedToWrite = \"\" valuesPreparedToPrint = \"\" matchSamplesContent = \"\" spamThreadValuesPreparedToWrite = \"\" spamThreadValuesPreparedToPrint = \"\" spamThreadSamplesContent = \"\" duplicateValuesToWrite = \"\" duplicateValuesToPrint = \"\" duplicateSamplesContent = \"\" hasDuplicates = False hasSpamThreads = False def print_and_write ( value , writeValues , printValues ): if loggingEnabled == True and logMode == \"rtf\" : writeValues = writeValues + value [ 'iString' ] + value [ 'cString' ] + f \" { str ( value [ 'authorID' ]) } | { make_rtf_compatible ( str ( value [ 'nameAndText' ])) } \\\\ line \\n \" elif loggingEnabled == True and logMode == \"plaintext\" : writeValues = writeValues + value [ 'iString' ] + value [ 'cString' ] + f \" { str ( value [ 'authorID' ]) } | { str ( value [ 'nameAndText' ]) } \\n \" if doWritePrint : printValues = printValues + value [ 'iString' ] + value [ 'cString' ] + f \" { str ( value [ 'nameAndText' ]) } \\n \" return writeValues , printValues if doWritePrint : print ( f \" { F . LIGHTMAGENTA_EX } ============================ Match Samples: One comment per matched-comment author ============================ { S . R } \" ) for value in current . matchSamplesDict . values (): if value [ 'matchReason' ] != \"Duplicate\" and value [ 'matchReason' ] != \"Spam Bot Thread\" : valuesPreparedToWrite , valuesPreparedToPrint = print_and_write ( value , valuesPreparedToWrite , valuesPreparedToPrint ) # If there are duplicates, save those to print later, but get ready by calculating some duplicate info elif value [ 'matchReason' ] == \"Duplicate\" : hasDuplicates = True similarity = str ( round ( float ( config [ 'levenshtein_distance' ]) * 100 )) + \"%\" minDupes = str ( config [ 'minimum_duplicates' ]) elif value [ 'matchReason' ] == \"Spam Bot Thread\" : hasSpamThreads = True if doWritePrint : print ( valuesPreparedToPrint ) # Print Spam Thread Match Samples if hasSpamThreads == True : if doWritePrint : print ( f \" { S . BRIGHT }{ F . MAGENTA } ============================ Match Samples: Spam Bot Threads ============================ { S . R } \" ) for value in current . matchSamplesDict . values (): if value [ 'matchReason' ] == \"Spam Bot Thread\" : spamThreadValuesPreparedToWrite , spamThreadValuesPreparedToPrint = print_and_write ( value , spamThreadValuesPreparedToWrite , spamThreadValuesPreparedToPrint ) if doWritePrint : print ( spamThreadValuesPreparedToPrint ) # Print Duplicates Match Samples if hasDuplicates == True : if doWritePrint : print ( f \" { F . LIGHTMAGENTA_EX } ------------------------- { S . BRIGHT }{ F . WHITE }{ B . BLUE } Non-Matched { S . R }{ F . LIGHTCYAN_EX } Commenters, But Who Wrote Many Similar Comments { F . LIGHTMAGENTA_EX } ------------------------- { S . R } \" ) print ( f \" { F . MAGENTA } ---------------------------- ( { F . LIGHTBLUE_EX } Similarity Threshold: { similarity } | Minimum Duplicates: { minDupes }{ F . MAGENTA } ) ---------------------------- { S . R } \" ) for value in current . matchSamplesDict . values (): if value [ 'matchReason' ] == \"Duplicate\" : duplicateValuesToWrite , duplicateValuesToPrint = print_and_write ( value , duplicateValuesToWrite , duplicateValuesToPrint ) if doWritePrint : print ( duplicateValuesToPrint ) # -------------------------------------------------- # Write just match Samples to log, after header and comment contents already in place if loggingEnabled == True : if logMode == \"rtf\" : matchSamplesContent = \"==================== Match Samples: One comment per matched-comment author ==================== \\\\ line \\\\ line \\n \" + valuesPreparedToWrite if doWritePrint : write_rtf ( current . logFileName , matchSamplesContent ) if current . spamThreadsDict : spamThreadSamplesContent = \" \\n \\\\ line \\\\ line ============================ Match Samples: Spam Bot Threads ============================ \\\\ line \\\\ line \\n \" + spamThreadValuesPreparedToWrite if doWritePrint : write_rtf ( current . logFileName , spamThreadSamplesContent ) if hasDuplicates == True : duplicateSamplesContent = \" \\n \\\\ line \\\\ line -------------------- Non-Matched Commenters, but who wrote many similar comments -------------------- \\\\ line \\n \" duplicateSamplesContent += f \"---------------------- ( Similarity Threshold: { similarity } | Minimum Duplicates: { minDupes } ) ---------------------- \\\\ line \\\\ line \\n \" + duplicateValuesToWrite if doWritePrint : write_rtf ( current . logFileName , duplicateSamplesContent ) elif logMode == \"plaintext\" : matchSamplesContent = \"==================== Match Samples: One comment per matched-comment author ==================== \\n \" + valuesPreparedToWrite if doWritePrint : write_plaintext_log ( current . logFileName , matchSamplesContent ) if current . spamThreadsDict : spamThreadSamplesContent = \" \\n ============================ Match Samples: Spam Bot Threads ============================ \\n \" + spamThreadValuesPreparedToWrite if doWritePrint : write_plaintext_log ( current . logFileName , spamThreadSamplesContent ) if hasDuplicates == True : duplicateSamplesContent = \" \\n -------------------- Non-Matched Commenters, but who wrote many similar comments -------------------- \\n \" duplicateSamplesContent += f \"---------------------- ( Similarity Threshold: { similarity } | Minimum Duplicates: { minDupes } ) ---------------------- \\n \" + duplicateValuesToWrite if doWritePrint : write_plaintext_log ( current . logFileName , duplicateSamplesContent ) # Entire Contents of Log File logFileContents = commentsContents + matchSamplesContent + spamThreadSamplesContent + duplicateSamplesContent else : logFileContents = None logMode = None if doWritePrint : print ( f \" { F . LIGHTMAGENTA_EX } ==================== (See log file for channel IDs of matched authors above) ==================== { S . R } \" ) return logFileContents , logMode","title":"print_comments()"},{"location":"reference/Scripts/logging/#Scripts.logging.print_prepared_comments","text":"print_prepared_comments ( current , commentsContents , scanVideoID , comments , j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason ) Source code in Scripts/logging.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 def print_prepared_comments ( current , commentsContents , scanVideoID , comments , j , loggingEnabled , scanMode , logMode , doWritePrint , matchReason ): if matchReason != \"Filter Match\" : dividerString = \"============================================================================================\" if matchReason == \"Also By Matched Author\" : reasonString = \"======================== All Non-matched Comments by Authors Above ========================\" elif matchReason == \"Duplicate\" : reasonString = \"=========================== Non-Matched, But Duplicate Comments ===========================\" elif matchReason == \"Spam Bot Thread\" : reasonString = \"============================ Spam Bot Thread Top-Level Comments ===========================\" # -------------------- Print Section Header -------------------- # Print top divider if doWritePrint : print ( f \" \\n\\n { dividerString } \" ) if logMode == \"rtf\" : commentsContents = commentsContents + f \" \\\\ line \\\\ line \\n\\n { dividerString } \" elif logMode == \"plaintext\" : commentsContents = commentsContents + f \" \\n\\n { dividerString } \" # Print header text if doWritePrint : print ( f \" { reasonString } \" ) if logMode == \"rtf\" : commentsContents = commentsContents + f \" \\\\ line \\n { reasonString } \" elif logMode == \"plaintext\" : commentsContents = commentsContents + f \" \\n { reasonString } \" # Print bottom divider if doWritePrint : print ( f \" { dividerString } \\n \" ) if logMode == \"rtf\" : commentsContents = commentsContents + f \" \\\\ line \\n { dividerString } \\\\ line \\\\ line \\n\\n \" elif logMode == \"plaintext\" : commentsContents = commentsContents + f \" \\n { dividerString } \\n\\n \" # ----------------------------------------------------------------- for comment in comments : if matchReason == \"Filter Match\" : metadata = current . matchedCommentsDict [ comment ] elif matchReason == \"Duplicate\" : metadata = current . duplicateCommentsDict [ comment ] elif matchReason == \"Also By Matched Author\" : metadata = current . otherCommentsByMatchedAuthorsDict [ comment ] elif matchReason == \"Spam Bot Thread\" : metadata = current . spamThreadsDict [ comment ] # For printing and regular logging text = metadata [ 'text' ] author = metadata [ 'authorName' ] author_id_local = metadata [ 'authorID' ] comment_id_local = comment videoID = metadata [ 'videoID' ] matchReason = metadata [ 'matchReason' ] # Truncates very long comments, and removes excessive multiple lines if len ( text ) > 1500 : text = text [ 0 : 1500 ] + \"[Comment Truncated by YT SPammer Purge]\" if text . count ( \" \\n \" ) > 0 : text = text . replace ( \" \\n \" , \" \" ) # Add one sample from each matching author to current.matchSamplesDict, containing author ID, name, and text if matchReason != \"Also By Matched Author\" and author_id_local not in current . matchSamplesDict . keys (): add_sample ( current , author_id_local , author , text , matchReason ) # Build comment direct link if scanMode == \"communityPost\" or scanMode == \"recentCommunityPosts\" : directLink = \"https://www.youtube.com/post/\" + videoID + \"?lc=\" + comment_id_local else : directLink = \"https://www.youtube.com/watch?v=\" + videoID + \"&lc=\" + comment_id_local # Prints comment info to console if doWritePrint : print ( str ( j + 1 ) + f \". { F . LIGHTCYAN_EX } \" + author + f \" { S . R } : { F . YELLOW } \" + text + f \" { S . R } \" ) print ( \"\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\" ) print ( \" > Reason: \" + matchReason ) if scanVideoID is None : # Only print video title if searching entire channel title = utils . get_video_title ( current , videoID ) # Get Video Title if doWritePrint : print ( \" > Video: \" + title ) if doWritePrint : print ( \" > Direct Link: \" + directLink ) print ( f \" > Author Channel ID: { F . LIGHTBLUE_EX } \" + author_id_local + f \" { S . R } \" ) print ( \"============================================================================================= \\n \" ) # If logging enabled, also prints to log file if loggingEnabled == True : # Only print video title info if searching entire channel if scanVideoID is None : if logMode == \"rtf\" : titleInfoLine = \" > Video: \" + title + \" \\\\ line \" + \" \\n \" elif logMode == \"plaintext\" : titleInfoLine = \" > Video: \" + title + \" \\n \" else : titleInfoLine = \"\" if logMode == \"rtf\" : commentInfo = ( # Author Info str ( j + 1 ) + r \". \\cf4\" + make_rtf_compatible ( author ) + r \"\\cf1 : \\cf5\" + make_rtf_compatible ( text ) + r \"\\cf1 \\line \" + \" \\n \" + \"--------------------------------------------------------------------------------------------- \\\\ line \" + \" \\n \" # Rest of Comment Info + \" > Reason: \" + matchReason + \" \\\\ line \" + \" \\n \" + titleInfoLine + \" > Direct Link: \" + directLink + \" \\\\ line \" + \" \\n \" + \" > Author Channel ID: \\cf6\" + author_id_local + r \"\\cf1 \\line \" + \" \\n \" + \"============================================================================================= \\\\ line \\\\ line \\\\ line\" + \" \\n\\n\\n \" ) elif logMode == \"plaintext\" : commentInfo = ( # Author Info str ( j + 1 ) + \". \" + author + \": \" + text + \" \\n \" + \"--------------------------------------------------------------------------------------------- \\n \" # Rest of Comment Info + \" > Reason: \" + matchReason + \" \\n \" + titleInfoLine + \" > Direct Link: \" + directLink + \" \\n \" + \" > Author Channel ID: \" + author_id_local + \" \\n \" + \"============================================================================================= \\n\\n\\n \" ) commentsContents = commentsContents + commentInfo # Appends comment ID to new list of comments so it's in the correct order going forward, as provided by API and presented to user # Must use append here, not extend, or else it would add each character separately j += 1 return j , commentsContents","title":"print_prepared_comments()"},{"location":"reference/Scripts/logging/#Scripts.logging.rewrite_log_file","text":"rewrite_log_file ( current , logInfo , combinedCommentsDict = None ) Source code in Scripts/logging.py 777 778 779 780 781 782 783 784 785 786 787 788 789 790 def rewrite_log_file ( current , logInfo , combinedCommentsDict = None ): logMode = logInfo [ 'logMode' ] logFileContents = logInfo [ 'logFileContents' ] #jsonSettingsDict = logInfo['jsonSettingsDict'] filtersDict = logInfo [ 'filtersDict' ] # Rewrites the heading, which includes list of matched Comment IDs write_log_heading ( current , logMode , filtersDict , afterExclude = True , combinedCommentsDict = combinedCommentsDict ) # Rewrites the rest of the log file contents after the heading if logMode == \"rtf\" : write_rtf ( current . logFileName , logFileContents ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , logFileContents )","title":"rewrite_log_file()"},{"location":"reference/Scripts/logging/#Scripts.logging.write_json_log","text":"write_json_log ( jsonSettingsDict , commentsDict , jsonDataDict = None ) Source code in Scripts/logging.py 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 def write_json_log ( jsonSettingsDict , commentsDict , jsonDataDict = None ): success = False attempts = 0 if jsonDataDict : jsonDataDict [ 'Comments' ] = commentsDict dictionaryToWrite = jsonDataDict else : dictionaryToWrite = commentsDict fileName = jsonSettingsDict [ 'jsonLogFileName' ] jsonEncoding = jsonSettingsDict [ 'encoding' ] # If directory does not exist for desired log file path, create it logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) if not os . path . isdir ( logFolderPath ): try : os . mkdir ( logFolderPath ) # If relative path, make it absolute if not os . path . isabs ( fileName ): fileName = os . path . join ( logFolderPath , os . path . basename ( fileName )) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Could not create desired directory for log files. Will place them in current directory.\" ) fileName = os . path . basename ( fileName ) while success == False : try : attempts += 1 with open ( fileName , \"w\" , encoding = jsonEncoding ) as file : file . write ( json . dumps ( dictionaryToWrite , indent = 4 , ensure_ascii = False )) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break","title":"write_json_log()"},{"location":"reference/Scripts/logging/#Scripts.logging.write_log_completion_summary","text":"write_log_completion_summary ( current , exclude , logMode , banChoice , deletionModeFriendlyName , removeOtherAuthorComments ) Source code in Scripts/logging.py 765 766 767 768 769 770 771 772 773 774 def write_log_completion_summary ( current , exclude , logMode , banChoice , deletionModeFriendlyName , removeOtherAuthorComments ): if logMode == \"rtf\" : write_rtf ( current . logFileName , \" \\n\\n\\\\ line \\\\ line Spammers Banned: \" + str ( banChoice )) write_rtf ( current . logFileName , \" \\n\\n\\\\ line \\\\ line Action Taken on Comments: \" + str ( deletionModeFriendlyName ) + \" \\\\ line \\\\ line \\n\\n \" ) write_rtf ( current . logFileName , \" \\n\\n\\\\ line \\\\ line Also Retrieved All Other Comments by Matched Authors: \" + str ( removeOtherAuthorComments ) + \" \\\\ line \\\\ line \\n\\n \" ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , \" \\n\\n Spammers Banned: \" + str ( banChoice ) + \" \\n\\n \" ) write_plaintext_log ( current . logFileName , \"Action Taken on Comments: \" + str ( deletionModeFriendlyName ) + \" \\n\\n \" ) write_plaintext_log ( current . logFileName , \"Also Retrieved All Other Comments by Matched Authors: \" + str ( removeOtherAuthorComments ) + \" \\n\\n \" )","title":"write_log_completion_summary()"},{"location":"reference/Scripts/logging/#Scripts.logging.write_log_heading","text":"write_log_heading ( current , logMode , filtersDict , afterExclude = False , combinedCommentsDict = None ) Source code in Scripts/logging.py 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 def write_log_heading ( current , logMode , filtersDict , afterExclude = False , combinedCommentsDict = None ): if combinedCommentsDict == None : combinedCommentsDict = dict ( current . matchedCommentsDict ) combinedCommentsDict . update ( current . spamThreadsDict ) combinedCommentsDict . update ( current . duplicateCommentsDict ) filterMode = filtersDict [ 'filterMode' ] inputtedSpammerChannelID = filtersDict [ 'CustomChannelIdFilter' ] inputtedUsernameFilter = filtersDict [ 'CustomUsernameFilter' ] inputtedCommentTextFilter = filtersDict [ 'CustomCommentTextFilter' ] filterSettings = filtersDict [ 'filterSettings' ] def write_func ( logFileName , string , logMode , numLines ): rtfLineEnd = ( \" \\\\ line\" * numLines ) + \" \" newLines = \" \\n \" * numLines # Just the amount of new lines to put for this line if logMode == \"rtf\" : write_rtf ( logFileName , make_rtf_compatible ( string ) + rtfLineEnd ) elif logMode == \"plaintext\" : write_plaintext_log ( logFileName , string + newLines ) # Creates log file and writes first line if logMode == \"rtf\" : write_rtf ( current . logFileName , firstWrite = True ) write_func ( current . logFileName , \"----------- YouTube Spammer Purge Log File -----------\" , logMode , 2 ) elif logMode == \"plaintext\" : write_plaintext_log ( current . logFileName , firstWrite = True ) write_func ( current . logFileName , \"----------- YouTube Spammer Purge Log File -----------\" , logMode , 2 ) if filterMode == \"ID\" : write_func ( current . logFileName , \"Channel IDs of spammer searched: \" + \", \" . join ( inputtedSpammerChannelID ), logMode , 2 ) elif filterMode == \"Username\" : write_func ( current . logFileName , \"Characters searched in Usernames: \" + \", \" . join ( inputtedUsernameFilter ), logMode , 2 ) elif filterMode == \"Text\" : write_func ( current . logFileName , \"Characters searched in Comment Text: \" + \", \" . join ( inputtedCommentTextFilter ), logMode , 2 ) elif filterMode == \"NameAndText\" : write_func ( current . logFileName , \"Characters searched in Usernames and Comment Text: \" + \", \" . join ( inputtedCommentTextFilter ), logMode , 2 ) elif filterMode == \"AutoASCII\" : write_func ( current . logFileName , \"Automatic Search Mode: \" + str ( filterSettings [ 1 ]), logMode , 2 ) elif filterMode == \"AutoSmart\" : write_func ( current . logFileName , \"Automatic Search Mode: Smart Mode \" , logMode , 2 ) elif filterMode == \"SensitiveSmart\" : write_func ( current . logFileName , \"Automatic Search Mode: Sensitive Smart \" , logMode , 2 ) # Write number of comments for each type write_func ( current . logFileName , \"Number of Matched Comments Found: \" + str ( len ( current . matchedCommentsDict )), logMode , 2 ) write_func ( current . logFileName , \"Number of Spam Bot Threads Found: \" + str ( len ( current . spamThreadsDict )), logMode , 2 ) write_func ( current . logFileName , \"Number of Non-Matched, but Duplicate Comments Found: \" + str ( len ( current . duplicateCommentsDict )), logMode , 2 ) # How to label the comment ID list if current . duplicateCommentsDict : commentListLabel = \"IDs of Matched & Duplicate Comments\" else : commentListLabel = \"IDs of Matched Comments\" if afterExclude == True : excludeString = \" (Excluded Comments Removed)\" else : excludeString = \"\" write_func ( current . logFileName , f \" { commentListLabel }{ excludeString } : \\n [ { ', ' . join ( combinedCommentsDict ) } ] \" , logMode , 3 )","title":"write_log_heading()"},{"location":"reference/Scripts/logging/#Scripts.logging.write_plaintext_log","text":"write_plaintext_log ( fileName , newText = None , firstWrite = False , fullWrite = False ) Source code in Scripts/logging.py 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 def write_plaintext_log ( fileName , newText = None , firstWrite = False , fullWrite = False ): success = False attempts = 0 if firstWrite == True or fullWrite == True : # If directory does not exist for desired log file path, create it logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) if not os . path . isdir ( logFolderPath ): try : os . mkdir ( logFolderPath ) # If relative path, make it absolute if not os . path . isabs ( fileName ): fileName = os . path . join ( logFolderPath , os . path . basename ( fileName )) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Could not create desired directory for log files. Will place them in current directory.\" ) fileName = os . path . basename ( fileName ) while success == False : try : attempts += 1 with open ( fileName , \"w\" , encoding = \"utf-8\" ) as file : if fullWrite == True : file . write ( newText ) else : file . write ( \"\" ) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break else : while success == False : try : attempts += 1 with open ( fileName , 'a' , encoding = \"utf-8\" ) as file : for line in newText : file . write ( line ) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break","title":"write_plaintext_log()"},{"location":"reference/Scripts/logging/#Scripts.logging.write_rtf","text":"write_rtf ( fileName , newText = None , firstWrite = False , fullWrite = False ) Source code in Scripts/logging.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 def write_rtf ( fileName , newText = None , firstWrite = False , fullWrite = False ): success = False attempts = 0 if firstWrite == True or fullWrite == True : # If directory does not exist for desired log file path, create it logFolderPath = os . path . dirname ( os . path . realpath ( fileName )) if not os . path . isdir ( logFolderPath ): try : os . mkdir ( logFolderPath ) # If relative path, make it absolute if not os . path . isabs ( fileName ): fileName = os . path . join ( logFolderPath , os . path . basename ( fileName )) except : print ( f \" { F . LIGHTRED_EX } Error: { S . R } Could not create desired directory for log files. Will place them in current directory.\" ) fileName = os . path . basename ( fileName ) while success == False : try : attempts += 1 with open ( fileName , 'w' , encoding = \"utf-8\" ) as file : # Some header information for RTF file, sets courier as font file . write ( r \"{\\rtf1\\ansi\\deff0 {\\fonttbl {\\f0 Courier;}}\" + \" \\n \" ) # Sets color table to be able to set colors for text, each color set with RGB values in raw string # To use color, use '\\cf1 ' (with space) for black, cf2 = red, cf3 = green, cf4 = blue, cf5 = orange, cf6 = purple # cf1 cf2 cf3 cf4 cf5 cf6 file . write ( r \"{\\colortbl;\\red0\\green0\\blue0;\\red255\\green0\\blue0;\\red0\\green255\\blue0;\\red0\\green0\\blue255;\\red143\\green81\\blue0;\\red102\\green0\\blue214;}\" + \" \\n\\n \" ) if fullWrite == True : file . write ( newText ) file . write ( r \"}\" ) file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break # If the string might have unicode, use unicode mode to convert for rtf else : # Writes to line just before last, to preserve required ending bracket in rtf file # Slightly modified from: https://stackoverflow.com/a/50567967/17312053 while success == False : try : attempts += 1 with open ( fileName , 'r+' , encoding = \"utf-8\" ) as file : pos , text = 0 , '' while True : # save last line value and cursor position prev_pos , pos = pos , file . tell () prev_text , text = text , file . readline () if text == '' : # Checks for last line with only ending bracket break file . seek ( prev_pos , 0 ) # replace cursor to the last line for line in newText : # write new lines. If any brackets, add escape backslash line . replace ( \"}\" , \" \\\\ }\" ) line . replace ( \"{\" , \" \\\\ {\" ) file . write ( line ) file . write ( \" \\n }\" ) # Re-write new line with ending bracket again. Could put prev_text in here if being dynamic file . close () success = True except PermissionError : if attempts < 3 : print ( f \" \\n { F . YELLOW } \\n ERROR! { S . R } Cannot write to { F . LIGHTCYAN_EX }{ fileName }{ S . R } . Is it open? Try { F . YELLOW } closing the file { S . R } before continuing.\" ) input ( \" \\n Press Enter to Try Again...\" ) else : print ( f \" { F . LIGHTRED_EX } \\n ERROR! Still cannot write to { F . LIGHTCYAN_EX }{ fileName }{ F . LIGHTRED_EX } . { F . YELLOW } Try again? { S . R } (Y) or { F . YELLOW } Skip Writing Log? { S . R } (N)\" ) if choice ( \"Choice\" ) == False : break","title":"write_rtf()"},{"location":"reference/Scripts/operations/","text":"CommentFoundError \u00b6 Bases: Exception Source code in Scripts/operations.py 948 949 class CommentFoundError ( Exception ): pass CommentNotFoundError \u00b6 Bases: Exception Source code in Scripts/operations.py 1019 1020 class CommentNotFoundError ( Exception ): pass add_spam \u00b6 add_spam ( current , config , miscData , currentCommentDict , videoID , matchReason = 'Filter Match' ) Source code in Scripts/operations.py 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 def add_spam ( current , config , miscData , currentCommentDict , videoID , matchReason = \"Filter Match\" ): if matchReason == \"Filter Match\" : dictToUse = current . matchedCommentsDict elif matchReason == \"Duplicate\" : dictToUse = current . duplicateCommentsDict elif matchReason == \"Also By Matched Author\" : dictToUse = current . otherCommentsByMatchedAuthorsDict elif matchReason == \"Spam Bot Thread\" : dictToUse = current . spamThreadsDict commentID = currentCommentDict [ 'commentID' ] authorChannelName = currentCommentDict [ 'authorChannelName' ] authorChannelID = currentCommentDict [ 'authorChannelID' ] commentTextRaw = str ( currentCommentDict [ 'commentText' ]) # Use str() to ensure not pointing to same place in memory commentText = str ( currentCommentDict [ 'commentText' ]) . replace ( \" \\r \" , \"\" ) dictToUse [ commentID ] = { 'text' : commentText , 'textUnsanitized' : commentTextRaw , 'authorName' : authorChannelName , 'authorID' : authorChannelID , 'videoID' : videoID , 'matchReason' : matchReason } current . vidIdDict [ commentID ] = videoID # Probably remove this later, but still being used for now # Count of comments per author if authorChannelID in current . authorMatchCountDict : current . authorMatchCountDict [ authorChannelID ] += 1 else : current . authorMatchCountDict [ authorChannelID ] = 1 if config [ 'json_log' ] == True and config [ 'json_extra_data' ] == True : dictToUse [ commentID ][ 'uploaderChannelID' ] = miscData . channelOwnerID dictToUse [ commentID ][ 'uploaderChannelName' ] = miscData . channelOwnerName dictToUse [ commentID ][ 'videoTitle' ] = utils . get_video_title ( current , videoID ) check_against_filter \u00b6 check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID , allThreadAuthorNames = None ) Source code in Scripts/operations.py 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 def check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID , allThreadAuthorNames = None ): # Retrieve Data from currentCommentDict commentID = currentCommentDict [ 'commentID' ] authorChannelName = currentCommentDict [ 'authorChannelName' ] authorChannelID = currentCommentDict [ 'authorChannelID' ] parentAuthorChannelID = currentCommentDict [ 'parentAuthorChannelID' ] commentTextRaw = str ( currentCommentDict [ 'commentText' ]) # Use str() to ensure not pointing to same place in memory commentText = str ( currentCommentDict [ 'commentText' ]) . replace ( \" \\r \" , \"\" ) # #Debugging # print(f\"{F.LIGHTRED_EX}DEBUG MODE{S.R} - If you see this, I forgot to disable it before release, oops. \\n Please report here: {F.YELLOW}TJoe.io/bug-report{S.R}\") # print(\"Comment ID: \" + commentID) # debugSingleComment = True #Debug usage # if debugSingleComment == True: # authorChannelName = input(\"Channel Name: \") # commentText = input(\"Comment Text: \") # authorChannelID = \"x\" # Do not even check comment if: Author is Current User, Author is Channel Owner, or Author is in whitelist if auth . CURRENTUSER . id != authorChannelID and miscData . channelOwnerID != authorChannelID and authorChannelID not in miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ]: if \"@\" in commentText : # Logic to avoid false positives from replies to spammers if allThreadAuthorNames and ( filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"NameAndText\" ): for name in allThreadAuthorNames : if \"@\" + str ( name ) in commentText : commentText = commentText . replace ( \"@\" + str ( name ), \"\" ) # Extra logic to detect false positive if spammer's comment already deleted, but someone replied if current . matchedCommentsDict and filtersDict [ 'filterMode' ] == \"AutoSmart\" : for key , value in current . matchedCommentsDict . items (): if \"@\" + str ( value [ 'authorName' ]) in commentText : remove = True for key2 , value2 in current . matchedCommentsDict . items (): if value2 [ 'authorID' ] == authorChannelID : remove = False if remove == True : commentText = commentText . replace ( \"@\" + str ( value [ 'authorName' ]), \"\" ) # Checks author of either parent comment or reply (both passed in as commentID) against channel ID inputted by user if filtersDict [ 'filterMode' ] == \"ID\" : if any ( authorChannelID == x for x in filtersDict [ 'CustomChannelIdFilter' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Username elif filtersDict [ 'filterMode' ] == \"Username\" : if filtersDict [ 'filterSubMode' ] == \"chars\" : authorChannelName = utils . make_char_set ( str ( authorChannelName )) if any ( x in filtersDict [ 'CustomUsernameFilter' ] for x in authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"string\" : if utils . check_list_against_string ( listInput = filtersDict [ 'CustomUsernameFilter' ], stringInput = authorChannelName , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"regex\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Comment Text elif filtersDict [ 'filterMode' ] == \"Text\" : if filtersDict [ 'filterSubMode' ] == \"chars\" : commentText = utils . make_char_set ( str ( commentText )) if any ( x in filtersDict [ 'CustomCommentTextFilter' ] for x in commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"string\" : if utils . check_list_against_string ( listInput = filtersDict [ 'CustomCommentTextFilter' ], stringInput = commentText , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"regex\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Name and Text elif filtersDict [ 'filterMode' ] == \"NameAndText\" : if filtersDict [ 'filterSubMode' ] == \"chars\" : authorChannelName = utils . make_char_set ( str ( authorChannelName )) commentText = utils . make_char_set ( str ( commentText )) if any ( x in filtersDict [ 'CustomUsernameFilter' ] for x in authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( x in filtersDict [ 'CustomCommentTextFilter' ] for x in commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"string\" : if utils . check_list_against_string ( listInput = filtersDict [ 'CustomUsernameFilter' ], stringInput = authorChannelName , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif utils . check_list_against_string ( listInput = filtersDict [ 'CustomCommentTextFilter' ], stringInput = commentText , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"regex\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Auto ASCII (in username) elif filtersDict [ 'filterMode' ] == \"AutoASCII\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Auto Smart (in username or comment text) # Here inputtedComment/Author Filters are tuples of, where 2nd element is list of char-sets to check against ## Also Check if reply author ID is same as parent comment author ID, if so, ignore (to account for users who reply to spammers) elif filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"SensitiveSmart\" : smartFilter = filtersDict [ 'CustomCommentTextFilter' ] # Receive Variables compiledRegexDict = smartFilter [ 'compiledRegexDict' ] numberFilterSet = smartFilter [ 'spammerNumbersSet' ] compiledNumRegex = smartFilter [ 'compiledNumRegex' ] minNumbersMatchCount = smartFilter [ 'minNumbersMatchCount' ] bufferChars = compiledRegexDict [ 'bufferChars' ] #usernameBlackCharsSet = smartFilter['usernameBlackCharsSet'] spamGenEmojiSet = smartFilter [ 'spamGenEmojiSet' ] redAdEmojiSet = smartFilter [ 'redAdEmojiSet' ] yellowAdEmojiSet = smartFilter [ 'yellowAdEmojiSet' ] hrtSet = smartFilter [ 'hrtSet' ] lowAlSet = smartFilter [ 'lowAlSet' ] languages = smartFilter [ 'languages' ] sensitive = smartFilter [ 'sensitive' ] rootDomainRegex = smartFilter [ 'rootDomainRegex' ] # Spam Lists spamListCombinedRegex = smartFilter [ 'spamListCombinedRegex' ] # if debugSingleComment == True: # if input(\"Sensitive True/False: \").lower() == 'true': sensitive = True # else: sensitive = False # Check for sensitive smart mode if sensitive : rootDomainRegex = smartFilter [ 'sensitiveRootDomainRegex' ] # Functions -------------------------------------------------------------- def findOnlyObfuscated ( regexExpression , originalWord , stringToSearch ): # Confusable thinks s and f look similar, have to compensate to avoid false positive ignoredConfusablesConverter = { ord ( 'f' ): ord ( 's' ), ord ( 's' ): ord ( 'f' )} result = re . findall ( regexExpression , stringToSearch . lower ()) if not result : return False else : for match in result : lowerWord = originalWord . lower () for char in compiledRegexDict [ 'bufferChars' ]: match = match . strip ( char ) if match . lower () != lowerWord and match . lower () != lowerWord . translate ( ignoredConfusablesConverter ): return True def remove_unicode_categories ( string ): return \"\" . join ( char for char in string if unicodedata . category ( char ) not in smartFilter [ 'unicodeCategoriesStrip' ]) def check_if_only_link ( string ): result = re . match ( compiledRegexDict [ 'onlyVideoLinkRegex' ], string ) if not result : return False elif result . group ( 0 ) and len ( result . group ( 0 )) == len ( string ): return True else : return False # ------------------------------------------------------------------------ # Normalize usernames and text, remove multiple whitespace and invisible chars commentText = re . sub ( ' +' , ' ' , commentText ) # https://stackoverflow.com/a/49695605/17312053 commentText = \"\" . join ( k if k in bufferChars else \"\" . join ( v ) for k , v in itertools . groupby ( commentText , lambda c : c )) commentText = remove_unicode_categories ( commentText ) authorChannelName = re . sub ( ' +' , ' ' , authorChannelName ) authorChannelName = remove_unicode_categories ( authorChannelName ) # Processed Variables combinedString = authorChannelName + commentText combinedSet = utils . make_char_set ( combinedString , stripLettersNumbers = True , stripPunctuation = True ) upLowTextSet = set ( commentText . replace ( miscData . channelOwnerName , \"\" )) #usernameSet = utils.make_char_set(authorChannelName) # Run Checks if authorChannelID == parentAuthorChannelID : pass elif len ( numberFilterSet . intersection ( combinedSet )) >= minNumbersMatchCount : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif compiledNumRegex . search ( combinedString ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Black Tests #elif usernameBlackCharsSet.intersection(usernameSet): # add_spam(current, config, miscData, currentCommentDict, videoID) elif any ( re . search ( expression [ 1 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif config [ 'detect_sub_challenge_spam' ] and any ( re . search ( expression [ 1 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameNovidBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], combinedString ) for expression in compiledRegexDict [ 'blackAdWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], commentText ) for expression in compiledRegexDict [ 'textObfuBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( word in commentText . lower () for word in compiledRegexDict [ 'textExactBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any (( word in commentText and not upLowTextSet . intersection ( lowAlSet )) for word in compiledRegexDict [ 'textUpLowBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameObfuBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif re . search ( spamListCombinedRegex , combinedString ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif config [ 'detect_link_spam' ] and check_if_only_link ( commentText . strip ()): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif sensitive and re . search ( smartFilter [ 'usernameConfuseRegex' ], authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif not sensitive and ( findOnlyObfuscated ( smartFilter [ 'usernameConfuseRegex' ], miscData . channelOwnerName , authorChannelName ) or authorChannelName == miscData . channelOwnerName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Multi Criteria Tests else : # Defaults yellowCount = 0 redCount = 0 languageCount = 0 for language in languages : if language [ 2 ] . intersection ( combinedSet ): languageCount += 1 # Yellow Tests if any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], combinedString ) for expression in compiledRegexDict [ 'yellowAdWords' ]): yellowCount += 1 hrtTest = len ( hrtSet . intersection ( combinedSet )) if hrtTest >= 2 : if not sensitive : yellowCount += 1 else : redCount += 1 elif sensitive and hrtTest >= 1 : yellowCount += 1 if yellowAdEmojiSet . intersection ( combinedSet ): yellowCount += 1 if not sensitive and spamGenEmojiSet . intersection ( combinedSet ): yellowCount += 1 if combinedString . count ( '#' ) >= 5 : yellowCount += 1 if combinedString . count ( ' \\n ' ) >= 10 : yellowCount += 1 if languageCount >= 2 : yellowCount += 1 if re . search ( rootDomainRegex , combinedString . lower ()): yellowCount += 1 # Red Tests #if any(foundObfuscated(re.findall(expression[1], combinedString), expression[0]) for expression in compiledRegexDict['redAdWords']): if any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], combinedString ) for expression in compiledRegexDict [ 'redAdWords' ]): redCount += 1 if any ( re . search ( expression [ 1 ], combinedString ) for expression in compiledRegexDict [ 'exactRedAdWords' ]): redCount += 1 if redAdEmojiSet . intersection ( combinedSet ): redCount += 1 if sensitive and spamGenEmojiSet . intersection ( combinedSet ): redCount += 1 if any ( re . search ( expression [ 1 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameRedWords' ]): redCount += 1 # Calculate Score if yellowCount >= 3 : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif redCount >= 2 : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif redCount >= 1 and yellowCount >= 1 : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif sensitive and redCount >= 1 : add_spam ( current , config , miscData , currentCommentDict , videoID ) else : pass check_deleted_comments \u00b6 check_deleted_comments ( commentInput ) Source code in Scripts/operations.py 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 def check_deleted_comments ( commentInput ): i = 0 # Count number of remaining comments j = 1 # Count number of checked total = len ( commentInput ) unsuccessfulResults = [] commentList = [] if type ( commentInput ) == list : commentList = commentInput elif type ( commentInput ) == dict : commentList = list ( commentInput . keys ()) # Wait 2 seconds so YouTube API has time to update comment status print ( \" Preparing to check deletion status...\" , end = \" \\r \" ) time . sleep ( 1 ) print ( \" \" ) print ( \" (Note: You can disable deletion success checking in the config file, to save time and API quota) \\n \" ) for commentID in commentList : try : results = auth . YOUTUBE . comments () . list ( part = \"snippet\" , id = commentID , maxResults = 1 , fields = \"items\" , textFormat = \"plainText\" ) . execute () print ( \"Verifying Deleted Comments: [\" + str ( j ) + \" / \" + str ( total ) + \"]\" , end = \" \\r \" ) j += 1 if results [ \"items\" ]: # Check if the items result is empty raise CommentFoundError # If comment is found and possibly not deleted, print out video ID and comment ID except CommentFoundError : if type ( commentInput ) == dict : print ( \"Possible Issue Deleting Comment: \" + str ( commentID ) + \" | Check Here: \" + \"https://www.youtube.com/watch?v=\" + str ( commentInput [ commentID ][ 'videoID' ]) + \"&lc=\" + str ( commentID )) elif type ( commentInput ) == list : print ( \"Possible Issue Deleting Comment: \" + str ( commentID )) i += 1 unsuccessfulResults . append ( results ) pass except Exception : if type ( commentInput ) == dict : print ( \"Unhandled Exception While Deleting Comment: \" + str ( commentID ) + \" | Check Here: \" + \"https://www.youtube.com/watch?v=\" + str ( commentInput [ commentID ][ 'videoID' ]) + \"&lc=\" + str ( commentID )) elif type ( commentInput ) == list : print ( \"Unhandled Exception While Deleting Comment: \" + str ( commentID )) i += 1 unsuccessfulResults . append ( results ) pass if i == 0 : print ( \" \\n\\n Success: All comments should be gone.\" ) elif i > 0 : print ( \" \\n\\n Warning: \" + str ( i ) + \" comments may remain. Check links above or try running the program again. An error log file has been created: 'Deletion_Error_Log.txt'\" ) # Write error log with open ( \"Deletion_Error_Log.txt\" , \"a\" , encoding = \"utf-8\" ) as f : f . write ( \"----- YT Spammer Purge Error Log: Possible Issue Deleting Comments ------ \\n\\n \" ) f . write ( str ( unsuccessfulResults )) f . write ( \" \\n\\n \" ) f . close () else : print ( \" \\n\\n Something strange happened... The comments may or may have not been deleted.\" ) return None check_duplicates \u00b6 check_duplicates ( current , config , miscData , allVideoCommentsDict , videoID ) Source code in Scripts/operations.py 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 def check_duplicates ( current , config , miscData , allVideoCommentsDict , videoID ): # Get Lenvenshtein Distance Setting try : levenshtein = float ( config [ 'levenshtein_distance' ]) if levenshtein < 0 or levenshtein > 1 : print ( \" \\n Error: Levenshtein_distance config setting must be between 0 and 1. Defaulting to 0.9\" ) input ( \" \\n Press Enter to continue...\" ) levenshtein = 0.9 except ValueError : print ( \" \\n Error: Levenshtein_distance config setting must be a number between 0 and 1. Defaulting to 0.9\" ) input ( \" \\n Press Enter to continue...\" ) levenshtein = 0.9 # Get duplicate count setting try : minimum_duplicates = int ( config [ 'minimum_duplicates' ]) if minimum_duplicates < 2 : minimum_duplicates = 4 print ( \" \\n Error: Minimum_Duplicates config setting must be greater than 1. Defaulting to 4.\" ) input ( \" \\n Press Enter to continue...\" ) except ValueError : minimum_duplicates = 4 print ( \" \\n Error: Minimum_Duplicates config setting is invalid. Defaulting to 4.\" ) input ( \" \\n Press Enter to continue...\" ) # Calculate number of authors to check, for progress authorCount = len ( allVideoCommentsDict ) scannedCount = 0 # Run the actual duplicate checking for authorID , authorCommentsList in allVideoCommentsDict . items (): # Don't scan channel owner, current user, or any user in whitelist. Also don't bother if author is already in matchedCommentsDict if auth . CURRENTUSER . id == authorID or miscData . channelOwnerID == authorID or authorID in miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] or any ( authorID == value [ 'authorID' ] for key , value in current . matchedCommentsDict . items ()): scannedCount += 1 print ( f \" Analyzing For Duplicates: [ { scannedCount / authorCount * 100 : .2f } % ] (Can be disabled & customized in config)\" . ljust ( 75 , \" \" ), end = \" \\r \" ) else : numDupes = 0 commentTextList = [] matchedIndexes = [] for commentDict in authorCommentsList : commentTextList . append ( commentDict [ 'commentText' ]) # Count number of comments that are similar to at least one other comment if len ( commentTextList ) > 1 : for i , x in enumerate ( commentTextList ): for j in range ( i + 1 , len ( commentTextList )): y = commentTextList [ j ] if ratio ( x , y ) > levenshtein : # List the indexes of the matched comments in the list matchedIndexes . append ( i ) matchedIndexes . append ( j ) break # Only count each comment once by counting number of unique indexes in matchedIndexes uniqueMatches = len ( set ( matchedIndexes )) if uniqueMatches >= minimum_duplicates : numDupes += uniqueMatches if numDupes > 0 : for commentDict in authorCommentsList : add_spam ( current , config , miscData , commentDict , videoID , matchReason = \"Duplicate\" ) scannedCount += 1 print ( f \" Analyzing For Duplicates: [ { scannedCount / authorCount * 100 : .2f } % ] (Can be disabled & customized in config)\" . ljust ( 75 , \" \" ), end = \" \\r \" ) print ( \"\" . ljust ( 90 , \" \" )) # Erase line check_recovered_comments \u00b6 check_recovered_comments ( commentsList ) Source code in Scripts/operations.py 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 def check_recovered_comments ( commentsList ): i = 0 # Count number of remaining comments j = 1 # Count number of checked total = len ( commentsList ) unsuccessfulResults = [] for comment in commentsList : try : results = auth . YOUTUBE . comments () . list ( part = \"snippet\" , id = comment , maxResults = 1 , fields = \"items\" , textFormat = \"plainText\" ) . execute () print ( \"Verifying Deleted Comments: [\" + str ( j ) + \" / \" + str ( total ) + \"]\" , end = \" \\r \" ) j += 1 if not results [ \"items\" ]: # Check if the items result is empty raise CommentNotFoundError except CommentNotFoundError : #print(\"Possible Issue Deleting Comment: \" + str(key) + \" | Check Here: \" + \"https://www.youtube.com/watch?v=\" + str(value) + \"&lc=\" + str(key)) print ( \"Possible Issue Restoring Comment: \" + str ( comment )) i += 1 unsuccessfulResults . append ( comment ) if i == 0 : print ( f \" \\n\\n { F . LIGHTGREEN_EX } Success: All spam comments should be restored! { S . R } \" ) print ( \"You can view them by using the links to them in the same log file you used.\" ) elif i > 0 : print ( \" \\n\\n Warning: \" + str ( i ) + \" comments may have not been restored. See above list.\" ) print ( \"Use the links to the comments from the log file you used, to verify if they are back or not.\" ) input ( \" \\n Recovery process finished. Press Enter to return to main menu...\" ) return True check_spam_threads \u00b6 check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ) Source code in Scripts/operations.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 def check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ): threadWords = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'threadWords' ] threadPhrases = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'threadPhrases' ] monetWords = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'monetWords' ] monetStrings = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'monetStrings' ] nameRegex = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'nameRegex' ] nakedNameRegex = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'nakedNameRegex' ] cashRegex = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'cashRegex' ] ignoreList = [ 'earn' , 'trade' , 'invest' , 'signal' , 'crypto' , ' is' , ' she' , ' he' ] spam = False threadAnalysisDict = {} preliminaryCount , redCount , yellowCount , nameCount , fullNameCount , partialNameCount , susMentionCount = 0 , 0 , 0 , 0 , 0 , 0 , 0 nameList , partialNameList , fullNameList = [] , [], [] name , partialName , fullName = \"\" , \"\" , \"\" if any ( item in parentCommentDict [ 'commentText' ] . lower () for item in miscData . spamLists [ 'spamThreadsList' ]): add_spam ( current , config , miscData , parentCommentDict , parentCommentDict [ 'videoID' ], matchReason = \"Spam Bot Thread\" ) return current # Preliminary Analysis for word in threadWords : if word in parentCommentDict [ 'commentText' ] . lower (): preliminaryCount += 1 if preliminaryCount < 2 : return current # Shoves all comments by each author into one each. Each author ID is key, combined comments text is value for _ , data in threadDict . items (): if data [ 'authorChannelID' ] in threadAnalysisDict : threadAnalysisDict [ data [ 'authorChannelID' ]] = threadAnalysisDict [ data [ 'authorChannelID' ]] + \" \" + re . sub ( ' +' , ' ' , data [ 'commentText' ] . lower ()) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) else : threadAnalysisDict [ data [ 'authorChannelID' ]] = re . sub ( ' +' , ' ' , data [ 'commentText' ] . lower ()) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) # When all authors have one combined comment text, put each into list threadAnalysisList = list ( threadAnalysisDict . values ()) # ------------------------------------------------------------------------------- def processResult ( regResult , naked ): len1 = len ( regResult . group ( 1 )) len2 = len ( regResult . group ( 2 )) len3 = len ( regResult . group ( 3 )) if not ( naked and len1 > 2 and len3 > 2 ) or ( naked and len2 >= 4 and len3 >= 5 ): name = regResult . group ( 2 ) . strip () + \" \" + regResult . group ( 3 ) . strip () name = re . sub ( ' +' , ' ' , name ) else : name = \"\" if not naked : partialName = regResult . group ( 1 ) . strip () + \" \" + regResult . group ( 2 ) . strip () partialName = re . sub ( ' +' , ' ' , partialName ) else : partialName = \"\" if not naked : fullName = regResult . group ( 0 ) else : fullName = \"\" return name , partialName , fullName # ------------------------------------------------------------------------------- def regexSearchNames ( regex , name , partialName , fullName , naked = False ): # Get Potential Names for comment in threadAnalysisList : regResult = re . search ( regex , comment ) if regResult : x , y , z = processResult ( regResult , naked ) # Strip empty name . append ( x ) partialName . append ( y ) fullName . append ( z ) regResult = re . search ( regex , parentCommentDict [ 'commentText' ] . lower ()) if regResult : x , y , z = processResult ( regResult , naked ) if x : name . append ( x ) if y : partialName . append ( y ) if z : fullName . append ( z ) return name , partialName , fullName # ------------------------------------------------------------------------------- def remove_ignore ( nameList ): removeList = [] for n in nameList : for word in ignoreList : if word in n : removeList . append ( n ) if removeList : for item in removeList : if item in nameList : nameList . remove ( item ) return nameList # ------------------------------------------------------------------------------- nameList , partialNameList , fullNameList = regexSearchNames ( nameRegex , nameList , partialNameList , fullNameList ) if not nameList : nameList , partialNameList , fullNameList = regexSearchNames ( nakedNameRegex , nameList , partialNameList , fullNameList , naked = True ) partialNameList = [] fullNameList = [] while \"\" in nameList : nameList . remove ( \"\" ) while \"\" in partialNameList : partialNameList . remove ( \"\" ) while \"\" in fullNameList : fullNameList . remove ( \"\" ) # Determine most common names if nameList : name = max ( set ( nameList ), key = nameList . count ) if nameList . count ( name ) == 1 : nameList = remove_ignore ( nameList ) if nameList : name = max ( set ( nameList ), key = nameList . count ) else : name = \"\" if partialNameList : partialName = max ( set ( partialNameList ), key = partialNameList . count ) if partialNameList . count ( partialName ) == 1 : partialNameList = remove_ignore ( partialNameList ) if partialNameList : partialName = max ( set ( partialNameList ), key = partialNameList . count ) else : partialName = \"\" if fullNameList : fullName = max ( set ( fullNameList ), key = fullNameList . count ) if fullNameList . count ( fullName ) == 1 : fullNameList = remove_ignore ( fullNameList ) if fullNameList : fullName = max ( set ( fullNameList ), key = fullNameList . count ) else : fullName = \"\" # Analyze Thread for comment in threadAnalysisList : if name : if fullName and fullName in comment : fullNameCount += 1 elif name and name in comment : nameCount += 1 elif partialName and partialName in comment : partialNameCount += 1 susMention = False if any ( word in comment for word in threadWords ): yellowCount += 1 susMention = True if any ( phrase in comment for phrase in threadPhrases ): redCount += 1 susMention = True if re . search ( cashRegex , comment ): if any ( word in comment for word in monetWords ): redCount += 1 else : yellowCount += 1 susMention = True if susMention : susMentionCount += 1 if fullName in parentCommentDict [ 'commentText' ] . lower () or name in parentCommentDict [ 'commentText' ] . lower (): fullNameCount += 1 redCount += 1 susRatio = susMentionCount / len ( threadAnalysisList ) # Number of people, not replies allNameCount = nameCount + partialNameCount + fullNameCount if susRatio > 0.7 : if filtersDict [ 'filterMode' ] == \"SensitiveSmart\" : add_spam ( current , config , miscData , parentCommentDict , parentCommentDict [ 'videoID' ], matchReason = \"Spam Bot Thread\" ) return current elif len ( threadAnalysisList ) >= 10 : redCount += 2 else : redCount += 1 elif susRatio < 0.3 : return current # Score if redCount >= 1 and yellowCount >= 5 and ( susRatio > 0.75 or ( allNameCount >= 4 or fullNameCount >= 2 )): spam = True elif redCount > 2 and yellowCount >= 3 and ( susRatio > 0.70 or ( allNameCount >= 4 or fullNameCount >= 2 )): spam = True elif redCount >= 2 and ( allNameCount >= 5 or fullNameCount >= 3 ) and susRatio > 0.6 : spam = True elif redCount >= 5 and susRatio > 0.5 : spam = True elif yellowCount >= 10 and susRatio > 0.65 : spam = True if spam == True : add_spam ( current , config , miscData , parentCommentDict , parentCommentDict [ 'videoID' ], matchReason = \"Spam Bot Thread\" ) return current delete_found_comments \u00b6 delete_found_comments ( commentsList , banChoice , deletionMode , recoveryMode = False , skipCheck = False ) Source code in Scripts/operations.py 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 def delete_found_comments ( commentsList , banChoice , deletionMode , recoveryMode = False , skipCheck = False ): print ( \" \\n \" ) if deletionMode == \"rejected\" : actionPresent = \"Deleting\" actionPast = \"Deleted\" elif deletionMode == \"heldForReview\" : actionPresent = \"Hiding\" actionPast = \"Hidden\" elif deletionMode == \"reportSpam\" : actionPresent = \"Reporting\" actionPast = \"Reported\" else : actionPresent = \"Processing\" actionPast = \"Processed\" failedComments = [] # Local Functions def setStatus ( commentIDs , failedComments ): #Does the actual deletion if deletionMode == \"reportSpam\" : result = auth . YOUTUBE . comments () . markAsSpam ( id = commentIDs ) . execute () if len ( result ) > 0 : print ( \" \\n Something may gone wrong when reporting the comments.\" ) failedComments += commentIDs elif deletionMode == \"heldForReview\" or deletionMode == \"rejected\" or deletionMode == \"published\" : try : response = auth . YOUTUBE . comments () . setModerationStatus ( id = commentIDs , moderationStatus = deletionMode , banAuthor = banChoice ) . execute () if len ( response ) > 0 : failedComments += commentIDs except HttpError : print ( \" \\n Something has gone wrong when removing some comments...\" ) failedComments += commentIDs else : print ( \"Invalid deletion mode. This is definitely a bug, please report it here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) print ( \"Deletion Mode Is: \" + deletionMode ) input ( \"Press Enter to Exit...\" ) sys . exit () return failedComments def print_progress ( d , t , recoveryMode = False ): if recoveryMode == False : print ( actionPresent + \" Comments... - Progress: [\" + str ( d ) + \" / \" + str ( t ) + \"] (In Groups of 50)\" , end = \" \\r \" ) elif recoveryMode == True : print ( \"Recovering Comments... - Progress: [\" + str ( d ) + \" / \" + str ( t ) + \"] (In Groups of 50)\" , end = \" \\r \" ) total = len ( commentsList ) deletedCounter = 0 print_progress ( deletedCounter , total , recoveryMode ) if total > 50 : # If more than 50 comments, break into chunks of 50 remainder = total % 50 # Gets how many left over after dividing into chunks of 50 numDivisions = int (( total - remainder ) / 50 ) # Gets how many full chunks of 50 there are for i in range ( numDivisions ): # Loops through each full chunk of 50 failedComments = setStatus ( commentsList [ i * 50 : i * 50 + 50 ], failedComments ) deletedCounter += 50 print_progress ( deletedCounter , total , recoveryMode ) if remainder > 0 : failedComments = setStatus ( commentsList [ numDivisions * 50 : total ], failedComments ) # Handles any leftover comments range after last full chunk deletedCounter += remainder print_progress ( deletedCounter , total , recoveryMode ) else : failedComments = setStatus ( commentsList , failedComments ) print_progress ( deletedCounter , total , recoveryMode ) if deletionMode == \"reportSpam\" : print ( f \" { F . YELLOW } Comments Reported! { S . R } If no error messages were displayed, then everything was successful.\" ) return failedComments elif recoveryMode == False and skipCheck == False : print ( \"Comments \" + actionPast + \"! Will now verify each is gone. \\n \" ) elif recoveryMode == False and skipCheck == True : print ( \"Comments \" + actionPast + \"! \\n \" ) elif recoveryMode == True : print ( \"Comments Recovered! Will now verify each is back. \\n \" ) return failedComments exclude_authors \u00b6 exclude_authors ( current , config , miscData , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , displayString , inputtedString , logInfo = None , only = False ) Source code in Scripts/operations.py 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 def exclude_authors ( current , config , miscData , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , displayString , inputtedString , logInfo = None , only = False ): plaintextFormattedExcludes = \"\" rtfFormattedExcludes = \"\" valid = False while valid == False : if \"exclude\" in inputtedString . lower () or \"only\" in inputtedString . lower (): try : if \"exclude\" in inputtedString . lower (): # Account for if user is trying again isolateExpression = r \"(?<=exclude ).*\" # Matches everything after 'exclude' result = str ( re . search ( isolateExpression , inputtedString . lower ()) . group ( 0 )) elif \"only\" in inputtedString . lower (): isolateExpression = r \"(?<=only ).*\" # Matches everything after 'exclude' result = str ( re . search ( isolateExpression , inputtedString . lower ()) . group ( 0 )) # User didn't enter any numbers or they're not right except AttributeError : result = \"ThisStringCausesErrorNext\" else : #Take new input from further down result = inputtedString result = result . replace ( \" \" , \"\" ) validInputExpression = r '^[0-9,-]+$' # Ensures only digits, commas, and dashes are used if re . match ( validInputExpression , result ) == None : print ( f \" \\n { F . LIGHTRED_EX } Invalid input! { S . R } Must be a comma separated list of numbers and/or range of numbers. Please try again.\" ) if only == False : inputtedString = input ( \" \\n Enter the list of authors to exclude from deletion: \" ) elif only == True : inputtedString = input ( \" \\n Enter the list of only authors to delete: \" ) else : result = result . strip ( ',' ) # Remove leading/trailing comma result = utils . expand_ranges ( result ) # Expands ranges of numbers into a list of numbers chosenSampleIndexes = result . split ( \",\" ) valid = True for num in chosenSampleIndexes : # Check if any numbers outside max range if int ( num ) > len ( current . matchSamplesDict ) or int ( num ) < 1 : print ( f \" \\n { F . LIGHTRED_EX } Invalid input! { S . R } Number is outside the range of samples: { num } -- Please try again.\" ) valid = False break if valid == False : if only == False : inputtedString = input ( \" \\n Enter the comma separated list of numbers and/or ranges to exclude: \" ) elif only == True : inputtedString = input ( \" \\n Enter the comma separated list of numbers and/or ranges to delete: \" ) # Go through all the sample numbers, check if they are on the list given by user for authorID , info in current . matchSamplesDict . items (): if only == False : if str ( info [ 'index' ]) in chosenSampleIndexes : authorsToExcludeSet . add ( authorID ) elif only == True : if str ( info [ 'index' ]) not in chosenSampleIndexes : authorsToExcludeSet . add ( authorID ) # Get comment IDs to be excluded for comment , metadata in current . matchedCommentsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) for comment , metadata in current . duplicateCommentsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) for comment , metadata in current . otherCommentsByMatchedAuthorsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) for comment , metadata in current . spamThreadsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) # Remove all comments by selected authors from dictionary of comments for comment in commentIDExcludeSet : if comment in current . matchedCommentsDict . keys (): excludedCommentsDict [ comment ] = current . matchedCommentsDict . pop ( comment ) if comment in current . duplicateCommentsDict . keys (): excludedCommentsDict [ comment ] = current . duplicateCommentsDict . pop ( comment ) if comment in current . otherCommentsByMatchedAuthorsDict . keys (): excludedCommentsDict [ comment ] = current . otherCommentsByMatchedAuthorsDict . pop ( comment ) if comment in current . spamThreadsDict . keys (): excludedCommentsDict [ comment ] = current . spamThreadsDict . pop ( comment ) # Create strings that can be used in log files rtfFormattedExcludes += f \" \\\\ line \\n Comments Excluded From Deletion: \\\\ line \\n \" rtfFormattedExcludes += f \"(Values = Comment ID | Author ID | Author Name | Comment Text) \\\\ line \\n \" plaintextFormattedExcludes += f \" \\n Comments Excluded From Deletion: \\n \" plaintextFormattedExcludes += f \"(Values = Comment ID | Author ID | Author Name | Comment Text) \\n \" for commentID , meta in excludedCommentsDict . items (): sanitizedText = str ( excludedCommentsDict [ commentID ][ 'text' ]) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) rtfFormattedExcludes += f \" { str ( commentID ) } | { str ( excludedCommentsDict [ commentID ][ 'authorID' ]) } | { str ( excludedCommentsDict [ commentID ][ 'authorName' ]) } | { sanitizedText } \\\\ line \\n \" for commentID , meta in excludedCommentsDict . items (): sanitizedText = str ( excludedCommentsDict [ commentID ][ 'text' ]) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) plaintextFormattedExcludes += f \" { str ( commentID ) } | { str ( excludedCommentsDict [ commentID ][ 'authorID' ]) } | { str ( excludedCommentsDict [ commentID ][ 'authorName' ]) } | { sanitizedText } \\n \" # Verify removal for comment in current . matchedCommentsDict . keys (): if comment in commentIDExcludeSet : print ( f \" { F . LIGHTRED_EX } FATAL ERROR { S . R } : Something went wrong while trying to exclude comments. No comments have been deleted.\" ) print ( f \"You should { F . YELLOW } DEFINITELY { S . R } report this bug here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) print ( \"Provide the error code: X-1\" ) input ( \"Press Enter to Exit...\" ) sys . exit () # Get author names and IDs from dictionary, and display them for author in authorsToExcludeSet : displayString += f \" User ID: { author } | User Name: { current . matchSamplesDict [ author ][ 'authorName' ] } \\n \" print ( f \" \\n { F . CYAN } All { len ( excludedCommentsDict ) } comments { S . R } from the { F . CYAN } following users { S . R } are now { F . LIGHTGREEN_EX } excluded { S . R } from deletion:\" ) print ( displayString ) if config [ 'whitelist_excluded' ] == 'ask' : print ( f \" \\n Add these { F . LIGHTGREEN_EX } excluded { S . R } users to the { F . LIGHTGREEN_EX } whitelist { S . R } for future scans?\" ) addWhitelist = choice ( \"Whitelist Users?\" ) elif config [ 'whitelist_excluded' ] == True : addWhitelist = True elif config [ 'whitelist_excluded' ] == False : addWhitelist = False if addWhitelist == True : with open ( miscData . resources [ 'Whitelist' ][ 'PathWithName' ], \"a\" , encoding = \"utf-8\" ) as f : for author in authorsToExcludeSet : f . write ( f \"# [Excluded] Channel Name: { current . matchSamplesDict [ author ][ 'authorName' ] } | Channel ID: \" + \" \\n \" ) f . write ( f \" { author } \\n \" ) input ( \" \\n Press Enter to decide what to do with the rest...\" ) return current , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , rtfFormattedExcludes , plaintextFormattedExcludes # May use excludedCommentsDict later for printing them to log file get_all_author_comments \u00b6 get_all_author_comments ( current , config , miscData , allCommentsDict ) Source code in Scripts/operations.py 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_all_author_comments ( current , config , miscData , allCommentsDict ): # Make set of all matched author IDs print ( \" Finding all other comments by authors...\" , end = \" \\r \" ) totalCommentsAmount = len ( allCommentsDict ) scannedCount = 0 matchedAuthorIDSet = set () for _ , commentData in current . matchedCommentsDict . items (): matchedAuthorIDSet . add ( commentData [ 'authorID' ]) # Go through all comments for authorID , authorCommentsListofDicts in allCommentsDict . items (): if authorID in matchedAuthorIDSet : for commentDict in authorCommentsListofDicts : scannedCount += 1 print ( f \" Finding all other comments by authors: [ { scannedCount / totalCommentsAmount * 100 : .2f } % ]\" . ljust ( 40 , \" \" ), end = \" \\r \" ) if commentDict [ 'commentID' ] not in current . matchedCommentsDict : add_spam ( current , config , miscData , commentDict , commentDict [ 'videoID' ], matchReason = \"Also By Matched Author\" ) print ( \"\" . ljust ( 55 , \" \" )) return current get_comments \u00b6 get_comments ( current , filtersDict , miscData , config , allVideoCommentsDict , scanVideoID = None , nextPageToken = None , videosToScan = None ) Source code in Scripts/operations.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def get_comments ( current , filtersDict , miscData , config , allVideoCommentsDict , scanVideoID = None , nextPageToken = None , videosToScan = None ): # None are set as default if no parameters passed into function # Initialize some variables authorChannelName = None commentText = None parentAuthorChannelID = None fieldsToFetch = \"nextPageToken,items/snippet/topLevelComment/id,items/replies/comments,items/snippet/totalReplyCount,items/snippet/topLevelComment/snippet/videoId,items/snippet/topLevelComment/snippet/authorChannelId/value,items/snippet/topLevelComment/snippet/authorDisplayName,items/snippet/topLevelComment/snippet/textDisplay\" try : # Gets all comment threads for a specific video if scanVideoID is not None : results = auth . YOUTUBE . commentThreads () . list ( part = \"snippet, replies\" , videoId = scanVideoID , maxResults = 100 , pageToken = nextPageToken , fields = fieldsToFetch , textFormat = \"plainText\" ) . execute () # Get all comment threads across the whole channel elif scanVideoID is None : results = auth . YOUTUBE . commentThreads () . list ( part = \"snippet, replies\" , allThreadsRelatedToChannelId = auth . CURRENTUSER . id , maxResults = 100 , pageToken = nextPageToken , fields = fieldsToFetch , textFormat = \"plainText\" ) . execute () except HttpError as hx : traceback . print_exc () utils . print_http_error_during_scan ( hx ) current . errorOccurred = True return \"Error\" , None except Exception as ex : traceback . print_exc () utils . print_exception_during_scan ( ex ) current . errorOccurred = True return \"Error\" , None # Get token for next page. If no token, sets to 'End' RetrievedNextPageToken = results . get ( \"nextPageToken\" , \"End\" ) # After getting all comments threads for page, extracts data for each and stores matches in current.matchedCommentsDict # Also goes through each thread and executes get_replies() to get reply content and matches for item in results [ \"items\" ]: comment = item [ \"snippet\" ][ \"topLevelComment\" ] videoID = comment [ \"snippet\" ][ \"videoId\" ] parent_id = item [ \"snippet\" ][ \"topLevelComment\" ][ \"id\" ] numReplies = item [ \"snippet\" ][ \"totalReplyCount\" ] # On rare occasions a comment will be there but the channel name will be empty, so this allows placeholders try : limitedRepliesList = item [ \"replies\" ][ \"comments\" ] # API will return a limited number of replies (~5), but to get all, need to make separate call except KeyError : limitedRepliesList = [] pass try : parentAuthorChannelID = comment [ \"snippet\" ][ \"authorChannelId\" ][ \"value\" ] except KeyError : parentAuthorChannelID = \"[Deleted Channel]\" # Need to be able to catch exceptions because sometimes the API will return a comment from non-existent / deleted channel try : authorChannelName = comment [ \"snippet\" ][ \"authorDisplayName\" ] except KeyError : authorChannelName = \"[Deleted Channel]\" try : commentText = comment [ \"snippet\" ][ \"textDisplay\" ] # Remove Return carriages except KeyError : commentText = \"[Deleted/Missing Comment]\" # Runs check against comment info for whichever filter data is relevant currentCommentDict = { 'authorChannelID' : parentAuthorChannelID , 'parentAuthorChannelID' : None , 'authorChannelName' : authorChannelName , 'commentText' : commentText , 'commentID' : parent_id , 'videoID' : videoID , } check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID ) current . scannedCommentsCount += 1 #Log All Comments try : allVideoCommentsDict [ parentAuthorChannelID ] . append ( currentCommentDict ) except KeyError : allVideoCommentsDict [ parentAuthorChannelID ] = [ currentCommentDict ] except TypeError : pass # If there are more replies than in the limited list if numReplies > 0 and len ( limitedRepliesList ) < numReplies : if numReplies > 7 and ( filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"SensitiveSmart\" ) and config [ 'detect_spam_threads' ] == True : parentCommentDict = currentCommentDict else : parentCommentDict = None allVideoCommentsDict = get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , parentCommentDict = parentCommentDict ) if allVideoCommentsDict == \"Error\" : return \"Error\" , None # If all the replies are in the limited list elif numReplies > 0 and len ( limitedRepliesList ) == numReplies : # limitedRepliesList can never be more than numReplies allVideoCommentsDict = get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , repliesList = limitedRepliesList ) if allVideoCommentsDict == \"Error\" : return \"Error\" , None else : print_count_stats ( current , miscData , videosToScan , final = False ) # Updates displayed stats if no replies # Runs after all comments scanned if RetrievedNextPageToken == \"End\" and allVideoCommentsDict : dupeCheckModes = utils . string_to_list ( config [ 'duplicate_check_modes' ]) if filtersDict [ 'filterMode' ] . lower () in dupeCheckModes : print ( \" Analyzing For Duplicates \" , end = \" \\r \" ) check_duplicates ( current , config , miscData , allVideoCommentsDict , videoID ) current . allScannedCommentsDict . update ( allVideoCommentsDict ) return RetrievedNextPageToken , allVideoCommentsDict get_recent_videos \u00b6 get_recent_videos ( channel_id , numVideosTotal ) Source code in Scripts/operations.py 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 def get_recent_videos ( channel_id , numVideosTotal ): def get_block_of_videos ( nextPageToken , j , k , numVideosBlock = 5 ): result = auth . YOUTUBE . search () . list ( part = \"snippet\" , channelId = channel_id , type = 'video' , order = 'date' , pageToken = nextPageToken , #fields='nextPageToken,items/id/videoId,items/snippet/title', maxResults = numVideosBlock , ) . execute () for item in result [ 'items' ]: videoID = str ( item [ 'id' ][ 'videoId' ]) videoTitle = str ( item [ 'snippet' ][ 'title' ]) . replace ( \"&quot;\" , \" \\\" \" ) . replace ( \"&#39;\" , \"'\" ) commentCount = validation . validate_video_id ( videoID , pass_exception = True )[ 3 ] #Skips over video if comment count is zero, or comments disabled / is live stream if str ( commentCount ) == '0' : print ( f \" { B . YELLOW }{ F . BLACK } Skipping { S . R } { F . LIGHTRED_EX } Video with no comments: { S . R } \" + str ( item [ 'snippet' ][ 'title' ])) k += 1 continue recentVideos . append ({}) recentVideos [ j ][ 'videoID' ] = videoID recentVideos [ j ][ 'videoTitle' ] = videoTitle if str ( commentCount ) == \"MainMenu\" : return None , None , \"MainMenu\" recentVideos [ j ][ 'commentCount' ] = commentCount j += 1 k += 1 # Get token for next page try : nextPageToken = result [ 'nextPageToken' ] except KeyError : nextPageToken = \"End\" # 0 1 2 3 return nextPageToken , j , k , \"\" #---------------------------------------------------------------- nextPageToken = None recentVideos = [] #List of dictionaries abortCheck = \"\" # Used to receive \"MainMenu\" if user wants to exit, when entering j , k = 0 , 0 # i = number of videos added to list, k = number of videos checked (different only if one video skipped because no comments) if numVideosTotal <= 5 : result = get_block_of_videos ( None , j , k , numVideosBlock = numVideosTotal ) if result [ 3 ] == \"MainMenu\" : return \"MainMenu\" else : while nextPageToken != \"End\" and k < numVideosTotal and str ( abortCheck ) != \"MainMenu\" : print ( \"Retrieved \" + str ( len ( recentVideos )) + \"/\" + str ( numVideosTotal ) + \" videos.\" , end = \" \\r \" ) remainingVideos = numVideosTotal - k if remainingVideos <= 5 : nextPageToken , j , k , abortCheck = get_block_of_videos ( nextPageToken , j , k , numVideosBlock = remainingVideos ) else : nextPageToken , j , k , abortCheck = get_block_of_videos ( nextPageToken , j , k , numVideosBlock = 5 ) if str ( nextPageToken [ 0 ]) == \"MainMenu\" : return \"MainMenu\" print ( \" \" ) return recentVideos get_replies \u00b6 get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , parentCommentDict = None , repliesList = None ) Source code in Scripts/operations.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 def get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , parentCommentDict = None , repliesList = None ): # Initialize some variables authorChannelName = None commentText = None threadDict = {} if repliesList == None : fieldsToFetch = \"nextPageToken,items/snippet/authorChannelId/value,items/id,items/snippet/authorDisplayName,items/snippet/textDisplay\" replies = [] replyPageToken = None while replyPageToken != \"End\" : try : results = auth . YOUTUBE . comments () . list ( part = \"snippet\" , parentId = parent_id , pageToken = replyPageToken , maxResults = 100 , fields = fieldsToFetch , textFormat = \"plainText\" ) . execute () except HttpError as hx : traceback . print_exc () utils . print_http_error_during_scan ( hx ) current . errorOccurred = True return \"Error\" except Exception as ex : traceback . print_exc () utils . print_exception_during_scan ( ex ) current . errorOccurred = True return \"Error\" replies . extend ( results [ \"items\" ]) # Get token for next page try : replyPageToken = results [ 'nextPageToken' ] except KeyError : replyPageToken = \"End\" else : replies = repliesList # Create list of author names in current thread, add into list - Only necessary when scanning comment text allThreadAuthorNames = [] # Iterates through items in results # Need to be able to catch exceptions because sometimes the API will return a comment from non-existent / deleted channel # Need individual tries because not all are fetched for each mode for reply in replies : replyID = reply [ \"id\" ] try : authorChannelID = reply [ \"snippet\" ][ \"authorChannelId\" ][ \"value\" ] except KeyError : authorChannelID = \"[Deleted Channel]\" # Get author display name try : authorChannelName = reply [ \"snippet\" ][ \"authorDisplayName\" ] if filtersDict [ 'filterMode' ] == \"Username\" or filtersDict [ 'filterMode' ] == \"AutoASCII\" or filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"NameAndText\" : allThreadAuthorNames . append ( authorChannelName ) except KeyError : authorChannelName = \"[Deleted Channel]\" # Comment Text try : commentText = reply [ \"snippet\" ][ \"textDisplay\" ] # Remove Return carriages except KeyError : commentText = \"[Deleted/Missing Comment]\" # Runs check against comment info for whichever filter data is relevant currentCommentDict = { 'authorChannelID' : authorChannelID , 'parentAuthorChannelID' : parentAuthorChannelID , 'authorChannelName' : authorChannelName , 'commentText' : commentText , 'commentID' : replyID , 'videoID' : videoID } if parentCommentDict : threadDict [ replyID ] = currentCommentDict check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID , allThreadAuthorNames = allThreadAuthorNames ) #Log All Comments try : allVideoCommentsDict [ authorChannelID ] . append ( currentCommentDict ) except KeyError : allVideoCommentsDict [ authorChannelID ] = [ currentCommentDict ] except TypeError : pass # Update latest stats current . scannedRepliesCount += 1 print_count_stats ( current , miscData , videosToScan , final = False ) if parentCommentDict : current = check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ) return allVideoCommentsDict make_community_thread_dict \u00b6 make_community_thread_dict ( commentID , allCommunityCommentsDict ) Source code in Scripts/operations.py 453 454 455 456 457 458 459 460 def make_community_thread_dict ( commentID , allCommunityCommentsDict ): threadDict = {} if \".\" not in commentID : # Checks if is top level comment or reply for id in allCommunityCommentsDict . keys (): if commentID in id and commentID != id : threadDict [ id ] = allCommunityCommentsDict [ id ] return threadDict print_count_stats \u00b6 print_count_stats ( current , miscData , videosToScan , final ) Source code in Scripts/operations.py 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 def print_count_stats ( current , miscData , videosToScan , final ): # Use videosToScan (list of dictionaries) to retrieve total number of comments if videosToScan and miscData . totalCommentCount > 0 : totalComments = miscData . totalCommentCount totalScanned = current . scannedRepliesCount + current . scannedCommentsCount percent = (( totalScanned / totalComments ) * 100 ) progress = f \"Total: [ { str ( totalScanned ) } / { str ( totalComments ) } ] ( { percent : .0f } %) \" . ljust ( 27 , \" \" ) + \"|\" #Formats percentage to 0 decimal places else : progress = \"\" comScanned = str ( current . scannedCommentsCount ) repScanned = str ( current . scannedRepliesCount ) matchCount = str ( len ( current . matchedCommentsDict ) + len ( current . spamThreadsDict )) if final == True : print ( f \" { progress } Comments Scanned: { F . YELLOW }{ comScanned }{ S . R } | Replies Scanned: { F . YELLOW }{ repScanned }{ S . R } | Matches Found So Far: { F . LIGHTRED_EX }{ matchCount }{ S . R } \\n \" ) else : print ( f \" { progress } Comments Scanned: { F . YELLOW }{ comScanned }{ S . R } | Replies Scanned: { F . YELLOW }{ repScanned }{ S . R } | Matches Found So Far: { F . LIGHTRED_EX }{ matchCount }{ S . R } \" , end = \" \\r \" ) return None","title":"operations"},{"location":"reference/Scripts/operations/#Scripts.operations.CommentFoundError","text":"Bases: Exception Source code in Scripts/operations.py 948 949 class CommentFoundError ( Exception ): pass","title":"CommentFoundError"},{"location":"reference/Scripts/operations/#Scripts.operations.CommentNotFoundError","text":"Bases: Exception Source code in Scripts/operations.py 1019 1020 class CommentNotFoundError ( Exception ): pass","title":"CommentNotFoundError"},{"location":"reference/Scripts/operations/#Scripts.operations.add_spam","text":"add_spam ( current , config , miscData , currentCommentDict , videoID , matchReason = 'Filter Match' ) Source code in Scripts/operations.py 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 def add_spam ( current , config , miscData , currentCommentDict , videoID , matchReason = \"Filter Match\" ): if matchReason == \"Filter Match\" : dictToUse = current . matchedCommentsDict elif matchReason == \"Duplicate\" : dictToUse = current . duplicateCommentsDict elif matchReason == \"Also By Matched Author\" : dictToUse = current . otherCommentsByMatchedAuthorsDict elif matchReason == \"Spam Bot Thread\" : dictToUse = current . spamThreadsDict commentID = currentCommentDict [ 'commentID' ] authorChannelName = currentCommentDict [ 'authorChannelName' ] authorChannelID = currentCommentDict [ 'authorChannelID' ] commentTextRaw = str ( currentCommentDict [ 'commentText' ]) # Use str() to ensure not pointing to same place in memory commentText = str ( currentCommentDict [ 'commentText' ]) . replace ( \" \\r \" , \"\" ) dictToUse [ commentID ] = { 'text' : commentText , 'textUnsanitized' : commentTextRaw , 'authorName' : authorChannelName , 'authorID' : authorChannelID , 'videoID' : videoID , 'matchReason' : matchReason } current . vidIdDict [ commentID ] = videoID # Probably remove this later, but still being used for now # Count of comments per author if authorChannelID in current . authorMatchCountDict : current . authorMatchCountDict [ authorChannelID ] += 1 else : current . authorMatchCountDict [ authorChannelID ] = 1 if config [ 'json_log' ] == True and config [ 'json_extra_data' ] == True : dictToUse [ commentID ][ 'uploaderChannelID' ] = miscData . channelOwnerID dictToUse [ commentID ][ 'uploaderChannelName' ] = miscData . channelOwnerName dictToUse [ commentID ][ 'videoTitle' ] = utils . get_video_title ( current , videoID )","title":"add_spam()"},{"location":"reference/Scripts/operations/#Scripts.operations.check_against_filter","text":"check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID , allThreadAuthorNames = None ) Source code in Scripts/operations.py 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 def check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID , allThreadAuthorNames = None ): # Retrieve Data from currentCommentDict commentID = currentCommentDict [ 'commentID' ] authorChannelName = currentCommentDict [ 'authorChannelName' ] authorChannelID = currentCommentDict [ 'authorChannelID' ] parentAuthorChannelID = currentCommentDict [ 'parentAuthorChannelID' ] commentTextRaw = str ( currentCommentDict [ 'commentText' ]) # Use str() to ensure not pointing to same place in memory commentText = str ( currentCommentDict [ 'commentText' ]) . replace ( \" \\r \" , \"\" ) # #Debugging # print(f\"{F.LIGHTRED_EX}DEBUG MODE{S.R} - If you see this, I forgot to disable it before release, oops. \\n Please report here: {F.YELLOW}TJoe.io/bug-report{S.R}\") # print(\"Comment ID: \" + commentID) # debugSingleComment = True #Debug usage # if debugSingleComment == True: # authorChannelName = input(\"Channel Name: \") # commentText = input(\"Comment Text: \") # authorChannelID = \"x\" # Do not even check comment if: Author is Current User, Author is Channel Owner, or Author is in whitelist if auth . CURRENTUSER . id != authorChannelID and miscData . channelOwnerID != authorChannelID and authorChannelID not in miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ]: if \"@\" in commentText : # Logic to avoid false positives from replies to spammers if allThreadAuthorNames and ( filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"NameAndText\" ): for name in allThreadAuthorNames : if \"@\" + str ( name ) in commentText : commentText = commentText . replace ( \"@\" + str ( name ), \"\" ) # Extra logic to detect false positive if spammer's comment already deleted, but someone replied if current . matchedCommentsDict and filtersDict [ 'filterMode' ] == \"AutoSmart\" : for key , value in current . matchedCommentsDict . items (): if \"@\" + str ( value [ 'authorName' ]) in commentText : remove = True for key2 , value2 in current . matchedCommentsDict . items (): if value2 [ 'authorID' ] == authorChannelID : remove = False if remove == True : commentText = commentText . replace ( \"@\" + str ( value [ 'authorName' ]), \"\" ) # Checks author of either parent comment or reply (both passed in as commentID) against channel ID inputted by user if filtersDict [ 'filterMode' ] == \"ID\" : if any ( authorChannelID == x for x in filtersDict [ 'CustomChannelIdFilter' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Username elif filtersDict [ 'filterMode' ] == \"Username\" : if filtersDict [ 'filterSubMode' ] == \"chars\" : authorChannelName = utils . make_char_set ( str ( authorChannelName )) if any ( x in filtersDict [ 'CustomUsernameFilter' ] for x in authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"string\" : if utils . check_list_against_string ( listInput = filtersDict [ 'CustomUsernameFilter' ], stringInput = authorChannelName , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"regex\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Comment Text elif filtersDict [ 'filterMode' ] == \"Text\" : if filtersDict [ 'filterSubMode' ] == \"chars\" : commentText = utils . make_char_set ( str ( commentText )) if any ( x in filtersDict [ 'CustomCommentTextFilter' ] for x in commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"string\" : if utils . check_list_against_string ( listInput = filtersDict [ 'CustomCommentTextFilter' ], stringInput = commentText , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"regex\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Name and Text elif filtersDict [ 'filterMode' ] == \"NameAndText\" : if filtersDict [ 'filterSubMode' ] == \"chars\" : authorChannelName = utils . make_char_set ( str ( authorChannelName )) commentText = utils . make_char_set ( str ( commentText )) if any ( x in filtersDict [ 'CustomUsernameFilter' ] for x in authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( x in filtersDict [ 'CustomCommentTextFilter' ] for x in commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"string\" : if utils . check_list_against_string ( listInput = filtersDict [ 'CustomUsernameFilter' ], stringInput = authorChannelName , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif utils . check_list_against_string ( listInput = filtersDict [ 'CustomCommentTextFilter' ], stringInput = commentText , caseSensitive = False ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif filtersDict [ 'filterSubMode' ] == \"regex\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), commentText ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Auto ASCII (in username) elif filtersDict [ 'filterMode' ] == \"AutoASCII\" : if re . search ( str ( filtersDict [ 'CustomRegexPattern' ]), authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Check Modes: Auto Smart (in username or comment text) # Here inputtedComment/Author Filters are tuples of, where 2nd element is list of char-sets to check against ## Also Check if reply author ID is same as parent comment author ID, if so, ignore (to account for users who reply to spammers) elif filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"SensitiveSmart\" : smartFilter = filtersDict [ 'CustomCommentTextFilter' ] # Receive Variables compiledRegexDict = smartFilter [ 'compiledRegexDict' ] numberFilterSet = smartFilter [ 'spammerNumbersSet' ] compiledNumRegex = smartFilter [ 'compiledNumRegex' ] minNumbersMatchCount = smartFilter [ 'minNumbersMatchCount' ] bufferChars = compiledRegexDict [ 'bufferChars' ] #usernameBlackCharsSet = smartFilter['usernameBlackCharsSet'] spamGenEmojiSet = smartFilter [ 'spamGenEmojiSet' ] redAdEmojiSet = smartFilter [ 'redAdEmojiSet' ] yellowAdEmojiSet = smartFilter [ 'yellowAdEmojiSet' ] hrtSet = smartFilter [ 'hrtSet' ] lowAlSet = smartFilter [ 'lowAlSet' ] languages = smartFilter [ 'languages' ] sensitive = smartFilter [ 'sensitive' ] rootDomainRegex = smartFilter [ 'rootDomainRegex' ] # Spam Lists spamListCombinedRegex = smartFilter [ 'spamListCombinedRegex' ] # if debugSingleComment == True: # if input(\"Sensitive True/False: \").lower() == 'true': sensitive = True # else: sensitive = False # Check for sensitive smart mode if sensitive : rootDomainRegex = smartFilter [ 'sensitiveRootDomainRegex' ] # Functions -------------------------------------------------------------- def findOnlyObfuscated ( regexExpression , originalWord , stringToSearch ): # Confusable thinks s and f look similar, have to compensate to avoid false positive ignoredConfusablesConverter = { ord ( 'f' ): ord ( 's' ), ord ( 's' ): ord ( 'f' )} result = re . findall ( regexExpression , stringToSearch . lower ()) if not result : return False else : for match in result : lowerWord = originalWord . lower () for char in compiledRegexDict [ 'bufferChars' ]: match = match . strip ( char ) if match . lower () != lowerWord and match . lower () != lowerWord . translate ( ignoredConfusablesConverter ): return True def remove_unicode_categories ( string ): return \"\" . join ( char for char in string if unicodedata . category ( char ) not in smartFilter [ 'unicodeCategoriesStrip' ]) def check_if_only_link ( string ): result = re . match ( compiledRegexDict [ 'onlyVideoLinkRegex' ], string ) if not result : return False elif result . group ( 0 ) and len ( result . group ( 0 )) == len ( string ): return True else : return False # ------------------------------------------------------------------------ # Normalize usernames and text, remove multiple whitespace and invisible chars commentText = re . sub ( ' +' , ' ' , commentText ) # https://stackoverflow.com/a/49695605/17312053 commentText = \"\" . join ( k if k in bufferChars else \"\" . join ( v ) for k , v in itertools . groupby ( commentText , lambda c : c )) commentText = remove_unicode_categories ( commentText ) authorChannelName = re . sub ( ' +' , ' ' , authorChannelName ) authorChannelName = remove_unicode_categories ( authorChannelName ) # Processed Variables combinedString = authorChannelName + commentText combinedSet = utils . make_char_set ( combinedString , stripLettersNumbers = True , stripPunctuation = True ) upLowTextSet = set ( commentText . replace ( miscData . channelOwnerName , \"\" )) #usernameSet = utils.make_char_set(authorChannelName) # Run Checks if authorChannelID == parentAuthorChannelID : pass elif len ( numberFilterSet . intersection ( combinedSet )) >= minNumbersMatchCount : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif compiledNumRegex . search ( combinedString ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Black Tests #elif usernameBlackCharsSet.intersection(usernameSet): # add_spam(current, config, miscData, currentCommentDict, videoID) elif any ( re . search ( expression [ 1 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif config [ 'detect_sub_challenge_spam' ] and any ( re . search ( expression [ 1 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameNovidBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], combinedString ) for expression in compiledRegexDict [ 'blackAdWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], commentText ) for expression in compiledRegexDict [ 'textObfuBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( word in commentText . lower () for word in compiledRegexDict [ 'textExactBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any (( word in commentText and not upLowTextSet . intersection ( lowAlSet )) for word in compiledRegexDict [ 'textUpLowBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameObfuBlackWords' ]): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif re . search ( spamListCombinedRegex , combinedString ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif config [ 'detect_link_spam' ] and check_if_only_link ( commentText . strip ()): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif sensitive and re . search ( smartFilter [ 'usernameConfuseRegex' ], authorChannelName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) elif not sensitive and ( findOnlyObfuscated ( smartFilter [ 'usernameConfuseRegex' ], miscData . channelOwnerName , authorChannelName ) or authorChannelName == miscData . channelOwnerName ): add_spam ( current , config , miscData , currentCommentDict , videoID ) # Multi Criteria Tests else : # Defaults yellowCount = 0 redCount = 0 languageCount = 0 for language in languages : if language [ 2 ] . intersection ( combinedSet ): languageCount += 1 # Yellow Tests if any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], combinedString ) for expression in compiledRegexDict [ 'yellowAdWords' ]): yellowCount += 1 hrtTest = len ( hrtSet . intersection ( combinedSet )) if hrtTest >= 2 : if not sensitive : yellowCount += 1 else : redCount += 1 elif sensitive and hrtTest >= 1 : yellowCount += 1 if yellowAdEmojiSet . intersection ( combinedSet ): yellowCount += 1 if not sensitive and spamGenEmojiSet . intersection ( combinedSet ): yellowCount += 1 if combinedString . count ( '#' ) >= 5 : yellowCount += 1 if combinedString . count ( ' \\n ' ) >= 10 : yellowCount += 1 if languageCount >= 2 : yellowCount += 1 if re . search ( rootDomainRegex , combinedString . lower ()): yellowCount += 1 # Red Tests #if any(foundObfuscated(re.findall(expression[1], combinedString), expression[0]) for expression in compiledRegexDict['redAdWords']): if any ( findOnlyObfuscated ( expression [ 1 ], expression [ 0 ], combinedString ) for expression in compiledRegexDict [ 'redAdWords' ]): redCount += 1 if any ( re . search ( expression [ 1 ], combinedString ) for expression in compiledRegexDict [ 'exactRedAdWords' ]): redCount += 1 if redAdEmojiSet . intersection ( combinedSet ): redCount += 1 if sensitive and spamGenEmojiSet . intersection ( combinedSet ): redCount += 1 if any ( re . search ( expression [ 1 ], authorChannelName ) for expression in compiledRegexDict [ 'usernameRedWords' ]): redCount += 1 # Calculate Score if yellowCount >= 3 : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif redCount >= 2 : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif redCount >= 1 and yellowCount >= 1 : add_spam ( current , config , miscData , currentCommentDict , videoID ) elif sensitive and redCount >= 1 : add_spam ( current , config , miscData , currentCommentDict , videoID ) else : pass","title":"check_against_filter()"},{"location":"reference/Scripts/operations/#Scripts.operations.check_deleted_comments","text":"check_deleted_comments ( commentInput ) Source code in Scripts/operations.py 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 def check_deleted_comments ( commentInput ): i = 0 # Count number of remaining comments j = 1 # Count number of checked total = len ( commentInput ) unsuccessfulResults = [] commentList = [] if type ( commentInput ) == list : commentList = commentInput elif type ( commentInput ) == dict : commentList = list ( commentInput . keys ()) # Wait 2 seconds so YouTube API has time to update comment status print ( \" Preparing to check deletion status...\" , end = \" \\r \" ) time . sleep ( 1 ) print ( \" \" ) print ( \" (Note: You can disable deletion success checking in the config file, to save time and API quota) \\n \" ) for commentID in commentList : try : results = auth . YOUTUBE . comments () . list ( part = \"snippet\" , id = commentID , maxResults = 1 , fields = \"items\" , textFormat = \"plainText\" ) . execute () print ( \"Verifying Deleted Comments: [\" + str ( j ) + \" / \" + str ( total ) + \"]\" , end = \" \\r \" ) j += 1 if results [ \"items\" ]: # Check if the items result is empty raise CommentFoundError # If comment is found and possibly not deleted, print out video ID and comment ID except CommentFoundError : if type ( commentInput ) == dict : print ( \"Possible Issue Deleting Comment: \" + str ( commentID ) + \" | Check Here: \" + \"https://www.youtube.com/watch?v=\" + str ( commentInput [ commentID ][ 'videoID' ]) + \"&lc=\" + str ( commentID )) elif type ( commentInput ) == list : print ( \"Possible Issue Deleting Comment: \" + str ( commentID )) i += 1 unsuccessfulResults . append ( results ) pass except Exception : if type ( commentInput ) == dict : print ( \"Unhandled Exception While Deleting Comment: \" + str ( commentID ) + \" | Check Here: \" + \"https://www.youtube.com/watch?v=\" + str ( commentInput [ commentID ][ 'videoID' ]) + \"&lc=\" + str ( commentID )) elif type ( commentInput ) == list : print ( \"Unhandled Exception While Deleting Comment: \" + str ( commentID )) i += 1 unsuccessfulResults . append ( results ) pass if i == 0 : print ( \" \\n\\n Success: All comments should be gone.\" ) elif i > 0 : print ( \" \\n\\n Warning: \" + str ( i ) + \" comments may remain. Check links above or try running the program again. An error log file has been created: 'Deletion_Error_Log.txt'\" ) # Write error log with open ( \"Deletion_Error_Log.txt\" , \"a\" , encoding = \"utf-8\" ) as f : f . write ( \"----- YT Spammer Purge Error Log: Possible Issue Deleting Comments ------ \\n\\n \" ) f . write ( str ( unsuccessfulResults )) f . write ( \" \\n\\n \" ) f . close () else : print ( \" \\n\\n Something strange happened... The comments may or may have not been deleted.\" ) return None","title":"check_deleted_comments()"},{"location":"reference/Scripts/operations/#Scripts.operations.check_duplicates","text":"check_duplicates ( current , config , miscData , allVideoCommentsDict , videoID ) Source code in Scripts/operations.py 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 def check_duplicates ( current , config , miscData , allVideoCommentsDict , videoID ): # Get Lenvenshtein Distance Setting try : levenshtein = float ( config [ 'levenshtein_distance' ]) if levenshtein < 0 or levenshtein > 1 : print ( \" \\n Error: Levenshtein_distance config setting must be between 0 and 1. Defaulting to 0.9\" ) input ( \" \\n Press Enter to continue...\" ) levenshtein = 0.9 except ValueError : print ( \" \\n Error: Levenshtein_distance config setting must be a number between 0 and 1. Defaulting to 0.9\" ) input ( \" \\n Press Enter to continue...\" ) levenshtein = 0.9 # Get duplicate count setting try : minimum_duplicates = int ( config [ 'minimum_duplicates' ]) if minimum_duplicates < 2 : minimum_duplicates = 4 print ( \" \\n Error: Minimum_Duplicates config setting must be greater than 1. Defaulting to 4.\" ) input ( \" \\n Press Enter to continue...\" ) except ValueError : minimum_duplicates = 4 print ( \" \\n Error: Minimum_Duplicates config setting is invalid. Defaulting to 4.\" ) input ( \" \\n Press Enter to continue...\" ) # Calculate number of authors to check, for progress authorCount = len ( allVideoCommentsDict ) scannedCount = 0 # Run the actual duplicate checking for authorID , authorCommentsList in allVideoCommentsDict . items (): # Don't scan channel owner, current user, or any user in whitelist. Also don't bother if author is already in matchedCommentsDict if auth . CURRENTUSER . id == authorID or miscData . channelOwnerID == authorID or authorID in miscData . resources [ 'Whitelist' ][ 'WhitelistContents' ] or any ( authorID == value [ 'authorID' ] for key , value in current . matchedCommentsDict . items ()): scannedCount += 1 print ( f \" Analyzing For Duplicates: [ { scannedCount / authorCount * 100 : .2f } % ] (Can be disabled & customized in config)\" . ljust ( 75 , \" \" ), end = \" \\r \" ) else : numDupes = 0 commentTextList = [] matchedIndexes = [] for commentDict in authorCommentsList : commentTextList . append ( commentDict [ 'commentText' ]) # Count number of comments that are similar to at least one other comment if len ( commentTextList ) > 1 : for i , x in enumerate ( commentTextList ): for j in range ( i + 1 , len ( commentTextList )): y = commentTextList [ j ] if ratio ( x , y ) > levenshtein : # List the indexes of the matched comments in the list matchedIndexes . append ( i ) matchedIndexes . append ( j ) break # Only count each comment once by counting number of unique indexes in matchedIndexes uniqueMatches = len ( set ( matchedIndexes )) if uniqueMatches >= minimum_duplicates : numDupes += uniqueMatches if numDupes > 0 : for commentDict in authorCommentsList : add_spam ( current , config , miscData , commentDict , videoID , matchReason = \"Duplicate\" ) scannedCount += 1 print ( f \" Analyzing For Duplicates: [ { scannedCount / authorCount * 100 : .2f } % ] (Can be disabled & customized in config)\" . ljust ( 75 , \" \" ), end = \" \\r \" ) print ( \"\" . ljust ( 90 , \" \" )) # Erase line","title":"check_duplicates()"},{"location":"reference/Scripts/operations/#Scripts.operations.check_recovered_comments","text":"check_recovered_comments ( commentsList ) Source code in Scripts/operations.py 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 def check_recovered_comments ( commentsList ): i = 0 # Count number of remaining comments j = 1 # Count number of checked total = len ( commentsList ) unsuccessfulResults = [] for comment in commentsList : try : results = auth . YOUTUBE . comments () . list ( part = \"snippet\" , id = comment , maxResults = 1 , fields = \"items\" , textFormat = \"plainText\" ) . execute () print ( \"Verifying Deleted Comments: [\" + str ( j ) + \" / \" + str ( total ) + \"]\" , end = \" \\r \" ) j += 1 if not results [ \"items\" ]: # Check if the items result is empty raise CommentNotFoundError except CommentNotFoundError : #print(\"Possible Issue Deleting Comment: \" + str(key) + \" | Check Here: \" + \"https://www.youtube.com/watch?v=\" + str(value) + \"&lc=\" + str(key)) print ( \"Possible Issue Restoring Comment: \" + str ( comment )) i += 1 unsuccessfulResults . append ( comment ) if i == 0 : print ( f \" \\n\\n { F . LIGHTGREEN_EX } Success: All spam comments should be restored! { S . R } \" ) print ( \"You can view them by using the links to them in the same log file you used.\" ) elif i > 0 : print ( \" \\n\\n Warning: \" + str ( i ) + \" comments may have not been restored. See above list.\" ) print ( \"Use the links to the comments from the log file you used, to verify if they are back or not.\" ) input ( \" \\n Recovery process finished. Press Enter to return to main menu...\" ) return True","title":"check_recovered_comments()"},{"location":"reference/Scripts/operations/#Scripts.operations.check_spam_threads","text":"check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ) Source code in Scripts/operations.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 def check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ): threadWords = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'threadWords' ] threadPhrases = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'threadPhrases' ] monetWords = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'monetWords' ] monetStrings = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'monetStrings' ] nameRegex = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'nameRegex' ] nakedNameRegex = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'nakedNameRegex' ] cashRegex = filtersDict [ 'CustomCommentTextFilter' ][ 'threadFiltersDict' ][ 'cashRegex' ] ignoreList = [ 'earn' , 'trade' , 'invest' , 'signal' , 'crypto' , ' is' , ' she' , ' he' ] spam = False threadAnalysisDict = {} preliminaryCount , redCount , yellowCount , nameCount , fullNameCount , partialNameCount , susMentionCount = 0 , 0 , 0 , 0 , 0 , 0 , 0 nameList , partialNameList , fullNameList = [] , [], [] name , partialName , fullName = \"\" , \"\" , \"\" if any ( item in parentCommentDict [ 'commentText' ] . lower () for item in miscData . spamLists [ 'spamThreadsList' ]): add_spam ( current , config , miscData , parentCommentDict , parentCommentDict [ 'videoID' ], matchReason = \"Spam Bot Thread\" ) return current # Preliminary Analysis for word in threadWords : if word in parentCommentDict [ 'commentText' ] . lower (): preliminaryCount += 1 if preliminaryCount < 2 : return current # Shoves all comments by each author into one each. Each author ID is key, combined comments text is value for _ , data in threadDict . items (): if data [ 'authorChannelID' ] in threadAnalysisDict : threadAnalysisDict [ data [ 'authorChannelID' ]] = threadAnalysisDict [ data [ 'authorChannelID' ]] + \" \" + re . sub ( ' +' , ' ' , data [ 'commentText' ] . lower ()) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) else : threadAnalysisDict [ data [ 'authorChannelID' ]] = re . sub ( ' +' , ' ' , data [ 'commentText' ] . lower ()) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) # When all authors have one combined comment text, put each into list threadAnalysisList = list ( threadAnalysisDict . values ()) # ------------------------------------------------------------------------------- def processResult ( regResult , naked ): len1 = len ( regResult . group ( 1 )) len2 = len ( regResult . group ( 2 )) len3 = len ( regResult . group ( 3 )) if not ( naked and len1 > 2 and len3 > 2 ) or ( naked and len2 >= 4 and len3 >= 5 ): name = regResult . group ( 2 ) . strip () + \" \" + regResult . group ( 3 ) . strip () name = re . sub ( ' +' , ' ' , name ) else : name = \"\" if not naked : partialName = regResult . group ( 1 ) . strip () + \" \" + regResult . group ( 2 ) . strip () partialName = re . sub ( ' +' , ' ' , partialName ) else : partialName = \"\" if not naked : fullName = regResult . group ( 0 ) else : fullName = \"\" return name , partialName , fullName # ------------------------------------------------------------------------------- def regexSearchNames ( regex , name , partialName , fullName , naked = False ): # Get Potential Names for comment in threadAnalysisList : regResult = re . search ( regex , comment ) if regResult : x , y , z = processResult ( regResult , naked ) # Strip empty name . append ( x ) partialName . append ( y ) fullName . append ( z ) regResult = re . search ( regex , parentCommentDict [ 'commentText' ] . lower ()) if regResult : x , y , z = processResult ( regResult , naked ) if x : name . append ( x ) if y : partialName . append ( y ) if z : fullName . append ( z ) return name , partialName , fullName # ------------------------------------------------------------------------------- def remove_ignore ( nameList ): removeList = [] for n in nameList : for word in ignoreList : if word in n : removeList . append ( n ) if removeList : for item in removeList : if item in nameList : nameList . remove ( item ) return nameList # ------------------------------------------------------------------------------- nameList , partialNameList , fullNameList = regexSearchNames ( nameRegex , nameList , partialNameList , fullNameList ) if not nameList : nameList , partialNameList , fullNameList = regexSearchNames ( nakedNameRegex , nameList , partialNameList , fullNameList , naked = True ) partialNameList = [] fullNameList = [] while \"\" in nameList : nameList . remove ( \"\" ) while \"\" in partialNameList : partialNameList . remove ( \"\" ) while \"\" in fullNameList : fullNameList . remove ( \"\" ) # Determine most common names if nameList : name = max ( set ( nameList ), key = nameList . count ) if nameList . count ( name ) == 1 : nameList = remove_ignore ( nameList ) if nameList : name = max ( set ( nameList ), key = nameList . count ) else : name = \"\" if partialNameList : partialName = max ( set ( partialNameList ), key = partialNameList . count ) if partialNameList . count ( partialName ) == 1 : partialNameList = remove_ignore ( partialNameList ) if partialNameList : partialName = max ( set ( partialNameList ), key = partialNameList . count ) else : partialName = \"\" if fullNameList : fullName = max ( set ( fullNameList ), key = fullNameList . count ) if fullNameList . count ( fullName ) == 1 : fullNameList = remove_ignore ( fullNameList ) if fullNameList : fullName = max ( set ( fullNameList ), key = fullNameList . count ) else : fullName = \"\" # Analyze Thread for comment in threadAnalysisList : if name : if fullName and fullName in comment : fullNameCount += 1 elif name and name in comment : nameCount += 1 elif partialName and partialName in comment : partialNameCount += 1 susMention = False if any ( word in comment for word in threadWords ): yellowCount += 1 susMention = True if any ( phrase in comment for phrase in threadPhrases ): redCount += 1 susMention = True if re . search ( cashRegex , comment ): if any ( word in comment for word in monetWords ): redCount += 1 else : yellowCount += 1 susMention = True if susMention : susMentionCount += 1 if fullName in parentCommentDict [ 'commentText' ] . lower () or name in parentCommentDict [ 'commentText' ] . lower (): fullNameCount += 1 redCount += 1 susRatio = susMentionCount / len ( threadAnalysisList ) # Number of people, not replies allNameCount = nameCount + partialNameCount + fullNameCount if susRatio > 0.7 : if filtersDict [ 'filterMode' ] == \"SensitiveSmart\" : add_spam ( current , config , miscData , parentCommentDict , parentCommentDict [ 'videoID' ], matchReason = \"Spam Bot Thread\" ) return current elif len ( threadAnalysisList ) >= 10 : redCount += 2 else : redCount += 1 elif susRatio < 0.3 : return current # Score if redCount >= 1 and yellowCount >= 5 and ( susRatio > 0.75 or ( allNameCount >= 4 or fullNameCount >= 2 )): spam = True elif redCount > 2 and yellowCount >= 3 and ( susRatio > 0.70 or ( allNameCount >= 4 or fullNameCount >= 2 )): spam = True elif redCount >= 2 and ( allNameCount >= 5 or fullNameCount >= 3 ) and susRatio > 0.6 : spam = True elif redCount >= 5 and susRatio > 0.5 : spam = True elif yellowCount >= 10 and susRatio > 0.65 : spam = True if spam == True : add_spam ( current , config , miscData , parentCommentDict , parentCommentDict [ 'videoID' ], matchReason = \"Spam Bot Thread\" ) return current","title":"check_spam_threads()"},{"location":"reference/Scripts/operations/#Scripts.operations.delete_found_comments","text":"delete_found_comments ( commentsList , banChoice , deletionMode , recoveryMode = False , skipCheck = False ) Source code in Scripts/operations.py 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 def delete_found_comments ( commentsList , banChoice , deletionMode , recoveryMode = False , skipCheck = False ): print ( \" \\n \" ) if deletionMode == \"rejected\" : actionPresent = \"Deleting\" actionPast = \"Deleted\" elif deletionMode == \"heldForReview\" : actionPresent = \"Hiding\" actionPast = \"Hidden\" elif deletionMode == \"reportSpam\" : actionPresent = \"Reporting\" actionPast = \"Reported\" else : actionPresent = \"Processing\" actionPast = \"Processed\" failedComments = [] # Local Functions def setStatus ( commentIDs , failedComments ): #Does the actual deletion if deletionMode == \"reportSpam\" : result = auth . YOUTUBE . comments () . markAsSpam ( id = commentIDs ) . execute () if len ( result ) > 0 : print ( \" \\n Something may gone wrong when reporting the comments.\" ) failedComments += commentIDs elif deletionMode == \"heldForReview\" or deletionMode == \"rejected\" or deletionMode == \"published\" : try : response = auth . YOUTUBE . comments () . setModerationStatus ( id = commentIDs , moderationStatus = deletionMode , banAuthor = banChoice ) . execute () if len ( response ) > 0 : failedComments += commentIDs except HttpError : print ( \" \\n Something has gone wrong when removing some comments...\" ) failedComments += commentIDs else : print ( \"Invalid deletion mode. This is definitely a bug, please report it here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) print ( \"Deletion Mode Is: \" + deletionMode ) input ( \"Press Enter to Exit...\" ) sys . exit () return failedComments def print_progress ( d , t , recoveryMode = False ): if recoveryMode == False : print ( actionPresent + \" Comments... - Progress: [\" + str ( d ) + \" / \" + str ( t ) + \"] (In Groups of 50)\" , end = \" \\r \" ) elif recoveryMode == True : print ( \"Recovering Comments... - Progress: [\" + str ( d ) + \" / \" + str ( t ) + \"] (In Groups of 50)\" , end = \" \\r \" ) total = len ( commentsList ) deletedCounter = 0 print_progress ( deletedCounter , total , recoveryMode ) if total > 50 : # If more than 50 comments, break into chunks of 50 remainder = total % 50 # Gets how many left over after dividing into chunks of 50 numDivisions = int (( total - remainder ) / 50 ) # Gets how many full chunks of 50 there are for i in range ( numDivisions ): # Loops through each full chunk of 50 failedComments = setStatus ( commentsList [ i * 50 : i * 50 + 50 ], failedComments ) deletedCounter += 50 print_progress ( deletedCounter , total , recoveryMode ) if remainder > 0 : failedComments = setStatus ( commentsList [ numDivisions * 50 : total ], failedComments ) # Handles any leftover comments range after last full chunk deletedCounter += remainder print_progress ( deletedCounter , total , recoveryMode ) else : failedComments = setStatus ( commentsList , failedComments ) print_progress ( deletedCounter , total , recoveryMode ) if deletionMode == \"reportSpam\" : print ( f \" { F . YELLOW } Comments Reported! { S . R } If no error messages were displayed, then everything was successful.\" ) return failedComments elif recoveryMode == False and skipCheck == False : print ( \"Comments \" + actionPast + \"! Will now verify each is gone. \\n \" ) elif recoveryMode == False and skipCheck == True : print ( \"Comments \" + actionPast + \"! \\n \" ) elif recoveryMode == True : print ( \"Comments Recovered! Will now verify each is back. \\n \" ) return failedComments","title":"delete_found_comments()"},{"location":"reference/Scripts/operations/#Scripts.operations.exclude_authors","text":"exclude_authors ( current , config , miscData , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , displayString , inputtedString , logInfo = None , only = False ) Source code in Scripts/operations.py 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 def exclude_authors ( current , config , miscData , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , displayString , inputtedString , logInfo = None , only = False ): plaintextFormattedExcludes = \"\" rtfFormattedExcludes = \"\" valid = False while valid == False : if \"exclude\" in inputtedString . lower () or \"only\" in inputtedString . lower (): try : if \"exclude\" in inputtedString . lower (): # Account for if user is trying again isolateExpression = r \"(?<=exclude ).*\" # Matches everything after 'exclude' result = str ( re . search ( isolateExpression , inputtedString . lower ()) . group ( 0 )) elif \"only\" in inputtedString . lower (): isolateExpression = r \"(?<=only ).*\" # Matches everything after 'exclude' result = str ( re . search ( isolateExpression , inputtedString . lower ()) . group ( 0 )) # User didn't enter any numbers or they're not right except AttributeError : result = \"ThisStringCausesErrorNext\" else : #Take new input from further down result = inputtedString result = result . replace ( \" \" , \"\" ) validInputExpression = r '^[0-9,-]+$' # Ensures only digits, commas, and dashes are used if re . match ( validInputExpression , result ) == None : print ( f \" \\n { F . LIGHTRED_EX } Invalid input! { S . R } Must be a comma separated list of numbers and/or range of numbers. Please try again.\" ) if only == False : inputtedString = input ( \" \\n Enter the list of authors to exclude from deletion: \" ) elif only == True : inputtedString = input ( \" \\n Enter the list of only authors to delete: \" ) else : result = result . strip ( ',' ) # Remove leading/trailing comma result = utils . expand_ranges ( result ) # Expands ranges of numbers into a list of numbers chosenSampleIndexes = result . split ( \",\" ) valid = True for num in chosenSampleIndexes : # Check if any numbers outside max range if int ( num ) > len ( current . matchSamplesDict ) or int ( num ) < 1 : print ( f \" \\n { F . LIGHTRED_EX } Invalid input! { S . R } Number is outside the range of samples: { num } -- Please try again.\" ) valid = False break if valid == False : if only == False : inputtedString = input ( \" \\n Enter the comma separated list of numbers and/or ranges to exclude: \" ) elif only == True : inputtedString = input ( \" \\n Enter the comma separated list of numbers and/or ranges to delete: \" ) # Go through all the sample numbers, check if they are on the list given by user for authorID , info in current . matchSamplesDict . items (): if only == False : if str ( info [ 'index' ]) in chosenSampleIndexes : authorsToExcludeSet . add ( authorID ) elif only == True : if str ( info [ 'index' ]) not in chosenSampleIndexes : authorsToExcludeSet . add ( authorID ) # Get comment IDs to be excluded for comment , metadata in current . matchedCommentsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) for comment , metadata in current . duplicateCommentsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) for comment , metadata in current . otherCommentsByMatchedAuthorsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) for comment , metadata in current . spamThreadsDict . items (): if metadata [ 'authorID' ] in authorsToExcludeSet : commentIDExcludeSet . add ( comment ) # Remove all comments by selected authors from dictionary of comments for comment in commentIDExcludeSet : if comment in current . matchedCommentsDict . keys (): excludedCommentsDict [ comment ] = current . matchedCommentsDict . pop ( comment ) if comment in current . duplicateCommentsDict . keys (): excludedCommentsDict [ comment ] = current . duplicateCommentsDict . pop ( comment ) if comment in current . otherCommentsByMatchedAuthorsDict . keys (): excludedCommentsDict [ comment ] = current . otherCommentsByMatchedAuthorsDict . pop ( comment ) if comment in current . spamThreadsDict . keys (): excludedCommentsDict [ comment ] = current . spamThreadsDict . pop ( comment ) # Create strings that can be used in log files rtfFormattedExcludes += f \" \\\\ line \\n Comments Excluded From Deletion: \\\\ line \\n \" rtfFormattedExcludes += f \"(Values = Comment ID | Author ID | Author Name | Comment Text) \\\\ line \\n \" plaintextFormattedExcludes += f \" \\n Comments Excluded From Deletion: \\n \" plaintextFormattedExcludes += f \"(Values = Comment ID | Author ID | Author Name | Comment Text) \\n \" for commentID , meta in excludedCommentsDict . items (): sanitizedText = str ( excludedCommentsDict [ commentID ][ 'text' ]) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) rtfFormattedExcludes += f \" { str ( commentID ) } | { str ( excludedCommentsDict [ commentID ][ 'authorID' ]) } | { str ( excludedCommentsDict [ commentID ][ 'authorName' ]) } | { sanitizedText } \\\\ line \\n \" for commentID , meta in excludedCommentsDict . items (): sanitizedText = str ( excludedCommentsDict [ commentID ][ 'text' ]) . replace ( \" \\n \" , \" \" ) . replace ( \" \\r \" , \" \" ) plaintextFormattedExcludes += f \" { str ( commentID ) } | { str ( excludedCommentsDict [ commentID ][ 'authorID' ]) } | { str ( excludedCommentsDict [ commentID ][ 'authorName' ]) } | { sanitizedText } \\n \" # Verify removal for comment in current . matchedCommentsDict . keys (): if comment in commentIDExcludeSet : print ( f \" { F . LIGHTRED_EX } FATAL ERROR { S . R } : Something went wrong while trying to exclude comments. No comments have been deleted.\" ) print ( f \"You should { F . YELLOW } DEFINITELY { S . R } report this bug here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) print ( \"Provide the error code: X-1\" ) input ( \"Press Enter to Exit...\" ) sys . exit () # Get author names and IDs from dictionary, and display them for author in authorsToExcludeSet : displayString += f \" User ID: { author } | User Name: { current . matchSamplesDict [ author ][ 'authorName' ] } \\n \" print ( f \" \\n { F . CYAN } All { len ( excludedCommentsDict ) } comments { S . R } from the { F . CYAN } following users { S . R } are now { F . LIGHTGREEN_EX } excluded { S . R } from deletion:\" ) print ( displayString ) if config [ 'whitelist_excluded' ] == 'ask' : print ( f \" \\n Add these { F . LIGHTGREEN_EX } excluded { S . R } users to the { F . LIGHTGREEN_EX } whitelist { S . R } for future scans?\" ) addWhitelist = choice ( \"Whitelist Users?\" ) elif config [ 'whitelist_excluded' ] == True : addWhitelist = True elif config [ 'whitelist_excluded' ] == False : addWhitelist = False if addWhitelist == True : with open ( miscData . resources [ 'Whitelist' ][ 'PathWithName' ], \"a\" , encoding = \"utf-8\" ) as f : for author in authorsToExcludeSet : f . write ( f \"# [Excluded] Channel Name: { current . matchSamplesDict [ author ][ 'authorName' ] } | Channel ID: \" + \" \\n \" ) f . write ( f \" { author } \\n \" ) input ( \" \\n Press Enter to decide what to do with the rest...\" ) return current , excludedCommentsDict , authorsToExcludeSet , commentIDExcludeSet , rtfFormattedExcludes , plaintextFormattedExcludes # May use excludedCommentsDict later for printing them to log file","title":"exclude_authors()"},{"location":"reference/Scripts/operations/#Scripts.operations.get_all_author_comments","text":"get_all_author_comments ( current , config , miscData , allCommentsDict ) Source code in Scripts/operations.py 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_all_author_comments ( current , config , miscData , allCommentsDict ): # Make set of all matched author IDs print ( \" Finding all other comments by authors...\" , end = \" \\r \" ) totalCommentsAmount = len ( allCommentsDict ) scannedCount = 0 matchedAuthorIDSet = set () for _ , commentData in current . matchedCommentsDict . items (): matchedAuthorIDSet . add ( commentData [ 'authorID' ]) # Go through all comments for authorID , authorCommentsListofDicts in allCommentsDict . items (): if authorID in matchedAuthorIDSet : for commentDict in authorCommentsListofDicts : scannedCount += 1 print ( f \" Finding all other comments by authors: [ { scannedCount / totalCommentsAmount * 100 : .2f } % ]\" . ljust ( 40 , \" \" ), end = \" \\r \" ) if commentDict [ 'commentID' ] not in current . matchedCommentsDict : add_spam ( current , config , miscData , commentDict , commentDict [ 'videoID' ], matchReason = \"Also By Matched Author\" ) print ( \"\" . ljust ( 55 , \" \" )) return current","title":"get_all_author_comments()"},{"location":"reference/Scripts/operations/#Scripts.operations.get_comments","text":"get_comments ( current , filtersDict , miscData , config , allVideoCommentsDict , scanVideoID = None , nextPageToken = None , videosToScan = None ) Source code in Scripts/operations.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def get_comments ( current , filtersDict , miscData , config , allVideoCommentsDict , scanVideoID = None , nextPageToken = None , videosToScan = None ): # None are set as default if no parameters passed into function # Initialize some variables authorChannelName = None commentText = None parentAuthorChannelID = None fieldsToFetch = \"nextPageToken,items/snippet/topLevelComment/id,items/replies/comments,items/snippet/totalReplyCount,items/snippet/topLevelComment/snippet/videoId,items/snippet/topLevelComment/snippet/authorChannelId/value,items/snippet/topLevelComment/snippet/authorDisplayName,items/snippet/topLevelComment/snippet/textDisplay\" try : # Gets all comment threads for a specific video if scanVideoID is not None : results = auth . YOUTUBE . commentThreads () . list ( part = \"snippet, replies\" , videoId = scanVideoID , maxResults = 100 , pageToken = nextPageToken , fields = fieldsToFetch , textFormat = \"plainText\" ) . execute () # Get all comment threads across the whole channel elif scanVideoID is None : results = auth . YOUTUBE . commentThreads () . list ( part = \"snippet, replies\" , allThreadsRelatedToChannelId = auth . CURRENTUSER . id , maxResults = 100 , pageToken = nextPageToken , fields = fieldsToFetch , textFormat = \"plainText\" ) . execute () except HttpError as hx : traceback . print_exc () utils . print_http_error_during_scan ( hx ) current . errorOccurred = True return \"Error\" , None except Exception as ex : traceback . print_exc () utils . print_exception_during_scan ( ex ) current . errorOccurred = True return \"Error\" , None # Get token for next page. If no token, sets to 'End' RetrievedNextPageToken = results . get ( \"nextPageToken\" , \"End\" ) # After getting all comments threads for page, extracts data for each and stores matches in current.matchedCommentsDict # Also goes through each thread and executes get_replies() to get reply content and matches for item in results [ \"items\" ]: comment = item [ \"snippet\" ][ \"topLevelComment\" ] videoID = comment [ \"snippet\" ][ \"videoId\" ] parent_id = item [ \"snippet\" ][ \"topLevelComment\" ][ \"id\" ] numReplies = item [ \"snippet\" ][ \"totalReplyCount\" ] # On rare occasions a comment will be there but the channel name will be empty, so this allows placeholders try : limitedRepliesList = item [ \"replies\" ][ \"comments\" ] # API will return a limited number of replies (~5), but to get all, need to make separate call except KeyError : limitedRepliesList = [] pass try : parentAuthorChannelID = comment [ \"snippet\" ][ \"authorChannelId\" ][ \"value\" ] except KeyError : parentAuthorChannelID = \"[Deleted Channel]\" # Need to be able to catch exceptions because sometimes the API will return a comment from non-existent / deleted channel try : authorChannelName = comment [ \"snippet\" ][ \"authorDisplayName\" ] except KeyError : authorChannelName = \"[Deleted Channel]\" try : commentText = comment [ \"snippet\" ][ \"textDisplay\" ] # Remove Return carriages except KeyError : commentText = \"[Deleted/Missing Comment]\" # Runs check against comment info for whichever filter data is relevant currentCommentDict = { 'authorChannelID' : parentAuthorChannelID , 'parentAuthorChannelID' : None , 'authorChannelName' : authorChannelName , 'commentText' : commentText , 'commentID' : parent_id , 'videoID' : videoID , } check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID ) current . scannedCommentsCount += 1 #Log All Comments try : allVideoCommentsDict [ parentAuthorChannelID ] . append ( currentCommentDict ) except KeyError : allVideoCommentsDict [ parentAuthorChannelID ] = [ currentCommentDict ] except TypeError : pass # If there are more replies than in the limited list if numReplies > 0 and len ( limitedRepliesList ) < numReplies : if numReplies > 7 and ( filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"SensitiveSmart\" ) and config [ 'detect_spam_threads' ] == True : parentCommentDict = currentCommentDict else : parentCommentDict = None allVideoCommentsDict = get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , parentCommentDict = parentCommentDict ) if allVideoCommentsDict == \"Error\" : return \"Error\" , None # If all the replies are in the limited list elif numReplies > 0 and len ( limitedRepliesList ) == numReplies : # limitedRepliesList can never be more than numReplies allVideoCommentsDict = get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , repliesList = limitedRepliesList ) if allVideoCommentsDict == \"Error\" : return \"Error\" , None else : print_count_stats ( current , miscData , videosToScan , final = False ) # Updates displayed stats if no replies # Runs after all comments scanned if RetrievedNextPageToken == \"End\" and allVideoCommentsDict : dupeCheckModes = utils . string_to_list ( config [ 'duplicate_check_modes' ]) if filtersDict [ 'filterMode' ] . lower () in dupeCheckModes : print ( \" Analyzing For Duplicates \" , end = \" \\r \" ) check_duplicates ( current , config , miscData , allVideoCommentsDict , videoID ) current . allScannedCommentsDict . update ( allVideoCommentsDict ) return RetrievedNextPageToken , allVideoCommentsDict","title":"get_comments()"},{"location":"reference/Scripts/operations/#Scripts.operations.get_recent_videos","text":"get_recent_videos ( channel_id , numVideosTotal ) Source code in Scripts/operations.py 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 def get_recent_videos ( channel_id , numVideosTotal ): def get_block_of_videos ( nextPageToken , j , k , numVideosBlock = 5 ): result = auth . YOUTUBE . search () . list ( part = \"snippet\" , channelId = channel_id , type = 'video' , order = 'date' , pageToken = nextPageToken , #fields='nextPageToken,items/id/videoId,items/snippet/title', maxResults = numVideosBlock , ) . execute () for item in result [ 'items' ]: videoID = str ( item [ 'id' ][ 'videoId' ]) videoTitle = str ( item [ 'snippet' ][ 'title' ]) . replace ( \"&quot;\" , \" \\\" \" ) . replace ( \"&#39;\" , \"'\" ) commentCount = validation . validate_video_id ( videoID , pass_exception = True )[ 3 ] #Skips over video if comment count is zero, or comments disabled / is live stream if str ( commentCount ) == '0' : print ( f \" { B . YELLOW }{ F . BLACK } Skipping { S . R } { F . LIGHTRED_EX } Video with no comments: { S . R } \" + str ( item [ 'snippet' ][ 'title' ])) k += 1 continue recentVideos . append ({}) recentVideos [ j ][ 'videoID' ] = videoID recentVideos [ j ][ 'videoTitle' ] = videoTitle if str ( commentCount ) == \"MainMenu\" : return None , None , \"MainMenu\" recentVideos [ j ][ 'commentCount' ] = commentCount j += 1 k += 1 # Get token for next page try : nextPageToken = result [ 'nextPageToken' ] except KeyError : nextPageToken = \"End\" # 0 1 2 3 return nextPageToken , j , k , \"\" #---------------------------------------------------------------- nextPageToken = None recentVideos = [] #List of dictionaries abortCheck = \"\" # Used to receive \"MainMenu\" if user wants to exit, when entering j , k = 0 , 0 # i = number of videos added to list, k = number of videos checked (different only if one video skipped because no comments) if numVideosTotal <= 5 : result = get_block_of_videos ( None , j , k , numVideosBlock = numVideosTotal ) if result [ 3 ] == \"MainMenu\" : return \"MainMenu\" else : while nextPageToken != \"End\" and k < numVideosTotal and str ( abortCheck ) != \"MainMenu\" : print ( \"Retrieved \" + str ( len ( recentVideos )) + \"/\" + str ( numVideosTotal ) + \" videos.\" , end = \" \\r \" ) remainingVideos = numVideosTotal - k if remainingVideos <= 5 : nextPageToken , j , k , abortCheck = get_block_of_videos ( nextPageToken , j , k , numVideosBlock = remainingVideos ) else : nextPageToken , j , k , abortCheck = get_block_of_videos ( nextPageToken , j , k , numVideosBlock = 5 ) if str ( nextPageToken [ 0 ]) == \"MainMenu\" : return \"MainMenu\" print ( \" \" ) return recentVideos","title":"get_recent_videos()"},{"location":"reference/Scripts/operations/#Scripts.operations.get_replies","text":"get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , parentCommentDict = None , repliesList = None ) Source code in Scripts/operations.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 def get_replies ( current , filtersDict , miscData , config , parent_id , videoID , parentAuthorChannelID , videosToScan , allVideoCommentsDict , parentCommentDict = None , repliesList = None ): # Initialize some variables authorChannelName = None commentText = None threadDict = {} if repliesList == None : fieldsToFetch = \"nextPageToken,items/snippet/authorChannelId/value,items/id,items/snippet/authorDisplayName,items/snippet/textDisplay\" replies = [] replyPageToken = None while replyPageToken != \"End\" : try : results = auth . YOUTUBE . comments () . list ( part = \"snippet\" , parentId = parent_id , pageToken = replyPageToken , maxResults = 100 , fields = fieldsToFetch , textFormat = \"plainText\" ) . execute () except HttpError as hx : traceback . print_exc () utils . print_http_error_during_scan ( hx ) current . errorOccurred = True return \"Error\" except Exception as ex : traceback . print_exc () utils . print_exception_during_scan ( ex ) current . errorOccurred = True return \"Error\" replies . extend ( results [ \"items\" ]) # Get token for next page try : replyPageToken = results [ 'nextPageToken' ] except KeyError : replyPageToken = \"End\" else : replies = repliesList # Create list of author names in current thread, add into list - Only necessary when scanning comment text allThreadAuthorNames = [] # Iterates through items in results # Need to be able to catch exceptions because sometimes the API will return a comment from non-existent / deleted channel # Need individual tries because not all are fetched for each mode for reply in replies : replyID = reply [ \"id\" ] try : authorChannelID = reply [ \"snippet\" ][ \"authorChannelId\" ][ \"value\" ] except KeyError : authorChannelID = \"[Deleted Channel]\" # Get author display name try : authorChannelName = reply [ \"snippet\" ][ \"authorDisplayName\" ] if filtersDict [ 'filterMode' ] == \"Username\" or filtersDict [ 'filterMode' ] == \"AutoASCII\" or filtersDict [ 'filterMode' ] == \"AutoSmart\" or filtersDict [ 'filterMode' ] == \"NameAndText\" : allThreadAuthorNames . append ( authorChannelName ) except KeyError : authorChannelName = \"[Deleted Channel]\" # Comment Text try : commentText = reply [ \"snippet\" ][ \"textDisplay\" ] # Remove Return carriages except KeyError : commentText = \"[Deleted/Missing Comment]\" # Runs check against comment info for whichever filter data is relevant currentCommentDict = { 'authorChannelID' : authorChannelID , 'parentAuthorChannelID' : parentAuthorChannelID , 'authorChannelName' : authorChannelName , 'commentText' : commentText , 'commentID' : replyID , 'videoID' : videoID } if parentCommentDict : threadDict [ replyID ] = currentCommentDict check_against_filter ( current , filtersDict , miscData , config , currentCommentDict , videoID , allThreadAuthorNames = allThreadAuthorNames ) #Log All Comments try : allVideoCommentsDict [ authorChannelID ] . append ( currentCommentDict ) except KeyError : allVideoCommentsDict [ authorChannelID ] = [ currentCommentDict ] except TypeError : pass # Update latest stats current . scannedRepliesCount += 1 print_count_stats ( current , miscData , videosToScan , final = False ) if parentCommentDict : current = check_spam_threads ( current , filtersDict , miscData , config , parentCommentDict , threadDict ) return allVideoCommentsDict","title":"get_replies()"},{"location":"reference/Scripts/operations/#Scripts.operations.make_community_thread_dict","text":"make_community_thread_dict ( commentID , allCommunityCommentsDict ) Source code in Scripts/operations.py 453 454 455 456 457 458 459 460 def make_community_thread_dict ( commentID , allCommunityCommentsDict ): threadDict = {} if \".\" not in commentID : # Checks if is top level comment or reply for id in allCommunityCommentsDict . keys (): if commentID in id and commentID != id : threadDict [ id ] = allCommunityCommentsDict [ id ] return threadDict","title":"make_community_thread_dict()"},{"location":"reference/Scripts/operations/#Scripts.operations.print_count_stats","text":"print_count_stats ( current , miscData , videosToScan , final ) Source code in Scripts/operations.py 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 def print_count_stats ( current , miscData , videosToScan , final ): # Use videosToScan (list of dictionaries) to retrieve total number of comments if videosToScan and miscData . totalCommentCount > 0 : totalComments = miscData . totalCommentCount totalScanned = current . scannedRepliesCount + current . scannedCommentsCount percent = (( totalScanned / totalComments ) * 100 ) progress = f \"Total: [ { str ( totalScanned ) } / { str ( totalComments ) } ] ( { percent : .0f } %) \" . ljust ( 27 , \" \" ) + \"|\" #Formats percentage to 0 decimal places else : progress = \"\" comScanned = str ( current . scannedCommentsCount ) repScanned = str ( current . scannedRepliesCount ) matchCount = str ( len ( current . matchedCommentsDict ) + len ( current . spamThreadsDict )) if final == True : print ( f \" { progress } Comments Scanned: { F . YELLOW }{ comScanned }{ S . R } | Replies Scanned: { F . YELLOW }{ repScanned }{ S . R } | Matches Found So Far: { F . LIGHTRED_EX }{ matchCount }{ S . R } \\n \" ) else : print ( f \" { progress } Comments Scanned: { F . YELLOW }{ comScanned }{ S . R } | Replies Scanned: { F . YELLOW }{ repScanned }{ S . R } | Matches Found So Far: { F . LIGHTRED_EX }{ matchCount }{ S . R } \" , end = \" \\r \" ) return None","title":"print_count_stats()"},{"location":"reference/Scripts/prepare_modes/","text":"delete_comment_list \u00b6 delete_comment_list ( config ) Source code in Scripts/prepare_modes.py 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 def delete_comment_list ( config ): progressFileFolder = os . path . join ( RESOURCES_FOLDER_NAME , \"Removal_List_Progress\" ) print ( f \" \\n\\n -------------------- { F . LIGHTRED_EX } Delete Using a List / Log { S . R } --------------------\" ) while True : print ( \" \\n Use new comment list, or continue where you left off with another list?\" ) print ( f \" 1. Use { F . LIGHTCYAN_EX } New List { S . R } \" ) print ( f \" 2. { F . LIGHTMAGENTA_EX } Continue With { S . R } a List\" ) listChoice = input ( \" \\n Selection (1 or 2): \" ) if listChoice == \"1\" or listChoice == \"2\" : break else : print ( f \" \\n { F . LIGHTRED_EX } Invalid selection! { S . R } Please try again.\" ) if listChoice == \"1\" : continued = False previousRemovedComments = set () remainingCommentsSet = set () previousFailedComments = list () sessionNum = 1 removalList , listFileNameBase = files . parse_comment_list ( config , removal = True , returnFileName = True ) if removalList == \"MainMenu\" : return \"MainMenu\" progressFileName = listFileNameBase + \"_removal_progress.save\" if listChoice == \"2\" : continued = True valid = False # Use existing save if available existingSavesList = files . check_existing_save () if len ( existingSavesList ) > 0 : if len ( existingSavesList ) == 1 : saveChoice = existingSavesList [ 0 ] print ( f \" \\n { F . LIGHTGREEN_EX } Using existing save: { S . R }{ saveChoice } \" ) elif len ( existingSavesList ) > 1 : print ( \" \\n Which save file would you like to use?\" ) for i , save in enumerate ( existingSavesList ): print ( f \" { i + 1 } . { save [: - 22 ] } \" ) # Take and Validate Input while valid == False : saveChoice = input ( f \" \\n Selection (1- { len ( existingSavesList ) } ): \" ) if saveChoice . isdigit () and int ( saveChoice ) > 0 and int ( saveChoice ) <= len ( existingSavesList ): saveChoice = existingSavesList [ int ( saveChoice ) - 1 ] valid = True elif saveChoice . lower () == \"x\" : return \"MainMenu\" else : print ( f \" \\n { F . RED } Invalid Selectionp { S . R } . Please try again.\" ) progressFileName = saveChoice progressFileNameWithPath = os . path . join ( progressFileFolder , progressFileName ) progressDict = files . read_dict_pickle_file ( progressFileName , progressFileFolder ) valid = True removalList = \"Loaded\" else : print ( f \" \\n { F . RED } No previous saves found! { S . R } \" ) input ( \" \\n Press Enter to return to Main Menu...\" ) return \"MainMenu\" while valid == False : input ( F \" \\n Next, follow the process by loading { F . YELLOW } the same comment list/log you used before { S . R } . Press Enter to continue...\" ) removalList , listFileNameBase = files . parse_comment_list ( config , removal = True , returnFileName = True ) if removalList == \"MainMenu\" : return \"MainMenu\" # Read pickle into dictionary of deleted and non-deleted files from last time print ( \" \\n Checking for saved progress file...\" ) progressFileName = listFileNameBase + \"_removal_progress.save\" progressFileNameWithPath = os . path . join ( progressFileFolder , progressFileName ) if os . path . isfile ( progressFileNameWithPath ): progressDict = files . read_dict_pickle_file ( progressFileName , progressFileFolder ) valid = True else : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } No progress file found for that log file. Try again.\" ) # Get data from list lastSessionNum = int ( len ( progressDict )) previousRemovedComments = set ( progressDict [ lastSessionNum ][ 'removed' ]) remainingCommentsSet = set ( progressDict [ lastSessionNum ][ 'notRemoved' ]) previousFailedComments = progressDict [ lastSessionNum ][ 'failedCommentsList' ] sessionNum = int ( len ( progressDict )) + 1 if removalList == \"Loaded\" or ( len ( remainingCommentsSet ) + len ( previousRemovedComments ) + len ( previousFailedComments )) == len ( removalList ): pass else : print ( f \" { F . LIGHTRED_EX } Error: { S . R } The length of the comment list you loaded doesn't match the comment list you saved last time.\" ) if choice ( f \" { F . YELLOW } Continue anyway? { S . R } (Will use previous save and ignore the file you just loaded)\" ) != True : return \"MainMenu\" # Display status of loaded file prevRemovedNum = len ( previousRemovedComments ) prevNotRemovedNum = len ( remainingCommentsSet ) prevFailedNum = len ( previousFailedComments ) print ( f \" \\n { F . LIGHTCYAN_EX } ----------------------- Loaded Saved Comment List Status ----------------------- { S . R } \" ) print ( f \" { F . LIGHTGREEN_EX }{ prevRemovedNum } removed { S . R } | { F . YELLOW }{ prevNotRemovedNum } not removed yet { S . R } | { F . LIGHTRED_EX }{ prevFailedNum } failed to be removed { S . R } \" ) input ( \" \\n Press Enter to continue...\" ) # Set removal list based on previous save removalList = list ( remainingCommentsSet ) if len ( previousFailedComments ) > 0 : print ( f \" { F . LIGHTRED_EX } NOTE: { S . R } During previous sessions, { F . LIGHTRED_EX }{ len ( previousFailedComments ) } comments { S . R } failed to be deleted.\" ) failChoice = choice ( f \" \\n { F . YELLOW } Add these back into the list { S . R } to try again? (Otherwise will skip them for later) \" ) if failChoice == True : removalList = removalList + list ( previousFailedComments ) previousFailedComments = list () else : removalList = list ( remainingCommentsSet ) print ( f \" \\n Loaded { F . YELLOW }{ len ( removalList ) } Remaining Comments { S . R } \" ) # --- Begin removal process using list ------ print ( \" \\n What do you want to do with the comments in the list?\" ) print ( f \"1. { F . LIGHTRED_EX } Delete { S . R } them\" ) print ( f \"2. { F . LIGHTMAGENTA_EX } Hide { S . R } them for review\" ) validInput = False while validInput == False : userChoice = input ( \" \\n Selection (1 or 2): \" ) if userChoice == \"1\" : removalMode = \"rejected\" validInput = True elif userChoice == \"2\" : removalMode = \"heldForReview\" validInput = True banChoice = False elif userChoice == \"99\" : # For Testing removalMode = \"reportSpam\" banChoice = False validInput = True elif userChoice . lower () == \"x\" : return \"MainMenu\" else : print ( f \" { F . RED } Invalid input, try again. { S . R } \" ) if removalMode == \"rejected\" : banChoice = choice ( F \"Also { F . RED } ban { S . R } the commenters?\" ) if str ( banChoice ) . lower () == \"x\" : return \"MainMenu\" # Set limit based on quota quotaLimit = int ( config [ 'quota_limit' ]) - 100 validInput = False while validInput == False : print ( f \" \\n { F . YELLOW } How many comments { S . R } (out of { len ( removalList ) } ) do you want to remove this session? (Input '0' or 'all' to do them all)\" ) countChoice = input ( f \" \\n Number of comments (1- { str ( quotaLimit ) } ): \" ) if countChoice . lower () == \"all\" or countChoice == \"0\" : countChoice = len ( removalList ) try : countChoice = int ( countChoice ) if countChoice > 0 and countChoice <= quotaLimit : validInput = True elif countChoice >= quotaLimit : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } { countChoice } is too many comments, you'll run out of API Quota. Read Here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) else : print ( f \"Invalid input, must be 'all' or a whole number from 1 to { str ( quotaLimit ) } .\" ) except : print ( f \" { F . RED } Invalid input, must be a whole number. { S . R } Try again.\" ) # Extract selected amount of comment IDs from list if countChoice >= len ( removalList ): partial = False else : partial = True if partial == True : selectedRemovalList = removalList [: countChoice ] notRemovedList = removalList [ countChoice :] else : selectedRemovalList = removalList notRemovedList = list () input ( f \" \\n Press { F . YELLOW } Enter { S . R } to Begin Removal...\" ) failedCommentsList = operations . delete_found_comments ( commentsList = selectedRemovalList , banChoice = banChoice , deletionMode = removalMode ) ### Handle Results ### if len ( failedCommentsList ) > 0 : print ( f \" \\n { F . LIGHTRED_EX } Warning! { S . R } { len ( failedCommentsList ) } comments apparently failed to be removed. They'll be saved to be tried later.\" ) input ( \" \\n Press Enter to continue...\" ) failedCommentsSet = set ( failedCommentsList ) else : failedCommentsSet = set () selectedRemovalSet = set ( selectedRemovalList ) remainingCommentsSet = set ( notRemovedList ) # Calculating final results for save progress file if len ( failedCommentsSet ) > 0 : partial = True finalRemovedSet = selectedRemovalSet - failedCommentsSet else : finalRemovedSet = selectedRemovalSet if partial == True or continued == True : print ( \" \\n Saving progress...\" ) # Initialize progress dictionary if continued == True : progressDict [ sessionNum ] = { 'removed' : previousRemovedComments . union ( finalRemovedSet ), 'notRemoved' : remainingCommentsSet , 'failedCommentsList' : failedCommentsList + previousFailedComments } else : progressDict = dict () progressDict [ sessionNum ] = { 'removed' : finalRemovedSet , 'notRemoved' : remainingCommentsSet , 'failedCommentsList' : failedCommentsList + previousFailedComments } if len ( progressDict [ sessionNum ][ 'notRemoved' ]) == 0 and len ( progressDict [ sessionNum ][ 'failedCommentsList' ]) == 0 : if continued == True : print ( f \" \\n { F . LIGHTGREEN_EX } Success! { S . R } All comments should be removed. { F . YELLOW } Will now remove { S . R } finished progress file. (Log file will remain)\" ) files . try_remove_file ( progressFileNameWithPath ) else : print ( f \" \\n { F . LIGHTGREEN_EX } Success! { S . R } All comments should be removed.\" ) else : #progressFileName = listFileNameBase + \"_removal_progress.save\" result = files . write_dict_pickle_file ( progressDict , progressFileName , progressFileFolder , forceOverwrite = True ) if result == True : print ( f \"Progress file saved.\" ) removed = len ( progressDict [ sessionNum ][ 'removed' ]) notRemoved = len ( progressDict [ sessionNum ][ 'notRemoved' ]) failed = len ( progressDict [ sessionNum ][ 'failedCommentsList' ]) print ( f \" \\n { F . LIGHTCYAN_EX } ----------------------- Comment List Status ----------------------- { S . R } \" ) print ( f \" { F . LIGHTGREEN_EX }{ removed } removed { S . R } | { F . YELLOW }{ notRemoved } not removed yet { S . R } | { F . LIGHTRED_EX }{ failed } failed to be removed { S . R } \" ) print ( f \" \\n You will be able to { F . YELLOW } continue later { S . R } using the { F . YELLOW } same log file { S . R } .\" ) input ( f \" \\n Press { F . YELLOW } Enter { S . R } to return to Main Menu...\" ) return \"MainMenu\" prepare_filter_mode_ID \u00b6 prepare_filter_mode_ID ( scanMode , config ) Source code in Scripts/prepare_modes.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def prepare_filter_mode_ID ( scanMode , config ): processResult = ( False , None ) #Tuple, first element is status of validity of channel ID, second element is channel ID validConfigSetting = True while processResult [ 0 ] == False : if validConfigSetting == True and config and config [ 'channel_ids_to_filter' ] != \"ask\" : inputtedSpammerChannelID = config [ 'channel_ids_to_filter' ] bypass = True else : bypass = False inputtedSpammerChannelID = input ( f \"Enter the { F . LIGHTRED_EX } Channel link(s) or ID(s) { S . R } of the spammer (comma separated): \" ) if str ( inputtedSpammerChannelID ) . lower () == \"x\" : return \"MainMenu\" , None processResult = utils . process_spammer_ids ( inputtedSpammerChannelID ) if processResult [ 0 ] == True : inputtedSpammerChannelID = processResult [ 1 ] # After processing, if valid, inputtedSpammerChannelID is a list of channel IDs else : validConfigSetting = False print ( \" \\n \" ) # Check if spammer ID and user's channel ID are the same, and warn # If using channel-wide scanning mode, program will just ignore those comments if any ( auth . CURRENTUSER . id == i for i in inputtedSpammerChannelID ): print ( f \" { B . RED }{ F . WHITE } WARNING: { S . R } - You entered your own channel ID!\" ) print ( f \"For safety purposes, this program always { F . YELLOW } ignores { S . R } your own comments.\" ) if config [ 'channel_ids_to_filter' ] != \"ask\" : pass else : input ( \" \\n Press Enter to continue...\" ) return inputtedSpammerChannelID , None prepare_filter_mode_chars \u00b6 prepare_filter_mode_chars ( scanMode , filterMode , config ) Source code in Scripts/prepare_modes.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def prepare_filter_mode_chars ( scanMode , filterMode , config ): if filterMode == \"Username\" : whatToScanMsg = \"Usernames\" elif filterMode == \"Text\" : whatToScanMsg = \"Comment Text\" elif filterMode == \"NameAndText\" : whatToScanMsg = \"Usernames and Comment Text\" if config [ 'characters_to_filter' ] != \"ask\" : print ( \"Characters to filter obtained from config file.\" ) pass else : print ( f \" \\n Next, you will input { F . YELLOW } ONLY { S . R } any special characters / emojis you want to search for in all { whatToScanMsg } . Do not include commas or spaces!\" ) print ( \" Note: Letters, numbers, and basic punctuation will not be included for safety purposes, even if you enter them.\" ) print ( \" Example: \ud83d\udc4b\ud83d\udd25\u2714\ufe0f\u2728\" ) input ( f \" \\n Press { F . LIGHTGREEN_EX } Enter { S . R } to open the { F . LIGHTGREEN_EX } text entry window { S . R } ...\" ) print ( \"-------------------------------------------\" ) confirm = False validConfigSetting = True while confirm == False : if validConfigSetting == True and config and config [ 'characters_to_filter' ] != \"ask\" : inputChars = make_char_set ( config [ 'characters_to_filter' ], stripLettersNumbers = True , stripKeyboardSpecialChars = False , stripPunctuation = True ) bypass = True else : bypass = False print ( f \" \\n Waiting for input Window. Press { F . MAGENTA } 'Execute' { S . R } after entering valid characters to continue...\" , end = \" \\r \" ) try : # Takes in user input of characters, returns 'set' of characters stripped of specified characters inputChars = take_input_gui ( mode = \"chars\" , stripLettersNumbers = True , stripKeyboardSpecialChars = False , stripPunctuation = True ) except NameError : # Catch if user closes GUI window, exit program. print ( \" \" ) # Clears the line because of \\r on previous print print ( \" \\n Error Code G-1: Something went wrong with the input, or you closed the window improperly.\" ) print ( \"If this keeps happening inexplicably, consider filing a bug report here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press Enter to exit...\" ) sys . exit () print ( f \" { whatToScanMsg } will be scanned for { F . MAGENTA } ANY { S . R } of the characters you entered in the previous window.\" ) userChoice = choice ( \"Begin Scanning? \" , bypass ) if userChoice == True : confirm = True elif userChoice == False : confirm = False validConfigSetting = False elif userChoice == None : return \"MainMenu\" , None return inputChars , None prepare_filter_mode_non_ascii \u00b6 prepare_filter_mode_non_ascii ( scanMode , config ) Source code in Scripts/prepare_modes.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 def prepare_filter_mode_non_ascii ( scanMode , config ): print ( \" \\n -------------------------------------------------- ASCII Mode--------------------------------------------------\" ) print ( \"~~~ This mode automatically searches for usernames that contain special characters (aka not letters/numbers) ~~~ \\n \" ) print ( \"Choose the sensitivity level of the filter. You will be shown examples after you choose.\" ) print ( f \" 1. Allow { F . LIGHTMAGENTA_EX } Standard + Extended ASCII { S . R } : Filter rare unicode & Emojis only\" ) print ( f \" 2. Allow { F . LIGHTMAGENTA_EX } Standard ASCII only { S . R } : Also filter semi-common foreign characters\" ) print ( f \" 3. { F . LIGHTRED_EX } NUKE Mode (\u2518\u00b0\u25a1\u00b0)\u2518\u2248 \u2534\u2500\u2500\u2534 : Allow ONLY numbers, letters, and spaces { S . R } \" ) print ( \"\" ) # Get user input for mode selection, confirmation = False validConfigSetting = True while confirmation == False : if validConfigSetting == True and config and config [ 'autoascii_sensitivity' ] != \"ask\" : selection = config [ 'autoascii_sensitivity' ] bypass = True else : bypass = False selection = input ( \"Choose Mode: \" ) if str ( selection ) . lower () == \"x\" : return \"MainMenu\" , None if selection == \"1\" : print ( f \"Searches for { F . YELLOW } usernames with emojis, unicode symbols, and rare foreign characters { S . R } such as: \u2714\ufe0f \u261d\ufe0f \ud83e\udc46 \u25b2 \u03c0 \u019d \u0152\" ) userChoice = choice ( \"Choose this mode?\" , bypass ) if userChoice == True : regexPattern = r \"[^\\x00-\\xFF]\" confirmation = True elif userChoice == None : return \"MainMenu\" , None elif selection == \"2\" : print ( f \"Searches for { F . YELLOW } usernames with anything EXCEPT { S . R } the following: { F . YELLOW } Letters, numbers, punctuation, and common special characters { S . R } you can type with your keyboard like: % * & () + \" ) userChoice = choice ( \"Choose this mode?\" , bypass ) if userChoice == True : regexPattern = r \"[^\\x00-\\x7F]\" confirmation = True elif userChoice == None : return \"MainMenu\" , None elif selection == \"3\" : print ( f \"Searches for { F . YELLOW } usernames with anything EXCEPT letters, numbers, and spaces { S . R } - { B . RED }{ F . WHITE } EXTREMELY LIKELY to cause collateral damage! { S . R } Recommended to just use to manually gather list of spammer IDs, then use a different mode to delete.\" ) userChoice = choice ( \"Choose this mode?\" , bypass ) if userChoice == True : regexPattern = r \"[^a-zA-Z0-9 ]\" confirmation = True elif userChoice == None : return \"MainMenu\" , None else : print ( f \"Invalid input: { selection } - Must be 1, 2, or 3.\" ) validConfigSetting = False if selection == \"1\" : autoModeName = \"Allow Standard + Extended ASCII\" elif selection == \"2\" : autoModeName = \"Allow Standard ASCII only\" elif selection == \"3\" : autoModeName = \"NUKE Mode (\u2518\u00b0\u25a1\u00b0)\u2518\u2248 \u2534\u2500\u2500\u2534 - Allow only letters, numbers, and spaces\" if confirmation == True : return regexPattern , autoModeName else : input ( \"How did you get here? Something very strange went wrong. Press Enter to Exit...\" ) sys . exit () prepare_filter_mode_regex \u00b6 prepare_filter_mode_regex ( scanMode , filterMode , config ) Source code in Scripts/prepare_modes.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def prepare_filter_mode_regex ( scanMode , filterMode , config ): if filterMode == \"Username\" : whatToScanMsg = \"Usernames\" elif filterMode == \"Text\" : whatToScanMsg = \"Comment Text\" elif filterMode == \"NameAndText\" : whatToScanMsg = \"Usernames and Comment Text\" if config [ 'regex_to_filter' ] != \"ask\" : print ( \"Regex expression obtained from config file.\" ) validConfigSetting = True else : print ( f \"Enter any { F . YELLOW } regex expression { S . R } to search within { whatToScanMsg } .\" ) print ( r \" Example Input: [^\\x00-\\xFF]\" ) validConfigSetting = False validExpression = False while validExpression == False : if validConfigSetting == True and config and config [ 'regex_to_filter' ] != \"ask\" : inputtedExpression = config [ 'regex_to_filter' ] bypass = True else : inputtedExpression = input ( \"Input Expression Here: \" ) if str ( inputtedExpression ) . lower () == \"x\" : return \"MainMenu\" , None bypass = False validationResults = validation . validate_regex ( inputtedExpression ) # Returns tuple of valid, and processed expression validExpression = validationResults [ 0 ] if validExpression == True : processedExpression = validationResults [ 1 ] print ( f \" The expression appears to be { F . GREEN } valid { S . R } !\" ) if validExpression == True : userChoice = choice ( \"Begin scanning? \" , bypass ) if userChoice == True : pass elif userChoice == False : validExpression = False validConfigSetting = False elif userChoice == None : return \"MainMenu\" , None else : print ( f \" { F . RED } Error { S . R } : The expression appears to be { F . RED } invalid { S . R } !\" ) validConfigSetting = False return processedExpression , None prepare_filter_mode_smart \u00b6 prepare_filter_mode_smart ( scanMode , config , miscData , sensitive = False ) Source code in Scripts/prepare_modes.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 def prepare_filter_mode_smart ( scanMode , config , miscData , sensitive = False ): rootDomainList = miscData . rootDomainsList spamDomainsList = miscData . spamLists [ 'spamDomainsList' ] # List of domains from crowd sourced list #spamThreadsList = miscData.spamLists['spamThreadsList'] # List of filters associated with spam threads from crowd sourced list spamAccountsList = miscData . spamLists [ 'spamAccountsList' ] # List of mentioned instagram/telegram scam accounts from crowd sourced list utf_16 = \"utf-8\" if config [ 'filter_mode' ] == \"autosmart\" : pass else : if sensitive : print ( \" \\n ----------------------------------------------- Sensitive-Smart Mode -----------------------------------------------\" ) else : # if not sensitive print ( \" \\n ----------------------------------------------- Auto-Smart Mode -----------------------------------------------\" ) print ( f \"~~~ This mode is a { F . LIGHTCYAN_EX } spammer's worst nightmare { S . R } . It automatically scans for multiple spammer techniques ~~~ \\n \" ) print ( \" > Extremely low (near 0%) false positives\" ) print ( \" > Detects whatsapp scammers and '18+ spam' bots\" ) print ( \" > Easily cuts through look-alike characters and obfuscations, including impersonating usernames\" ) if sensitive == False : print ( f \" > { F . LIGHTRED_EX } NOTE: { S . R } This mode prioritizes a { F . LIGHTGREEN_EX } VERY low false positive rate { S . R } , at the cost of occasionally missing some spammers. \\n \" ) elif sensitive == True : print ( f \" > { F . LIGHTRED_EX } NOTE: { S . R } In sensitive mode, { F . LIGHTRED_EX } expect more false positives { S . R } . Recommended to run this AFTER regular Auto Smart Mode. \\n \" ) input ( \"Press Enter to Begin Scanning...\" ) print ( \" \\033 [A \\033 [A\" ) # Erases previous line print ( \" Loading Filters [ ]\" , end = \" \\r \" ) # Create Variables blackAdWords , redAdWords , yellowAdWords , exactRedAdWords , = [], [], [], [] usernameBlackWords , usernameNovidBlackWords , usernameObfuBlackWords , textExactBlackWords , textUpLowBlackWords = [], [], [], [], [] threadWords , threadPhrases , monetWords , monetStrings , salutations , nakedNamePre = [], [], [], [], [], [] compiledRegexDict = { 'usernameBlackWords' : [], 'usernameNovidBlackWords' : [], 'blackAdWords' : [], 'redAdWords' : [], 'yellowAdWords' : [], 'exactRedAdWords' : [], 'usernameRedWords' : [], 'textObfuBlackWords' : [], 'usernameObfuBlackWords' : [], 'textExactBlackWords' : [], 'textUpLowBlackWords' : [], } # General Spammer Criteria #usernameBlackChars = \"\" spamGenEmoji_Raw = b '@Sl-~@Sl-};+UQApOJ|0pOJ~;q_yw3kMN(AyyC2e@3@cRnVj&SlB@' usernameBlackWords_Raw = [ b 'aA|ICWn^M`' , b 'aA|ICWn>^?c>' , b 'Z*CxTWo%_<a$#)' , b 'c4=WCbY*O1XL4a}' , b 'Z*CxIZgX^DXL4a}' , b 'Z*CxIX8' , b 'V`yb#YanfTAY*7@' , b 'b7f^9ZFwMLXkh' , b 'c4>2IbRcbcAY*7@' , b 'X>N0LVP|q-Z8`' , b 'Z*CxIZgX^D' , b 'Z*CxIZgX^DAZK!6Z2' , b 'c4=WCX>N0LVP|q-Z2' , b 'b9G`gb9G_' , b 'b9G`MG$3<zVg' , b 'Z*CxMc_3qGVE' , b 'XKx^MZy;@XAY*7@' , b 'X(w$UY-ML@bRcteVq$4-X8' , b 'W^!d^AZKZ2bN' , b 'WN&UKbRcqNVPqg}c>' , b 'Kxb`XX>2ZIZ*2' ] usernameNovidBlackWords_Raw = [ b 'cWHEJATS_yX=D' , b 'cWHEJAZ~9Uc4=e' , b 'cWHEJZ*_DaVQzUKc4=e' ] usernameObfuBlackWords_Raw = [ b 'c4Bp7YjX' , b 'b|7MPV{3B' , b 'a&KaFcm' , b 'a&KaFV{3B' ] usernameRedWords = [ \"whatsapp\" , \"telegram\" ] textObfuBlackWords = [ 'telegram' ] textExactBlackWords_Raw = [ b 'Z*6BRAZ2)AV{~kJAa`hCbRcOUZe?X;Wn=' , b 'Z*6BRAZ2)AV{~kJAa`hCbRc<ebs%nKWn^V!' , b 'Z*6BRAZ2)AV{~kJAa`hCbRckLZ*Xj7AZ}%4WMyO' , b 'ZDnU+ZaN?$Xm50MWpW|' , b 'M`3zpIv^rJZDD$4WFi' , b 'X>%ZSa$$35EFf)pAY*TCbY*UIAZc>' , b 'X>%ZFVRB+&XJsrPZFwMLZ*FvDZge1Na{' , b 'Z*CwVX8' ] textUpLowBlackWords_Raw = [ b 'O<5pAPfk=tPE;UCQv' , b 'Ngz!@OGO}8L0KR|MO0KpQXoT5PE<usQ~' , b 'O<5pTNkm0YQy@W7MF' , b 'Qbj>TAWc~yP*P7uNlZl' , b 'Z*CwVM*' ] # General Settings unicodeCategoriesStrip = [ \"Mn\" , \"Cc\" , \"Cf\" , \"Cs\" , \"Co\" , \"Cn\" ] # Categories of unicode characters to strip during normalization lowAl = b 'VPa!sWoBn+X=-b1ZEkOHadLBXb#`}nd3p' # Create General Lists spamGenEmojiSet = make_char_set ( b64decode ( spamGenEmoji_Raw ) . decode ( utf_16 )) lowAlSet = make_char_set ( b64decode ( lowAl ) . decode ( utf_16 )) #usernameBlackCharsSet = make_char_set(usernameBlackChars) for x in usernameBlackWords_Raw : usernameBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in usernameNovidBlackWords_Raw : usernameNovidBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in usernameObfuBlackWords_Raw : usernameObfuBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in textExactBlackWords_Raw : textExactBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in textUpLowBlackWords_Raw : textUpLowBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) # Type 1 Spammer Criteria minNumbersMatchCount = 6 # Choice of minimum number of matches from spamNums before considered spam spamNums = b '@4S%jypiv`lJC5e@4S@nyp`{~mhZfm@4T4ryqWL3kng;a@4S-lyp!*|l<&Ni@4S}pyqE91nD4xq-+|(hpyH9V;*yBsleOZVw&I?E;+~4|pM-+ovAy7_sN#{K;*quDl8NGzw&I<);+}!xo{R9GgoEI*sp65M;*qxEl8WM!x8j|+;+}%yo{aFHgoNO$sp65N;*q!Fl8fS#xZ<6;;+})zo{jLIgoWafq~ejd;*yNwleyxZy5gRM;+~G;o`m9_j_{v^hT@T>;*q)Hl8xe%y5gO?;+}=#o{#XKgoomhrs9#h;*yTyle^-byyBjQ;+~N3k%YbQpM;3vf|%lwr{a;j;*yWzlf2@cz2csS;+~Q4pM;6xk*MO4yyB9O;*-7Noxb9ph~l1-@SlW=;*+Z4lfUqvgp2T>gpBZ?gn{s %g n;m!pN{aIpP2BSpQ7-cpRDkmpO5gJpPBHTpRMqnpQG@dpSJLwpOEmKpPKNUpRVwopQP}epSSRxpONsLpPTTVpRe$ppQZ4fpSbXypOWyMpPcZWpRn+qpQiAgpSkdzpOf&NpPlfXpRw?rpQrGhpStj!pOo;OpPulYpR(|spQ!MipS$p#pOx^PpP %r ZpR@3tpQ-SjpS<v$pO)~QpP=xapS19upQ`YkpS|#%pO^5RpP}%bpSAFvpR4elpT6*&pT7' spamPlus = b ';+&e|oSEXDmBO*hmf?`8;(@y2f{NmZlj4Y!;)<2xik{-1wBo0_;-|afsDa|BgyN{8;;5tIsHEbkrQ)cj;;5(MsHozot>UPz;;6aesj=dzvf`|=@42Gyyo=$Rt>S^4;+U!8n5g2IrsA2f;+e7Ho2cTPnc|$9;+&h}oSfpEo#LFH;+&u2oS^EOn(CUH@Sl}{@Sl}|@Sl}}@Sl~2@Sl~3@Sl~4@SmQc@SmQd@SmQe@SmQf@SmQg@SmQh@SmQi' spamOne = b '@4S)lou7~Jou8TTou8xdou94nou9Yjl8EAywc?$&;+}xwo{I3Fgo59J;*p@@k+c' x = b64decode ( spamNums ) . decode ( utf_16 ) y = b64decode ( spamPlus ) . decode ( utf_16 ) z = b64decode ( spamOne ) . decode ( utf_16 ) # Prepare Filters for Type 1 Spammers spammerNumbersSet = make_char_set ( x ) regexTest1 = f \"[ { y } ] ?[1]\" regexTest2 = f \"[+] ?[ { z } ]\" regexTest3 = f \"[ { y } ] ?[ { z } ]\" compiledNumRegex = re . compile ( f \"( { regexTest1 } | { regexTest2 } | { regexTest3 } )\" ) # Type 2 Spammer Criteria blackAdWords_Raw = [ b 'V`yb#YanfTAaHVTW@&5' , b 'Z*XO9AZ>XdaB^>EX>0' , b 'b7f^9ZFwMYa&Km7Yy' , b 'V`yb#YanfTAa-eFWp4' , b 'V`yb#YanoPZ)Rz1' , b 'V`yb#Yan)MWMyv' , b 'bYXBHZ*CxMc>' , b 'Z*CxMc_46UV{~<LWd' ] redAdWords_Raw = [ b 'W_4q0' , b 'b7gn' , b 'WNBk-' , b 'WFcc~' , b 'W-4QA' , b 'W-2OUYX' , b 'Zgpg3' , b 'b1HZ' , b 'F*qv' , b 'aBp&M' ] yellowAdWords_Raw = [ b 'Y;SgD' , b 'Vr5}<bZKUFYy' , b 'VsB)5' , b 'XK8Y5' , b 'O~a&QV`yb=' , b 'Xk}@`pJf' , b 'Xm4}' , b 'aCLKYc>' ] exactRedAdWords_Raw = [ b 'EiElAEiElAEiElAEiElAEiElAEiElAEiElAEiElAEiElAEiElAEiC' , b 'Wq4s@bZmJbcW7aBAZZ|OWo2Y#WB' ] redAdEmoji = b64decode ( b '@Sl{P' ) . decode ( utf_16 ) yellowAdEmoji = b64decode ( b '@Sl-|@Sm8N@Sm8C@Sl>4@Sl;H@Sly0' ) . decode ( utf_16 ) hrt = b64decode ( b ';+duJpOTpHpOTjFpOTmGpOTaCpOTsIpOTvJpOTyKpOT#LpQoYlpOT&MpO&QJouu %e l9lkElAZ' ) . decode ( utf_16 ) # Create Type 2 Lists for x in blackAdWords_Raw : blackAdWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in redAdWords_Raw : redAdWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in yellowAdWords_Raw : yellowAdWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in exactRedAdWords_Raw : exactRedAdWords . append ( b64decode ( x ) . decode ( utf_16 )) print ( \" Loading Filters [=== ]\" , end = \" \\r \" ) # Prepare Filters for Type 2 Spammers redAdEmojiSet = make_char_set ( redAdEmoji ) yellowAdEmojiSet = make_char_set ( yellowAdEmoji ) hrtSet = make_char_set ( hrt ) # Prepare Regex to detect nothing but video link in comment onlyVideoLinkRegex = re . compile ( r \"^((?:https?:)?\\/\\/)?((?:www|m)\\.)?((?:youtube\\.com|youtu.be))(\\/(?:[\\w\\-]+\\?v=|embed\\/|v\\/)?)([\\w\\-]+)(\\S+)?$\" ) compiledRegexDict [ 'onlyVideoLinkRegex' ] = onlyVideoLinkRegex # Spam Thread Detection threadWords_raw = [ b 'aB^>EX><' , b 'V{&<LbZ-' , b 'Vsv8' , b 'Vrg_^Z)t7' , b 'baG*2X>Ml' , b 'baG*2Wd' , b 'X>N99b94' , b 'b7^O8VQc' , b 'Wq5F9a&!' , b 'aB^>EWpi_BZ*F01' , b 'b98cHbY*9G' , b 'ZDn+5Z)5' , b 'W^Zz3cm' , b 'b9G~5Wpi@' , b 'Wnpq|' , b 'AZ>C' , b 'AZ>DU' , b 'Z*XvLa&&cWX>@r' , b 'X>Mb0ZDj' , b 'aBp&SW^Zh1Zv' , b 'aB^>EX><' , b 'ZEtR6c>' , b 'b7f<4Wpn' , b 'cV%I0bZ7' , b 'Wnpq|' ] threadPhrases_raw = [ b 'cWHEJAZ2)PWpZ=' , b 'Wq5F9a&#bVas' , b 'Wq5F9a&#bVa&r' , b 'V{dMBVPkY4ZE^' , b 'V{dMBVPkY4ZE|w' , b 'V{dMBVPkY4XlZQ' , b 'V{dMBVPkY4Xk~H' , b 'cXDZTWguv2Z2' , b 'cXDZTWguu}as' , b 'bY*ySAZTfA' , b 'bY*ySAZTTB' ] monetWords_raw = [ b 'aB^>EX><' , b 'Wnpq|' , b 'X&`N3WMu' , b 'ZDC|(AZ=v' ] monetStrings_raw = [ b 'b#r6' , b 'Wp#3I' , b 'Bm' , b '!lM' , b ';)1L' , b 'Vsv8' ] salutations_raw = [ b 'ZE^' , b 'ZE|w' , b 'ZE{>L' , b 'ZE|y5E&' , b 'ZF2' , b 'ZF4R' , b 'Wq5F9a&!' ] nakedNamePre_raw = [ b 'cWHEJ' , b 'VsdY5WpV' ] # Make Spam Thread Lists for x in threadWords_raw : threadWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in threadPhrases_raw : threadPhrases . append ( b64decode ( x ) . decode ( utf_16 )) for x in monetWords_raw : monetWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in monetStrings_raw : monetStrings . append ( b64decode ( x ) . decode ( utf_16 )) for x in salutations_raw : salutations . append ( b64decode ( x ) . decode ( utf_16 )) for x in nakedNamePre_raw : nakedNamePre . append ( b64decode ( x ) . decode ( utf_16 )) # Compile Thread Detection Regex salutationString = '|' . join ( salutations ) nakedNameString = '|' . join ( nakedNamePre ) nameRegex = re . compile ( f ' \\\\ b( { salutationString } )\\s+([a-zA-Z]+\\.?)\\s+([a-zA-Z]+)' ) nakedNameRegex = re . compile ( f ' \\\\ b( { nakedNameString } )\\s+([a-zA-Z]+\\.?)\\s+([a-zA-Z]+)' ) cashRegex = re . compile ( r \"^(\\$|\u00a3|\u20ac)?(\\d+|\\d{1,3}(,\\d {3} )*)(\\.\\d+)?(\\$|\u00a3|\u20ac|k| ?usd| ?eur| ?btc)?$\" ) print ( \" Loading Filters [====== ]\" , end = \" \\r \" ) # Compile regex with upper case, otherwise many false positive character matches bufferChars = r \"*_~|`[]()'-.\u2022,\" compiledRegexDict [ 'bufferChars' ] = bufferChars bufferMatch , addBuffers = \" \\\\ *_~|` \\\\ - \\\\ ._\" , re . escape ( bufferChars ) # Add 'buffer' chars usernameConfuseRegex = re . compile ( confusable_regex ( miscData . channelOwnerName )) m = bufferMatch a = addBuffers for word in usernameBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameBlackWords' ] . append ([ word , value ]) for word in usernameNovidBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameNovidBlackWords' ] . append ([ word , value ]) for word in blackAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'blackAdWords' ] . append ([ word , value ]) for word in redAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'redAdWords' ] . append ([ word , value ]) for word in yellowAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'yellowAdWords' ] . append ([ word , value ]) for word in exactRedAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = False )) compiledRegexDict [ 'exactRedAdWords' ] . append ([ word , value ]) print ( \" Loading Filters [======== ]\" , end = \" \\r \" ) for word in usernameRedWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameRedWords' ] . append ([ word , value ]) for word in textObfuBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'textObfuBlackWords' ] . append ([ word , value ]) for word in usernameObfuBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameObfuBlackWords' ] . append ([ word , value ]) for word in textExactBlackWords : compiledRegexDict [ 'textExactBlackWords' ] . append ( word ) for word in textUpLowBlackWords : compiledRegexDict [ 'textUpLowBlackWords' ] . append ( word ) print ( \" Loading Filters [============== ]\" , end = \" \\r \" ) # Prepare All-domain Regex Expression prepString = \"\\.(\" first = True for extension in rootDomainList : if first == True : prepString += extension first = False else : prepString = prepString + \"|\" + extension sensitivePrepString = prepString + \")\" prepString = prepString + \")\\/\" rootDomainRegex = re . compile ( prepString ) sensitiveRootDomainRegex = re . compile ( sensitivePrepString ) print ( \" Loading Filters [=================== ]\" , end = \" \\r \" ) spamListExpressionsList = [] # Prepare spam domain regex for domain in spamDomainsList : spamListExpressionsList . append ( confusable_regex ( domain . upper () . replace ( \".\" , \"\u26ab\" ), include_character_padding = False ) . replace ( \"(?:\u26ab)\" , \"(?:[^a-zA-Z0-9 ]{1,2})\" )) for account in spamAccountsList : spamListExpressionsList . append ( confusable_regex ( account . upper (), include_character_padding = True ) . replace ( m , a )) # for thread in spamThreadsList: # spamListExpressionsList.append(confusable_regex(thread.upper(), include_character_padding=True).replace(m, a)) print ( \" Loading Filters [====================== ]\" , end = \" \\r \" ) spamListCombinedRegex = re . compile ( '|' . join ( spamListExpressionsList )) # Prepare Multi Language Detection turkish = '\u00c7\u00e7\u015e\u015f\u011e\u011f\u0130' germanic = '\u1e9e\u00df\u00c4\u00e4' cyrillic = \"\u0433\u0434\u0436\u0437\u043a\u043b\u043c\u043d\u043f\u0440\u0441\u0442\u0444\u0445\u0446\u0447\u0448\u0449\u044b\u044d\u044e\u044f\u044a\u044c\" japanese = '\u30a1\u30a2\u30a3\u30a4\u30a5\u30a6\u30a7\u30a8\u30a9\u30aa\u30ab\u30ac\u30ad\u30ae\u30af\u30b0\u30b1\u30b2\u30b3\u30b4\u30b5\u30b6\u30b7\u30b8\u30b9\u30ba\u30bb\u30bc\u30bd\u30be\u30bf\u30c0\u30c1\u30c2\u30c6\u30c7\u30c8\u30c9\u30ca\u30cb\u30cc\u30cd\u30ce\u30cf\u30d0\u30d1\u30d2\u30d3\u30d4\u30d5\u30d6\u30d7\u30d8\u30d9\u30da\u30db\u30dc\u30dd\u30de\u30df\u30e0\u30e1\u30e2\u30e3\u30e4\u30e5\u30e6\u30e7\u30e8\u30e9\u30ea\u30eb\u30ec\u30ed\u30ee\u30ef\u30f0\u30f1\u30f2\u30f3\u30f4\u30f5\u30f6\u30f7\u30f8\u30f9\u30fa\u30fc\u30fd\u30fe\u30ff\u3041\u3042\u3043\u3044\u3045\u3046\u3047\u3048\u3049\u304a\u304b\u304c\u304d\u304e\u3050\u3051\u3052\u3053\u3054\u3055\u3056\u3057\u3058\u3059\u305a\u305b\u305c\u305d\u305e\u305f\u3060\u3061\u3062\u3063\u3064\u3065\u3066\u3067\u3068\u3069\u306a\u306b\u306c\u306d\u306e\u306f\u3070\u3071\u3072\u3073\u3074\u3075\u3076\u3077\u3078\u3079\u307a\u307b\u307c\u307d\u307e\u307f\u3080\u3081\u3082\u3083\u3084\u3085\u3086\u3087\u3088\u3089\u308a\u308b\u308c\u308d\u308e\u308f\u3090\u3091\u3092\u3093\u3094\u3095\u3096\u309d\u309e\u309f' languages = [[ 'turkish' , turkish , []], [ 'germanic' , germanic , []], [ 'cyrillic' , cyrillic , []], [ 'japanese' , japanese , []]] for item in languages : item [ 2 ] = make_char_set ( item [ 1 ]) print ( \" Loading Filters [============================ ]\" , end = \" \\r \" ) threadFiltersDict = { 'threadWords' : threadWords , 'threadPhrases' : threadPhrases , 'monetWords' : monetWords , 'monetStrings' : monetStrings , 'nameRegex' : nameRegex , 'nakedNameRegex' : nakedNameRegex , 'cashRegex' : cashRegex } filterSettings = { 'spammerNumbersSet' : spammerNumbersSet , 'compiledNumRegex' : compiledNumRegex , 'minNumbersMatchCount' : minNumbersMatchCount , #'usernameBlackCharsSet': usernameBlackCharsSet, 'spamGenEmojiSet' : spamGenEmojiSet , 'redAdEmojiSet' : redAdEmojiSet , 'yellowAdEmojiSet' : yellowAdEmojiSet , 'hrtSet' : hrtSet , 'lowAlSet' : lowAlSet , 'rootDomainRegex' : rootDomainRegex , 'compiledRegexDict' : compiledRegexDict , 'usernameConfuseRegex' : usernameConfuseRegex , 'languages' : languages , 'sensitive' : sensitive , 'sensitiveRootDomainRegex' : sensitiveRootDomainRegex , 'unicodeCategoriesStrip' : unicodeCategoriesStrip , 'spamListCombinedRegex' : spamListCombinedRegex , 'threadFiltersDict' : threadFiltersDict } print ( \" \" ) # Erases line that says \"loading filters\" return filterSettings , None prepare_filter_mode_strings \u00b6 prepare_filter_mode_strings ( scanMode , filterMode , config ) Source code in Scripts/prepare_modes.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def prepare_filter_mode_strings ( scanMode , filterMode , config ): if filterMode == \"Username\" : whatToScanMsg = \"Usernames\" elif filterMode == \"Text\" : whatToScanMsg = \"Comment Text\" elif filterMode == \"NameAndText\" : whatToScanMsg = \"Usernames and Comment Text\" if config [ 'strings_to_filter' ] != \"ask\" : print ( \"Strings to filter obtained from config file.\" ) pass else : print ( f \" \\n Paste or type in a list of any { F . YELLOW } comma separated strings { S . R } you want to search for in { whatToScanMsg } . (Not case sensitive)\" ) print ( \" >Note: If the text you paste includes special characters or emojis, they might not display correctly here, but it WILL still search them fine.\" ) print ( \" Example Input: whatsapp, whatever multiple words, investment\" ) validEntry = False validConfigSetting = True while validEntry == False : if validConfigSetting == True and config and config [ 'strings_to_filter' ] != \"ask\" : inputString = config [ 'strings_to_filter' ] bypass = True else : bypass = False inputString = input ( \"Input Here: \" ) if str ( inputString ) . lower () == \"x\" : return \"MainMenu\" , None # Convert comma separated string into list with function, then check against current user's name filterStringList = utils . string_to_list ( inputString , lower = True ) if len ( filterStringList ) > 0 : validEntry = True else : validConfigSetting = False if validEntry == True : if config [ 'strings_to_filter' ] != \"ask\" : pass else : print ( f \" { whatToScanMsg } will be scanned for { F . MAGENTA } ANY { S . R } of the following strings:\" ) print ( filterStringList ) userChoice = choice ( \"Begin scanning? \" , bypass ) if userChoice == True : validEntry = True elif userChoice == False : validEntry = False elif userChoice == None : return \"MainMenu\" , None return filterStringList , None recover_deleted_comments \u00b6 recover_deleted_comments ( config ) Source code in Scripts/prepare_modes.py 529 530 531 532 533 534 535 536 537 538 539 540 def recover_deleted_comments ( config ): print ( f \" \\n\\n -------------------- { F . LIGHTGREEN_EX } Comment Recovery Mode { S . R } -------------------- \\n \" ) print ( \"> Believe it or not, the YouTube API actually allows you to re-instate \\\" deleted \\\" comments.\" ) print ( f \"> This is { F . YELLOW } only possible if you have stored the comment IDs { S . R } of the deleted comments, \\n such as { F . YELLOW } having kept the log file { S . R } of that session.\" ) print ( \"> If you don't have the comment IDs you can't recover the comments, and there is no way to find them. \\n \" ) recoveryList = files . parse_comment_list ( config , recovery = True ) if recoveryList == \"MainMenu\" : return \"MainMenu\" operations . delete_found_comments ( commentsList = recoveryList , banChoice = False , deletionMode = \"published\" , recoveryMode = True ) operations . check_recovered_comments ( commentsList = recoveryList )","title":"prepare_modes"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.delete_comment_list","text":"delete_comment_list ( config ) Source code in Scripts/prepare_modes.py 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 def delete_comment_list ( config ): progressFileFolder = os . path . join ( RESOURCES_FOLDER_NAME , \"Removal_List_Progress\" ) print ( f \" \\n\\n -------------------- { F . LIGHTRED_EX } Delete Using a List / Log { S . R } --------------------\" ) while True : print ( \" \\n Use new comment list, or continue where you left off with another list?\" ) print ( f \" 1. Use { F . LIGHTCYAN_EX } New List { S . R } \" ) print ( f \" 2. { F . LIGHTMAGENTA_EX } Continue With { S . R } a List\" ) listChoice = input ( \" \\n Selection (1 or 2): \" ) if listChoice == \"1\" or listChoice == \"2\" : break else : print ( f \" \\n { F . LIGHTRED_EX } Invalid selection! { S . R } Please try again.\" ) if listChoice == \"1\" : continued = False previousRemovedComments = set () remainingCommentsSet = set () previousFailedComments = list () sessionNum = 1 removalList , listFileNameBase = files . parse_comment_list ( config , removal = True , returnFileName = True ) if removalList == \"MainMenu\" : return \"MainMenu\" progressFileName = listFileNameBase + \"_removal_progress.save\" if listChoice == \"2\" : continued = True valid = False # Use existing save if available existingSavesList = files . check_existing_save () if len ( existingSavesList ) > 0 : if len ( existingSavesList ) == 1 : saveChoice = existingSavesList [ 0 ] print ( f \" \\n { F . LIGHTGREEN_EX } Using existing save: { S . R }{ saveChoice } \" ) elif len ( existingSavesList ) > 1 : print ( \" \\n Which save file would you like to use?\" ) for i , save in enumerate ( existingSavesList ): print ( f \" { i + 1 } . { save [: - 22 ] } \" ) # Take and Validate Input while valid == False : saveChoice = input ( f \" \\n Selection (1- { len ( existingSavesList ) } ): \" ) if saveChoice . isdigit () and int ( saveChoice ) > 0 and int ( saveChoice ) <= len ( existingSavesList ): saveChoice = existingSavesList [ int ( saveChoice ) - 1 ] valid = True elif saveChoice . lower () == \"x\" : return \"MainMenu\" else : print ( f \" \\n { F . RED } Invalid Selectionp { S . R } . Please try again.\" ) progressFileName = saveChoice progressFileNameWithPath = os . path . join ( progressFileFolder , progressFileName ) progressDict = files . read_dict_pickle_file ( progressFileName , progressFileFolder ) valid = True removalList = \"Loaded\" else : print ( f \" \\n { F . RED } No previous saves found! { S . R } \" ) input ( \" \\n Press Enter to return to Main Menu...\" ) return \"MainMenu\" while valid == False : input ( F \" \\n Next, follow the process by loading { F . YELLOW } the same comment list/log you used before { S . R } . Press Enter to continue...\" ) removalList , listFileNameBase = files . parse_comment_list ( config , removal = True , returnFileName = True ) if removalList == \"MainMenu\" : return \"MainMenu\" # Read pickle into dictionary of deleted and non-deleted files from last time print ( \" \\n Checking for saved progress file...\" ) progressFileName = listFileNameBase + \"_removal_progress.save\" progressFileNameWithPath = os . path . join ( progressFileFolder , progressFileName ) if os . path . isfile ( progressFileNameWithPath ): progressDict = files . read_dict_pickle_file ( progressFileName , progressFileFolder ) valid = True else : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } No progress file found for that log file. Try again.\" ) # Get data from list lastSessionNum = int ( len ( progressDict )) previousRemovedComments = set ( progressDict [ lastSessionNum ][ 'removed' ]) remainingCommentsSet = set ( progressDict [ lastSessionNum ][ 'notRemoved' ]) previousFailedComments = progressDict [ lastSessionNum ][ 'failedCommentsList' ] sessionNum = int ( len ( progressDict )) + 1 if removalList == \"Loaded\" or ( len ( remainingCommentsSet ) + len ( previousRemovedComments ) + len ( previousFailedComments )) == len ( removalList ): pass else : print ( f \" { F . LIGHTRED_EX } Error: { S . R } The length of the comment list you loaded doesn't match the comment list you saved last time.\" ) if choice ( f \" { F . YELLOW } Continue anyway? { S . R } (Will use previous save and ignore the file you just loaded)\" ) != True : return \"MainMenu\" # Display status of loaded file prevRemovedNum = len ( previousRemovedComments ) prevNotRemovedNum = len ( remainingCommentsSet ) prevFailedNum = len ( previousFailedComments ) print ( f \" \\n { F . LIGHTCYAN_EX } ----------------------- Loaded Saved Comment List Status ----------------------- { S . R } \" ) print ( f \" { F . LIGHTGREEN_EX }{ prevRemovedNum } removed { S . R } | { F . YELLOW }{ prevNotRemovedNum } not removed yet { S . R } | { F . LIGHTRED_EX }{ prevFailedNum } failed to be removed { S . R } \" ) input ( \" \\n Press Enter to continue...\" ) # Set removal list based on previous save removalList = list ( remainingCommentsSet ) if len ( previousFailedComments ) > 0 : print ( f \" { F . LIGHTRED_EX } NOTE: { S . R } During previous sessions, { F . LIGHTRED_EX }{ len ( previousFailedComments ) } comments { S . R } failed to be deleted.\" ) failChoice = choice ( f \" \\n { F . YELLOW } Add these back into the list { S . R } to try again? (Otherwise will skip them for later) \" ) if failChoice == True : removalList = removalList + list ( previousFailedComments ) previousFailedComments = list () else : removalList = list ( remainingCommentsSet ) print ( f \" \\n Loaded { F . YELLOW }{ len ( removalList ) } Remaining Comments { S . R } \" ) # --- Begin removal process using list ------ print ( \" \\n What do you want to do with the comments in the list?\" ) print ( f \"1. { F . LIGHTRED_EX } Delete { S . R } them\" ) print ( f \"2. { F . LIGHTMAGENTA_EX } Hide { S . R } them for review\" ) validInput = False while validInput == False : userChoice = input ( \" \\n Selection (1 or 2): \" ) if userChoice == \"1\" : removalMode = \"rejected\" validInput = True elif userChoice == \"2\" : removalMode = \"heldForReview\" validInput = True banChoice = False elif userChoice == \"99\" : # For Testing removalMode = \"reportSpam\" banChoice = False validInput = True elif userChoice . lower () == \"x\" : return \"MainMenu\" else : print ( f \" { F . RED } Invalid input, try again. { S . R } \" ) if removalMode == \"rejected\" : banChoice = choice ( F \"Also { F . RED } ban { S . R } the commenters?\" ) if str ( banChoice ) . lower () == \"x\" : return \"MainMenu\" # Set limit based on quota quotaLimit = int ( config [ 'quota_limit' ]) - 100 validInput = False while validInput == False : print ( f \" \\n { F . YELLOW } How many comments { S . R } (out of { len ( removalList ) } ) do you want to remove this session? (Input '0' or 'all' to do them all)\" ) countChoice = input ( f \" \\n Number of comments (1- { str ( quotaLimit ) } ): \" ) if countChoice . lower () == \"all\" or countChoice == \"0\" : countChoice = len ( removalList ) try : countChoice = int ( countChoice ) if countChoice > 0 and countChoice <= quotaLimit : validInput = True elif countChoice >= quotaLimit : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } { countChoice } is too many comments, you'll run out of API Quota. Read Here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) else : print ( f \"Invalid input, must be 'all' or a whole number from 1 to { str ( quotaLimit ) } .\" ) except : print ( f \" { F . RED } Invalid input, must be a whole number. { S . R } Try again.\" ) # Extract selected amount of comment IDs from list if countChoice >= len ( removalList ): partial = False else : partial = True if partial == True : selectedRemovalList = removalList [: countChoice ] notRemovedList = removalList [ countChoice :] else : selectedRemovalList = removalList notRemovedList = list () input ( f \" \\n Press { F . YELLOW } Enter { S . R } to Begin Removal...\" ) failedCommentsList = operations . delete_found_comments ( commentsList = selectedRemovalList , banChoice = banChoice , deletionMode = removalMode ) ### Handle Results ### if len ( failedCommentsList ) > 0 : print ( f \" \\n { F . LIGHTRED_EX } Warning! { S . R } { len ( failedCommentsList ) } comments apparently failed to be removed. They'll be saved to be tried later.\" ) input ( \" \\n Press Enter to continue...\" ) failedCommentsSet = set ( failedCommentsList ) else : failedCommentsSet = set () selectedRemovalSet = set ( selectedRemovalList ) remainingCommentsSet = set ( notRemovedList ) # Calculating final results for save progress file if len ( failedCommentsSet ) > 0 : partial = True finalRemovedSet = selectedRemovalSet - failedCommentsSet else : finalRemovedSet = selectedRemovalSet if partial == True or continued == True : print ( \" \\n Saving progress...\" ) # Initialize progress dictionary if continued == True : progressDict [ sessionNum ] = { 'removed' : previousRemovedComments . union ( finalRemovedSet ), 'notRemoved' : remainingCommentsSet , 'failedCommentsList' : failedCommentsList + previousFailedComments } else : progressDict = dict () progressDict [ sessionNum ] = { 'removed' : finalRemovedSet , 'notRemoved' : remainingCommentsSet , 'failedCommentsList' : failedCommentsList + previousFailedComments } if len ( progressDict [ sessionNum ][ 'notRemoved' ]) == 0 and len ( progressDict [ sessionNum ][ 'failedCommentsList' ]) == 0 : if continued == True : print ( f \" \\n { F . LIGHTGREEN_EX } Success! { S . R } All comments should be removed. { F . YELLOW } Will now remove { S . R } finished progress file. (Log file will remain)\" ) files . try_remove_file ( progressFileNameWithPath ) else : print ( f \" \\n { F . LIGHTGREEN_EX } Success! { S . R } All comments should be removed.\" ) else : #progressFileName = listFileNameBase + \"_removal_progress.save\" result = files . write_dict_pickle_file ( progressDict , progressFileName , progressFileFolder , forceOverwrite = True ) if result == True : print ( f \"Progress file saved.\" ) removed = len ( progressDict [ sessionNum ][ 'removed' ]) notRemoved = len ( progressDict [ sessionNum ][ 'notRemoved' ]) failed = len ( progressDict [ sessionNum ][ 'failedCommentsList' ]) print ( f \" \\n { F . LIGHTCYAN_EX } ----------------------- Comment List Status ----------------------- { S . R } \" ) print ( f \" { F . LIGHTGREEN_EX }{ removed } removed { S . R } | { F . YELLOW }{ notRemoved } not removed yet { S . R } | { F . LIGHTRED_EX }{ failed } failed to be removed { S . R } \" ) print ( f \" \\n You will be able to { F . YELLOW } continue later { S . R } using the { F . YELLOW } same log file { S . R } .\" ) input ( f \" \\n Press { F . YELLOW } Enter { S . R } to return to Main Menu...\" ) return \"MainMenu\"","title":"delete_comment_list()"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.prepare_filter_mode_ID","text":"prepare_filter_mode_ID ( scanMode , config ) Source code in Scripts/prepare_modes.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def prepare_filter_mode_ID ( scanMode , config ): processResult = ( False , None ) #Tuple, first element is status of validity of channel ID, second element is channel ID validConfigSetting = True while processResult [ 0 ] == False : if validConfigSetting == True and config and config [ 'channel_ids_to_filter' ] != \"ask\" : inputtedSpammerChannelID = config [ 'channel_ids_to_filter' ] bypass = True else : bypass = False inputtedSpammerChannelID = input ( f \"Enter the { F . LIGHTRED_EX } Channel link(s) or ID(s) { S . R } of the spammer (comma separated): \" ) if str ( inputtedSpammerChannelID ) . lower () == \"x\" : return \"MainMenu\" , None processResult = utils . process_spammer_ids ( inputtedSpammerChannelID ) if processResult [ 0 ] == True : inputtedSpammerChannelID = processResult [ 1 ] # After processing, if valid, inputtedSpammerChannelID is a list of channel IDs else : validConfigSetting = False print ( \" \\n \" ) # Check if spammer ID and user's channel ID are the same, and warn # If using channel-wide scanning mode, program will just ignore those comments if any ( auth . CURRENTUSER . id == i for i in inputtedSpammerChannelID ): print ( f \" { B . RED }{ F . WHITE } WARNING: { S . R } - You entered your own channel ID!\" ) print ( f \"For safety purposes, this program always { F . YELLOW } ignores { S . R } your own comments.\" ) if config [ 'channel_ids_to_filter' ] != \"ask\" : pass else : input ( \" \\n Press Enter to continue...\" ) return inputtedSpammerChannelID , None","title":"prepare_filter_mode_ID()"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.prepare_filter_mode_chars","text":"prepare_filter_mode_chars ( scanMode , filterMode , config ) Source code in Scripts/prepare_modes.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def prepare_filter_mode_chars ( scanMode , filterMode , config ): if filterMode == \"Username\" : whatToScanMsg = \"Usernames\" elif filterMode == \"Text\" : whatToScanMsg = \"Comment Text\" elif filterMode == \"NameAndText\" : whatToScanMsg = \"Usernames and Comment Text\" if config [ 'characters_to_filter' ] != \"ask\" : print ( \"Characters to filter obtained from config file.\" ) pass else : print ( f \" \\n Next, you will input { F . YELLOW } ONLY { S . R } any special characters / emojis you want to search for in all { whatToScanMsg } . Do not include commas or spaces!\" ) print ( \" Note: Letters, numbers, and basic punctuation will not be included for safety purposes, even if you enter them.\" ) print ( \" Example: \ud83d\udc4b\ud83d\udd25\u2714\ufe0f\u2728\" ) input ( f \" \\n Press { F . LIGHTGREEN_EX } Enter { S . R } to open the { F . LIGHTGREEN_EX } text entry window { S . R } ...\" ) print ( \"-------------------------------------------\" ) confirm = False validConfigSetting = True while confirm == False : if validConfigSetting == True and config and config [ 'characters_to_filter' ] != \"ask\" : inputChars = make_char_set ( config [ 'characters_to_filter' ], stripLettersNumbers = True , stripKeyboardSpecialChars = False , stripPunctuation = True ) bypass = True else : bypass = False print ( f \" \\n Waiting for input Window. Press { F . MAGENTA } 'Execute' { S . R } after entering valid characters to continue...\" , end = \" \\r \" ) try : # Takes in user input of characters, returns 'set' of characters stripped of specified characters inputChars = take_input_gui ( mode = \"chars\" , stripLettersNumbers = True , stripKeyboardSpecialChars = False , stripPunctuation = True ) except NameError : # Catch if user closes GUI window, exit program. print ( \" \" ) # Clears the line because of \\r on previous print print ( \" \\n Error Code G-1: Something went wrong with the input, or you closed the window improperly.\" ) print ( \"If this keeps happening inexplicably, consider filing a bug report here: https://github.com/ThioJoe/YT-Spammer-Purge/issues\" ) input ( \"Press Enter to exit...\" ) sys . exit () print ( f \" { whatToScanMsg } will be scanned for { F . MAGENTA } ANY { S . R } of the characters you entered in the previous window.\" ) userChoice = choice ( \"Begin Scanning? \" , bypass ) if userChoice == True : confirm = True elif userChoice == False : confirm = False validConfigSetting = False elif userChoice == None : return \"MainMenu\" , None return inputChars , None","title":"prepare_filter_mode_chars()"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.prepare_filter_mode_non_ascii","text":"prepare_filter_mode_non_ascii ( scanMode , config ) Source code in Scripts/prepare_modes.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 def prepare_filter_mode_non_ascii ( scanMode , config ): print ( \" \\n -------------------------------------------------- ASCII Mode--------------------------------------------------\" ) print ( \"~~~ This mode automatically searches for usernames that contain special characters (aka not letters/numbers) ~~~ \\n \" ) print ( \"Choose the sensitivity level of the filter. You will be shown examples after you choose.\" ) print ( f \" 1. Allow { F . LIGHTMAGENTA_EX } Standard + Extended ASCII { S . R } : Filter rare unicode & Emojis only\" ) print ( f \" 2. Allow { F . LIGHTMAGENTA_EX } Standard ASCII only { S . R } : Also filter semi-common foreign characters\" ) print ( f \" 3. { F . LIGHTRED_EX } NUKE Mode (\u2518\u00b0\u25a1\u00b0)\u2518\u2248 \u2534\u2500\u2500\u2534 : Allow ONLY numbers, letters, and spaces { S . R } \" ) print ( \"\" ) # Get user input for mode selection, confirmation = False validConfigSetting = True while confirmation == False : if validConfigSetting == True and config and config [ 'autoascii_sensitivity' ] != \"ask\" : selection = config [ 'autoascii_sensitivity' ] bypass = True else : bypass = False selection = input ( \"Choose Mode: \" ) if str ( selection ) . lower () == \"x\" : return \"MainMenu\" , None if selection == \"1\" : print ( f \"Searches for { F . YELLOW } usernames with emojis, unicode symbols, and rare foreign characters { S . R } such as: \u2714\ufe0f \u261d\ufe0f \ud83e\udc46 \u25b2 \u03c0 \u019d \u0152\" ) userChoice = choice ( \"Choose this mode?\" , bypass ) if userChoice == True : regexPattern = r \"[^\\x00-\\xFF]\" confirmation = True elif userChoice == None : return \"MainMenu\" , None elif selection == \"2\" : print ( f \"Searches for { F . YELLOW } usernames with anything EXCEPT { S . R } the following: { F . YELLOW } Letters, numbers, punctuation, and common special characters { S . R } you can type with your keyboard like: % * & () + \" ) userChoice = choice ( \"Choose this mode?\" , bypass ) if userChoice == True : regexPattern = r \"[^\\x00-\\x7F]\" confirmation = True elif userChoice == None : return \"MainMenu\" , None elif selection == \"3\" : print ( f \"Searches for { F . YELLOW } usernames with anything EXCEPT letters, numbers, and spaces { S . R } - { B . RED }{ F . WHITE } EXTREMELY LIKELY to cause collateral damage! { S . R } Recommended to just use to manually gather list of spammer IDs, then use a different mode to delete.\" ) userChoice = choice ( \"Choose this mode?\" , bypass ) if userChoice == True : regexPattern = r \"[^a-zA-Z0-9 ]\" confirmation = True elif userChoice == None : return \"MainMenu\" , None else : print ( f \"Invalid input: { selection } - Must be 1, 2, or 3.\" ) validConfigSetting = False if selection == \"1\" : autoModeName = \"Allow Standard + Extended ASCII\" elif selection == \"2\" : autoModeName = \"Allow Standard ASCII only\" elif selection == \"3\" : autoModeName = \"NUKE Mode (\u2518\u00b0\u25a1\u00b0)\u2518\u2248 \u2534\u2500\u2500\u2534 - Allow only letters, numbers, and spaces\" if confirmation == True : return regexPattern , autoModeName else : input ( \"How did you get here? Something very strange went wrong. Press Enter to Exit...\" ) sys . exit ()","title":"prepare_filter_mode_non_ascii()"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.prepare_filter_mode_regex","text":"prepare_filter_mode_regex ( scanMode , filterMode , config ) Source code in Scripts/prepare_modes.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def prepare_filter_mode_regex ( scanMode , filterMode , config ): if filterMode == \"Username\" : whatToScanMsg = \"Usernames\" elif filterMode == \"Text\" : whatToScanMsg = \"Comment Text\" elif filterMode == \"NameAndText\" : whatToScanMsg = \"Usernames and Comment Text\" if config [ 'regex_to_filter' ] != \"ask\" : print ( \"Regex expression obtained from config file.\" ) validConfigSetting = True else : print ( f \"Enter any { F . YELLOW } regex expression { S . R } to search within { whatToScanMsg } .\" ) print ( r \" Example Input: [^\\x00-\\xFF]\" ) validConfigSetting = False validExpression = False while validExpression == False : if validConfigSetting == True and config and config [ 'regex_to_filter' ] != \"ask\" : inputtedExpression = config [ 'regex_to_filter' ] bypass = True else : inputtedExpression = input ( \"Input Expression Here: \" ) if str ( inputtedExpression ) . lower () == \"x\" : return \"MainMenu\" , None bypass = False validationResults = validation . validate_regex ( inputtedExpression ) # Returns tuple of valid, and processed expression validExpression = validationResults [ 0 ] if validExpression == True : processedExpression = validationResults [ 1 ] print ( f \" The expression appears to be { F . GREEN } valid { S . R } !\" ) if validExpression == True : userChoice = choice ( \"Begin scanning? \" , bypass ) if userChoice == True : pass elif userChoice == False : validExpression = False validConfigSetting = False elif userChoice == None : return \"MainMenu\" , None else : print ( f \" { F . RED } Error { S . R } : The expression appears to be { F . RED } invalid { S . R } !\" ) validConfigSetting = False return processedExpression , None","title":"prepare_filter_mode_regex()"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.prepare_filter_mode_smart","text":"prepare_filter_mode_smart ( scanMode , config , miscData , sensitive = False ) Source code in Scripts/prepare_modes.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 def prepare_filter_mode_smart ( scanMode , config , miscData , sensitive = False ): rootDomainList = miscData . rootDomainsList spamDomainsList = miscData . spamLists [ 'spamDomainsList' ] # List of domains from crowd sourced list #spamThreadsList = miscData.spamLists['spamThreadsList'] # List of filters associated with spam threads from crowd sourced list spamAccountsList = miscData . spamLists [ 'spamAccountsList' ] # List of mentioned instagram/telegram scam accounts from crowd sourced list utf_16 = \"utf-8\" if config [ 'filter_mode' ] == \"autosmart\" : pass else : if sensitive : print ( \" \\n ----------------------------------------------- Sensitive-Smart Mode -----------------------------------------------\" ) else : # if not sensitive print ( \" \\n ----------------------------------------------- Auto-Smart Mode -----------------------------------------------\" ) print ( f \"~~~ This mode is a { F . LIGHTCYAN_EX } spammer's worst nightmare { S . R } . It automatically scans for multiple spammer techniques ~~~ \\n \" ) print ( \" > Extremely low (near 0%) false positives\" ) print ( \" > Detects whatsapp scammers and '18+ spam' bots\" ) print ( \" > Easily cuts through look-alike characters and obfuscations, including impersonating usernames\" ) if sensitive == False : print ( f \" > { F . LIGHTRED_EX } NOTE: { S . R } This mode prioritizes a { F . LIGHTGREEN_EX } VERY low false positive rate { S . R } , at the cost of occasionally missing some spammers. \\n \" ) elif sensitive == True : print ( f \" > { F . LIGHTRED_EX } NOTE: { S . R } In sensitive mode, { F . LIGHTRED_EX } expect more false positives { S . R } . Recommended to run this AFTER regular Auto Smart Mode. \\n \" ) input ( \"Press Enter to Begin Scanning...\" ) print ( \" \\033 [A \\033 [A\" ) # Erases previous line print ( \" Loading Filters [ ]\" , end = \" \\r \" ) # Create Variables blackAdWords , redAdWords , yellowAdWords , exactRedAdWords , = [], [], [], [] usernameBlackWords , usernameNovidBlackWords , usernameObfuBlackWords , textExactBlackWords , textUpLowBlackWords = [], [], [], [], [] threadWords , threadPhrases , monetWords , monetStrings , salutations , nakedNamePre = [], [], [], [], [], [] compiledRegexDict = { 'usernameBlackWords' : [], 'usernameNovidBlackWords' : [], 'blackAdWords' : [], 'redAdWords' : [], 'yellowAdWords' : [], 'exactRedAdWords' : [], 'usernameRedWords' : [], 'textObfuBlackWords' : [], 'usernameObfuBlackWords' : [], 'textExactBlackWords' : [], 'textUpLowBlackWords' : [], } # General Spammer Criteria #usernameBlackChars = \"\" spamGenEmoji_Raw = b '@Sl-~@Sl-};+UQApOJ|0pOJ~;q_yw3kMN(AyyC2e@3@cRnVj&SlB@' usernameBlackWords_Raw = [ b 'aA|ICWn^M`' , b 'aA|ICWn>^?c>' , b 'Z*CxTWo%_<a$#)' , b 'c4=WCbY*O1XL4a}' , b 'Z*CxIZgX^DXL4a}' , b 'Z*CxIX8' , b 'V`yb#YanfTAY*7@' , b 'b7f^9ZFwMLXkh' , b 'c4>2IbRcbcAY*7@' , b 'X>N0LVP|q-Z8`' , b 'Z*CxIZgX^D' , b 'Z*CxIZgX^DAZK!6Z2' , b 'c4=WCX>N0LVP|q-Z2' , b 'b9G`gb9G_' , b 'b9G`MG$3<zVg' , b 'Z*CxMc_3qGVE' , b 'XKx^MZy;@XAY*7@' , b 'X(w$UY-ML@bRcteVq$4-X8' , b 'W^!d^AZKZ2bN' , b 'WN&UKbRcqNVPqg}c>' , b 'Kxb`XX>2ZIZ*2' ] usernameNovidBlackWords_Raw = [ b 'cWHEJATS_yX=D' , b 'cWHEJAZ~9Uc4=e' , b 'cWHEJZ*_DaVQzUKc4=e' ] usernameObfuBlackWords_Raw = [ b 'c4Bp7YjX' , b 'b|7MPV{3B' , b 'a&KaFcm' , b 'a&KaFV{3B' ] usernameRedWords = [ \"whatsapp\" , \"telegram\" ] textObfuBlackWords = [ 'telegram' ] textExactBlackWords_Raw = [ b 'Z*6BRAZ2)AV{~kJAa`hCbRcOUZe?X;Wn=' , b 'Z*6BRAZ2)AV{~kJAa`hCbRc<ebs%nKWn^V!' , b 'Z*6BRAZ2)AV{~kJAa`hCbRckLZ*Xj7AZ}%4WMyO' , b 'ZDnU+ZaN?$Xm50MWpW|' , b 'M`3zpIv^rJZDD$4WFi' , b 'X>%ZSa$$35EFf)pAY*TCbY*UIAZc>' , b 'X>%ZFVRB+&XJsrPZFwMLZ*FvDZge1Na{' , b 'Z*CwVX8' ] textUpLowBlackWords_Raw = [ b 'O<5pAPfk=tPE;UCQv' , b 'Ngz!@OGO}8L0KR|MO0KpQXoT5PE<usQ~' , b 'O<5pTNkm0YQy@W7MF' , b 'Qbj>TAWc~yP*P7uNlZl' , b 'Z*CwVM*' ] # General Settings unicodeCategoriesStrip = [ \"Mn\" , \"Cc\" , \"Cf\" , \"Cs\" , \"Co\" , \"Cn\" ] # Categories of unicode characters to strip during normalization lowAl = b 'VPa!sWoBn+X=-b1ZEkOHadLBXb#`}nd3p' # Create General Lists spamGenEmojiSet = make_char_set ( b64decode ( spamGenEmoji_Raw ) . decode ( utf_16 )) lowAlSet = make_char_set ( b64decode ( lowAl ) . decode ( utf_16 )) #usernameBlackCharsSet = make_char_set(usernameBlackChars) for x in usernameBlackWords_Raw : usernameBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in usernameNovidBlackWords_Raw : usernameNovidBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in usernameObfuBlackWords_Raw : usernameObfuBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in textExactBlackWords_Raw : textExactBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in textUpLowBlackWords_Raw : textUpLowBlackWords . append ( b64decode ( x ) . decode ( utf_16 )) # Type 1 Spammer Criteria minNumbersMatchCount = 6 # Choice of minimum number of matches from spamNums before considered spam spamNums = b '@4S%jypiv`lJC5e@4S@nyp`{~mhZfm@4T4ryqWL3kng;a@4S-lyp!*|l<&Ni@4S}pyqE91nD4xq-+|(hpyH9V;*yBsleOZVw&I?E;+~4|pM-+ovAy7_sN#{K;*quDl8NGzw&I<);+}!xo{R9GgoEI*sp65M;*qxEl8WM!x8j|+;+}%yo{aFHgoNO$sp65N;*q!Fl8fS#xZ<6;;+})zo{jLIgoWafq~ejd;*yNwleyxZy5gRM;+~G;o`m9_j_{v^hT@T>;*q)Hl8xe%y5gO?;+}=#o{#XKgoomhrs9#h;*yTyle^-byyBjQ;+~N3k%YbQpM;3vf|%lwr{a;j;*yWzlf2@cz2csS;+~Q4pM;6xk*MO4yyB9O;*-7Noxb9ph~l1-@SlW=;*+Z4lfUqvgp2T>gpBZ?gn{s %g n;m!pN{aIpP2BSpQ7-cpRDkmpO5gJpPBHTpRMqnpQG@dpSJLwpOEmKpPKNUpRVwopQP}epSSRxpONsLpPTTVpRe$ppQZ4fpSbXypOWyMpPcZWpRn+qpQiAgpSkdzpOf&NpPlfXpRw?rpQrGhpStj!pOo;OpPulYpR(|spQ!MipS$p#pOx^PpP %r ZpR@3tpQ-SjpS<v$pO)~QpP=xapS19upQ`YkpS|#%pO^5RpP}%bpSAFvpR4elpT6*&pT7' spamPlus = b ';+&e|oSEXDmBO*hmf?`8;(@y2f{NmZlj4Y!;)<2xik{-1wBo0_;-|afsDa|BgyN{8;;5tIsHEbkrQ)cj;;5(MsHozot>UPz;;6aesj=dzvf`|=@42Gyyo=$Rt>S^4;+U!8n5g2IrsA2f;+e7Ho2cTPnc|$9;+&h}oSfpEo#LFH;+&u2oS^EOn(CUH@Sl}{@Sl}|@Sl}}@Sl~2@Sl~3@Sl~4@SmQc@SmQd@SmQe@SmQf@SmQg@SmQh@SmQi' spamOne = b '@4S)lou7~Jou8TTou8xdou94nou9Yjl8EAywc?$&;+}xwo{I3Fgo59J;*p@@k+c' x = b64decode ( spamNums ) . decode ( utf_16 ) y = b64decode ( spamPlus ) . decode ( utf_16 ) z = b64decode ( spamOne ) . decode ( utf_16 ) # Prepare Filters for Type 1 Spammers spammerNumbersSet = make_char_set ( x ) regexTest1 = f \"[ { y } ] ?[1]\" regexTest2 = f \"[+] ?[ { z } ]\" regexTest3 = f \"[ { y } ] ?[ { z } ]\" compiledNumRegex = re . compile ( f \"( { regexTest1 } | { regexTest2 } | { regexTest3 } )\" ) # Type 2 Spammer Criteria blackAdWords_Raw = [ b 'V`yb#YanfTAaHVTW@&5' , b 'Z*XO9AZ>XdaB^>EX>0' , b 'b7f^9ZFwMYa&Km7Yy' , b 'V`yb#YanfTAa-eFWp4' , b 'V`yb#YanoPZ)Rz1' , b 'V`yb#Yan)MWMyv' , b 'bYXBHZ*CxMc>' , b 'Z*CxMc_46UV{~<LWd' ] redAdWords_Raw = [ b 'W_4q0' , b 'b7gn' , b 'WNBk-' , b 'WFcc~' , b 'W-4QA' , b 'W-2OUYX' , b 'Zgpg3' , b 'b1HZ' , b 'F*qv' , b 'aBp&M' ] yellowAdWords_Raw = [ b 'Y;SgD' , b 'Vr5}<bZKUFYy' , b 'VsB)5' , b 'XK8Y5' , b 'O~a&QV`yb=' , b 'Xk}@`pJf' , b 'Xm4}' , b 'aCLKYc>' ] exactRedAdWords_Raw = [ b 'EiElAEiElAEiElAEiElAEiElAEiElAEiElAEiElAEiElAEiElAEiC' , b 'Wq4s@bZmJbcW7aBAZZ|OWo2Y#WB' ] redAdEmoji = b64decode ( b '@Sl{P' ) . decode ( utf_16 ) yellowAdEmoji = b64decode ( b '@Sl-|@Sm8N@Sm8C@Sl>4@Sl;H@Sly0' ) . decode ( utf_16 ) hrt = b64decode ( b ';+duJpOTpHpOTjFpOTmGpOTaCpOTsIpOTvJpOTyKpOT#LpQoYlpOT&MpO&QJouu %e l9lkElAZ' ) . decode ( utf_16 ) # Create Type 2 Lists for x in blackAdWords_Raw : blackAdWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in redAdWords_Raw : redAdWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in yellowAdWords_Raw : yellowAdWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in exactRedAdWords_Raw : exactRedAdWords . append ( b64decode ( x ) . decode ( utf_16 )) print ( \" Loading Filters [=== ]\" , end = \" \\r \" ) # Prepare Filters for Type 2 Spammers redAdEmojiSet = make_char_set ( redAdEmoji ) yellowAdEmojiSet = make_char_set ( yellowAdEmoji ) hrtSet = make_char_set ( hrt ) # Prepare Regex to detect nothing but video link in comment onlyVideoLinkRegex = re . compile ( r \"^((?:https?:)?\\/\\/)?((?:www|m)\\.)?((?:youtube\\.com|youtu.be))(\\/(?:[\\w\\-]+\\?v=|embed\\/|v\\/)?)([\\w\\-]+)(\\S+)?$\" ) compiledRegexDict [ 'onlyVideoLinkRegex' ] = onlyVideoLinkRegex # Spam Thread Detection threadWords_raw = [ b 'aB^>EX><' , b 'V{&<LbZ-' , b 'Vsv8' , b 'Vrg_^Z)t7' , b 'baG*2X>Ml' , b 'baG*2Wd' , b 'X>N99b94' , b 'b7^O8VQc' , b 'Wq5F9a&!' , b 'aB^>EWpi_BZ*F01' , b 'b98cHbY*9G' , b 'ZDn+5Z)5' , b 'W^Zz3cm' , b 'b9G~5Wpi@' , b 'Wnpq|' , b 'AZ>C' , b 'AZ>DU' , b 'Z*XvLa&&cWX>@r' , b 'X>Mb0ZDj' , b 'aBp&SW^Zh1Zv' , b 'aB^>EX><' , b 'ZEtR6c>' , b 'b7f<4Wpn' , b 'cV%I0bZ7' , b 'Wnpq|' ] threadPhrases_raw = [ b 'cWHEJAZ2)PWpZ=' , b 'Wq5F9a&#bVas' , b 'Wq5F9a&#bVa&r' , b 'V{dMBVPkY4ZE^' , b 'V{dMBVPkY4ZE|w' , b 'V{dMBVPkY4XlZQ' , b 'V{dMBVPkY4Xk~H' , b 'cXDZTWguv2Z2' , b 'cXDZTWguu}as' , b 'bY*ySAZTfA' , b 'bY*ySAZTTB' ] monetWords_raw = [ b 'aB^>EX><' , b 'Wnpq|' , b 'X&`N3WMu' , b 'ZDC|(AZ=v' ] monetStrings_raw = [ b 'b#r6' , b 'Wp#3I' , b 'Bm' , b '!lM' , b ';)1L' , b 'Vsv8' ] salutations_raw = [ b 'ZE^' , b 'ZE|w' , b 'ZE{>L' , b 'ZE|y5E&' , b 'ZF2' , b 'ZF4R' , b 'Wq5F9a&!' ] nakedNamePre_raw = [ b 'cWHEJ' , b 'VsdY5WpV' ] # Make Spam Thread Lists for x in threadWords_raw : threadWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in threadPhrases_raw : threadPhrases . append ( b64decode ( x ) . decode ( utf_16 )) for x in monetWords_raw : monetWords . append ( b64decode ( x ) . decode ( utf_16 )) for x in monetStrings_raw : monetStrings . append ( b64decode ( x ) . decode ( utf_16 )) for x in salutations_raw : salutations . append ( b64decode ( x ) . decode ( utf_16 )) for x in nakedNamePre_raw : nakedNamePre . append ( b64decode ( x ) . decode ( utf_16 )) # Compile Thread Detection Regex salutationString = '|' . join ( salutations ) nakedNameString = '|' . join ( nakedNamePre ) nameRegex = re . compile ( f ' \\\\ b( { salutationString } )\\s+([a-zA-Z]+\\.?)\\s+([a-zA-Z]+)' ) nakedNameRegex = re . compile ( f ' \\\\ b( { nakedNameString } )\\s+([a-zA-Z]+\\.?)\\s+([a-zA-Z]+)' ) cashRegex = re . compile ( r \"^(\\$|\u00a3|\u20ac)?(\\d+|\\d{1,3}(,\\d {3} )*)(\\.\\d+)?(\\$|\u00a3|\u20ac|k| ?usd| ?eur| ?btc)?$\" ) print ( \" Loading Filters [====== ]\" , end = \" \\r \" ) # Compile regex with upper case, otherwise many false positive character matches bufferChars = r \"*_~|`[]()'-.\u2022,\" compiledRegexDict [ 'bufferChars' ] = bufferChars bufferMatch , addBuffers = \" \\\\ *_~|` \\\\ - \\\\ ._\" , re . escape ( bufferChars ) # Add 'buffer' chars usernameConfuseRegex = re . compile ( confusable_regex ( miscData . channelOwnerName )) m = bufferMatch a = addBuffers for word in usernameBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameBlackWords' ] . append ([ word , value ]) for word in usernameNovidBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameNovidBlackWords' ] . append ([ word , value ]) for word in blackAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'blackAdWords' ] . append ([ word , value ]) for word in redAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'redAdWords' ] . append ([ word , value ]) for word in yellowAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'yellowAdWords' ] . append ([ word , value ]) for word in exactRedAdWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = False )) compiledRegexDict [ 'exactRedAdWords' ] . append ([ word , value ]) print ( \" Loading Filters [======== ]\" , end = \" \\r \" ) for word in usernameRedWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameRedWords' ] . append ([ word , value ]) for word in textObfuBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'textObfuBlackWords' ] . append ([ word , value ]) for word in usernameObfuBlackWords : value = re . compile ( confusable_regex ( word . upper (), include_character_padding = True ) . replace ( m , a )) compiledRegexDict [ 'usernameObfuBlackWords' ] . append ([ word , value ]) for word in textExactBlackWords : compiledRegexDict [ 'textExactBlackWords' ] . append ( word ) for word in textUpLowBlackWords : compiledRegexDict [ 'textUpLowBlackWords' ] . append ( word ) print ( \" Loading Filters [============== ]\" , end = \" \\r \" ) # Prepare All-domain Regex Expression prepString = \"\\.(\" first = True for extension in rootDomainList : if first == True : prepString += extension first = False else : prepString = prepString + \"|\" + extension sensitivePrepString = prepString + \")\" prepString = prepString + \")\\/\" rootDomainRegex = re . compile ( prepString ) sensitiveRootDomainRegex = re . compile ( sensitivePrepString ) print ( \" Loading Filters [=================== ]\" , end = \" \\r \" ) spamListExpressionsList = [] # Prepare spam domain regex for domain in spamDomainsList : spamListExpressionsList . append ( confusable_regex ( domain . upper () . replace ( \".\" , \"\u26ab\" ), include_character_padding = False ) . replace ( \"(?:\u26ab)\" , \"(?:[^a-zA-Z0-9 ]{1,2})\" )) for account in spamAccountsList : spamListExpressionsList . append ( confusable_regex ( account . upper (), include_character_padding = True ) . replace ( m , a )) # for thread in spamThreadsList: # spamListExpressionsList.append(confusable_regex(thread.upper(), include_character_padding=True).replace(m, a)) print ( \" Loading Filters [====================== ]\" , end = \" \\r \" ) spamListCombinedRegex = re . compile ( '|' . join ( spamListExpressionsList )) # Prepare Multi Language Detection turkish = '\u00c7\u00e7\u015e\u015f\u011e\u011f\u0130' germanic = '\u1e9e\u00df\u00c4\u00e4' cyrillic = \"\u0433\u0434\u0436\u0437\u043a\u043b\u043c\u043d\u043f\u0440\u0441\u0442\u0444\u0445\u0446\u0447\u0448\u0449\u044b\u044d\u044e\u044f\u044a\u044c\" japanese = '\u30a1\u30a2\u30a3\u30a4\u30a5\u30a6\u30a7\u30a8\u30a9\u30aa\u30ab\u30ac\u30ad\u30ae\u30af\u30b0\u30b1\u30b2\u30b3\u30b4\u30b5\u30b6\u30b7\u30b8\u30b9\u30ba\u30bb\u30bc\u30bd\u30be\u30bf\u30c0\u30c1\u30c2\u30c6\u30c7\u30c8\u30c9\u30ca\u30cb\u30cc\u30cd\u30ce\u30cf\u30d0\u30d1\u30d2\u30d3\u30d4\u30d5\u30d6\u30d7\u30d8\u30d9\u30da\u30db\u30dc\u30dd\u30de\u30df\u30e0\u30e1\u30e2\u30e3\u30e4\u30e5\u30e6\u30e7\u30e8\u30e9\u30ea\u30eb\u30ec\u30ed\u30ee\u30ef\u30f0\u30f1\u30f2\u30f3\u30f4\u30f5\u30f6\u30f7\u30f8\u30f9\u30fa\u30fc\u30fd\u30fe\u30ff\u3041\u3042\u3043\u3044\u3045\u3046\u3047\u3048\u3049\u304a\u304b\u304c\u304d\u304e\u3050\u3051\u3052\u3053\u3054\u3055\u3056\u3057\u3058\u3059\u305a\u305b\u305c\u305d\u305e\u305f\u3060\u3061\u3062\u3063\u3064\u3065\u3066\u3067\u3068\u3069\u306a\u306b\u306c\u306d\u306e\u306f\u3070\u3071\u3072\u3073\u3074\u3075\u3076\u3077\u3078\u3079\u307a\u307b\u307c\u307d\u307e\u307f\u3080\u3081\u3082\u3083\u3084\u3085\u3086\u3087\u3088\u3089\u308a\u308b\u308c\u308d\u308e\u308f\u3090\u3091\u3092\u3093\u3094\u3095\u3096\u309d\u309e\u309f' languages = [[ 'turkish' , turkish , []], [ 'germanic' , germanic , []], [ 'cyrillic' , cyrillic , []], [ 'japanese' , japanese , []]] for item in languages : item [ 2 ] = make_char_set ( item [ 1 ]) print ( \" Loading Filters [============================ ]\" , end = \" \\r \" ) threadFiltersDict = { 'threadWords' : threadWords , 'threadPhrases' : threadPhrases , 'monetWords' : monetWords , 'monetStrings' : monetStrings , 'nameRegex' : nameRegex , 'nakedNameRegex' : nakedNameRegex , 'cashRegex' : cashRegex } filterSettings = { 'spammerNumbersSet' : spammerNumbersSet , 'compiledNumRegex' : compiledNumRegex , 'minNumbersMatchCount' : minNumbersMatchCount , #'usernameBlackCharsSet': usernameBlackCharsSet, 'spamGenEmojiSet' : spamGenEmojiSet , 'redAdEmojiSet' : redAdEmojiSet , 'yellowAdEmojiSet' : yellowAdEmojiSet , 'hrtSet' : hrtSet , 'lowAlSet' : lowAlSet , 'rootDomainRegex' : rootDomainRegex , 'compiledRegexDict' : compiledRegexDict , 'usernameConfuseRegex' : usernameConfuseRegex , 'languages' : languages , 'sensitive' : sensitive , 'sensitiveRootDomainRegex' : sensitiveRootDomainRegex , 'unicodeCategoriesStrip' : unicodeCategoriesStrip , 'spamListCombinedRegex' : spamListCombinedRegex , 'threadFiltersDict' : threadFiltersDict } print ( \" \" ) # Erases line that says \"loading filters\" return filterSettings , None","title":"prepare_filter_mode_smart()"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.prepare_filter_mode_strings","text":"prepare_filter_mode_strings ( scanMode , filterMode , config ) Source code in Scripts/prepare_modes.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def prepare_filter_mode_strings ( scanMode , filterMode , config ): if filterMode == \"Username\" : whatToScanMsg = \"Usernames\" elif filterMode == \"Text\" : whatToScanMsg = \"Comment Text\" elif filterMode == \"NameAndText\" : whatToScanMsg = \"Usernames and Comment Text\" if config [ 'strings_to_filter' ] != \"ask\" : print ( \"Strings to filter obtained from config file.\" ) pass else : print ( f \" \\n Paste or type in a list of any { F . YELLOW } comma separated strings { S . R } you want to search for in { whatToScanMsg } . (Not case sensitive)\" ) print ( \" >Note: If the text you paste includes special characters or emojis, they might not display correctly here, but it WILL still search them fine.\" ) print ( \" Example Input: whatsapp, whatever multiple words, investment\" ) validEntry = False validConfigSetting = True while validEntry == False : if validConfigSetting == True and config and config [ 'strings_to_filter' ] != \"ask\" : inputString = config [ 'strings_to_filter' ] bypass = True else : bypass = False inputString = input ( \"Input Here: \" ) if str ( inputString ) . lower () == \"x\" : return \"MainMenu\" , None # Convert comma separated string into list with function, then check against current user's name filterStringList = utils . string_to_list ( inputString , lower = True ) if len ( filterStringList ) > 0 : validEntry = True else : validConfigSetting = False if validEntry == True : if config [ 'strings_to_filter' ] != \"ask\" : pass else : print ( f \" { whatToScanMsg } will be scanned for { F . MAGENTA } ANY { S . R } of the following strings:\" ) print ( filterStringList ) userChoice = choice ( \"Begin scanning? \" , bypass ) if userChoice == True : validEntry = True elif userChoice == False : validEntry = False elif userChoice == None : return \"MainMenu\" , None return filterStringList , None","title":"prepare_filter_mode_strings()"},{"location":"reference/Scripts/prepare_modes/#Scripts.prepare_modes.recover_deleted_comments","text":"recover_deleted_comments ( config ) Source code in Scripts/prepare_modes.py 529 530 531 532 533 534 535 536 537 538 539 540 def recover_deleted_comments ( config ): print ( f \" \\n\\n -------------------- { F . LIGHTGREEN_EX } Comment Recovery Mode { S . R } -------------------- \\n \" ) print ( \"> Believe it or not, the YouTube API actually allows you to re-instate \\\" deleted \\\" comments.\" ) print ( f \"> This is { F . YELLOW } only possible if you have stored the comment IDs { S . R } of the deleted comments, \\n such as { F . YELLOW } having kept the log file { S . R } of that session.\" ) print ( \"> If you don't have the comment IDs you can't recover the comments, and there is no way to find them. \\n \" ) recoveryList = files . parse_comment_list ( config , recovery = True ) if recoveryList == \"MainMenu\" : return \"MainMenu\" operations . delete_found_comments ( commentsList = recoveryList , banChoice = False , deletionMode = \"published\" , recoveryMode = True ) operations . check_recovered_comments ( commentsList = recoveryList )","title":"recover_deleted_comments()"},{"location":"reference/Scripts/shared_imports/","text":"RESOURCES_FOLDER_NAME module-attribute \u00b6 RESOURCES_FOLDER_NAME = 'SpamPurge_Resources' __all__ module-attribute \u00b6 __all__ = [ 'os' , 'sys' , 're' , 'traceback' , 'F' , 'B' , 'S' , 'init' , 'RESOURCES_FOLDER_NAME' ]","title":"shared_imports"},{"location":"reference/Scripts/shared_imports/#Scripts.shared_imports.RESOURCES_FOLDER_NAME","text":"RESOURCES_FOLDER_NAME = 'SpamPurge_Resources'","title":"RESOURCES_FOLDER_NAME"},{"location":"reference/Scripts/shared_imports/#Scripts.shared_imports.__all__","text":"__all__ = [ 'os' , 'sys' , 're' , 'traceback' , 'F' , 'B' , 'S' , 'init' , 'RESOURCES_FOLDER_NAME' ]","title":"__all__"},{"location":"reference/Scripts/utils/","text":"check_list_against_string \u00b6 check_list_against_string ( listInput , stringInput , caseSensitive = False ) Source code in Scripts/utils.py 82 83 84 85 86 87 88 89 def check_list_against_string ( listInput , stringInput , caseSensitive = False ): if caseSensitive == False : stringInput = stringInput . lower () listInput = [ item . lower () for item in listInput ] if any ( x in stringInput for x in listInput ): return True else : return False choice \u00b6 choice ( message = '' , bypass = False ) Source code in Scripts/utils.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def choice ( message = \"\" , bypass = False ): if bypass == True : return True # While loop until valid input valid = False while valid == False : response = input ( \" \\n \" + message + f \" ( { F . LIGHTCYAN_EX } y { S . R } / { F . LIGHTRED_EX } n { S . R } ): \" ) . strip () if response == \"Y\" or response == \"y\" : return True elif response == \"N\" or response == \"n\" : return False elif response == \"X\" or response == \"x\" : return None else : print ( \" \\n Invalid Input. Enter Y or N -- Or enter X to return to main menu.\" ) expand_ranges \u00b6 expand_ranges ( stringInput ) Source code in Scripts/utils.py 133 134 135 136 137 138 139 140 141 142 143 def expand_ranges ( stringInput ): return re . sub ( r '(\\d+)-(\\d+)' , lambda match : ',' . join ( str ( i ) for i in range ( int ( match . group ( 1 )), int ( match . group ( 2 )) + 1 ) ), stringInput ) get_video_title \u00b6 get_video_title ( current , video_id ) Source code in Scripts/utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def get_video_title ( current , video_id ): if video_id in current . vidTitleDict . keys (): title = current . vidTitleDict [ video_id ] elif current . errorOccurred == False : try : results = auth . YOUTUBE . videos () . list ( part = \"snippet\" , id = video_id , fields = \"items/snippet/title\" , maxResults = 1 ) . execute () except HttpError as hx : traceback . print_exc () print_http_error_during_scan ( hx ) print_error_title_fetch () current . errorOccurred = True return \"[Unavailable]\" except Exception as ex : traceback . print_exc () print_exception_during_scan ( ex ) print_error_title_fetch () current . errorOccurred = True return \"[Unavailable]\" if results [ 'items' ]: title = results [ \"items\" ][ 0 ][ \"snippet\" ][ \"title\" ] current . vidTitleDict [ video_id ] = title elif ( len ( video_id ) == 26 or len ( video_id ) == 36 ) and video_id [ 0 : 2 ] == \"Ug\" : title = \"[Community Post - No Title]\" current . vidTitleDict [ video_id ] = title else : title = \"[Title Unavailable]\" current . vidTitleDict [ video_id ] = title else : title = \"[Title Unavailable]\" return title make_char_set \u00b6 make_char_set ( stringInput , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ) Source code in Scripts/utils.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def make_char_set ( stringInput , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ): # Optional lists of characters to strip from string translateDict = {} charsToStrip = \" \" if stripLettersNumbers == True : numbersLettersChars = ( \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" ) charsToStrip += numbersLettersChars if stripKeyboardSpecialChars == True : keyboardSpecialChars = ( \"!@#$%^&*()_+-=[]\\{\\}|;':,./<>?`~\" ) charsToStrip += keyboardSpecialChars if stripPunctuation == True : punctuationChars = ( \"!? \\\" .,;:'-/()\" ) charsToStrip += punctuationChars # Adds characters to dictionary to use with translate to remove these characters for c in charsToStrip : translateDict [ ord ( c )] = None translateDict [ ord ( \" \\ufe0f \" )] = None # Strips invisible varation selector for emojis # Removes charsToStrip from string stringInput = stringInput . translate ( translateDict ) listedInput = list ( stringInput ) return set ( filter ( None , listedInput )) print_break_finished \u00b6 print_break_finished ( scanMode ) Source code in Scripts/utils.py 199 200 201 202 203 204 205 206 207 def print_break_finished ( scanMode ): print ( \"------------------------------------------------\" ) print ( f \" \\n { F . LIGHTRED_EX } [!] Fatal Error Occurred During Scan! { F . BLACK }{ B . LIGHTRED_EX } Read the important info below! { S . R } \" ) print ( f \" \\n Program must skip the rest of the scan. { F . LIGHTGREEN_EX } Comments already scanned can still be used to create a log file (if you choose) { S . R } \" ) print ( f \" > You won't be able to delete/hide any comments like usual, but you can { F . LIGHTMAGENTA_EX } exclude users before saving the log file { S . R } \" ) print ( f \" > Then, you can { F . LIGHTGREEN_EX } delete the comments later { S . R } using the { F . YELLOW } mode that removes comments using a pre-existing list { S . R } \" ) if scanMode == \"entireChannel\" : print ( f \" { F . RED } NOTE: { S . R } Because of the scanning mode (entire channel) the log will be missing the video IDs and video names.\" ) input ( \" \\n Press Enter to continue...\" ) print_error_title_fetch \u00b6 print_error_title_fetch () Source code in Scripts/utils.py 209 210 211 212 213 214 215 def print_error_title_fetch (): print ( \"--------------------------------------------------------------------------------------------------------------------------\" ) print ( f \" \\n { F . BLACK }{ B . RED } ERROR OCCURRED { S . R } While Fetching Video Title... { F . BLACK }{ B . LIGHTRED_EX } READ THE INFO BELOW { S . R } \" ) print ( f \"Program will { F . LIGHTGREEN_EX } attempt to continue { S . R } , but the { F . YELLOW } video title may not be available { S . R } in the log file.\" ) print ( f \" > You won't be able to delete/hide any comments like usual, but you can { F . LIGHTMAGENTA_EX } exclude users before saving the log file { S . R } \" ) print ( f \" > Then, you can { F . LIGHTGREEN_EX } delete the comments later { S . R } using the { F . YELLOW } mode that removes comments using a pre-existing log file { S . R } \" ) input ( \" \\n Press Enter to continue...\" ) print_exception_during_scan \u00b6 print_exception_during_scan ( ex ) Source code in Scripts/utils.py 195 196 197 def print_exception_during_scan ( ex ): print ( \"------------------------------------------------\" ) print ( f \" { B . RED }{ F . WHITE } ERROR! { S . R } Error Message: \" + str ( ex )) print_exception_reason \u00b6 print_exception_reason ( reason ) Source code in Scripts/utils.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def print_exception_reason ( reason ): print ( \" Reason: \" + str ( reason )) if reason == \"processingFailure\" : print ( f \" \\n { F . LIGHTRED_EX } [!!] Processing Error { S . R } - Sometimes this error fixes itself. Try just running the program again. !!\" ) print ( \"This issue is often on YouTube's side, so if it keeps happening try again later.\" ) print ( \"(This also occurs if you try deleting comments on someone elses video, which is not possible.)\" ) elif reason == \"commentsDisabled\" : print ( f \" \\n { F . LIGHTRED_EX } [!] Error: { S . R } Comments are disabled on this video. This error can also occur if scanning a live stream.\" ) elif reason == \"quotaExceeded\" : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } You have exceeded the YouTube API quota. To do more scanning you must wait until the quota resets.\" ) print ( \" > There is a daily limit of 10,000 units/day, which works out to around reporting 10,000 comments/day.\" ) print ( \" > You can check your quota by searching 'quota' in the google cloud console.\" ) print ( f \" { F . YELLOW } Solutions: Either wait until tomorrow, or create additional projects in the cloud console. { S . R } \" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" ) print_http_error_during_scan \u00b6 print_http_error_during_scan ( hx ) Source code in Scripts/utils.py 186 187 188 189 190 191 192 193 def print_http_error_during_scan ( hx ): print ( \"------------------------------------------------\" ) print ( f \" { B . RED }{ F . WHITE } ERROR! { S . R } Error Message: \" + str ( hx )) if hx . status_code : print ( \"Status Code: \" + str ( hx . status_code )) if hx . error_details [ 0 ][ \"reason\" ]: # If error reason is available, print it reason = str ( hx . error_details [ 0 ][ \"reason\" ]) print_exception_reason ( reason ) process_spammer_ids \u00b6 process_spammer_ids ( rawString ) Source code in Scripts/utils.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def process_spammer_ids ( rawString ): inputList = [] # For list of unvalidated inputted items IDList = [] # For list of validated channel IDs, converted from inputList of spammer IDs - Separate to allow printing original invalid input if necessary inputList = rawString . split ( \",\" ) # Split spammer IDs / Links by commas # Remove whitespace from each list item for i in range ( len ( inputList )): inputList [ i ] = inputList [ i ] . strip () inputList = list ( filter ( None , inputList )) # Remove empty strings from list IDList = list ( inputList ) # Need to use list() instead of just setting equal so each list is separately affected, otherwise same pointer # Validate each ID in list for i in range ( len ( inputList )): valid , IDList [ i ], channelTitle = validation . validate_channel_id ( inputList [ i ]) if valid == False : print ( f \" { B . RED }{ F . BLACK } Invalid { S . R } Channel ID or Link: \" + str ( inputList [ i ]) + \" \\n \" ) return False , None return True , IDList string_to_list \u00b6 string_to_list ( rawString , lower = False ) Source code in Scripts/utils.py 94 95 96 97 98 99 100 101 102 103 104 105 def string_to_list ( rawString , lower = False ): if lower == True : rawString = rawString . lower () # Remove whitespace newList = rawString . split ( \",\" ) for i in range ( len ( newList )): newList [ i ] = newList [ i ] . strip () # Remove empty strings from list newList = list ( filter ( None , newList )) return newList","title":"utils"},{"location":"reference/Scripts/utils/#Scripts.utils.check_list_against_string","text":"check_list_against_string ( listInput , stringInput , caseSensitive = False ) Source code in Scripts/utils.py 82 83 84 85 86 87 88 89 def check_list_against_string ( listInput , stringInput , caseSensitive = False ): if caseSensitive == False : stringInput = stringInput . lower () listInput = [ item . lower () for item in listInput ] if any ( x in stringInput for x in listInput ): return True else : return False","title":"check_list_against_string()"},{"location":"reference/Scripts/utils/#Scripts.utils.choice","text":"choice ( message = '' , bypass = False ) Source code in Scripts/utils.py 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def choice ( message = \"\" , bypass = False ): if bypass == True : return True # While loop until valid input valid = False while valid == False : response = input ( \" \\n \" + message + f \" ( { F . LIGHTCYAN_EX } y { S . R } / { F . LIGHTRED_EX } n { S . R } ): \" ) . strip () if response == \"Y\" or response == \"y\" : return True elif response == \"N\" or response == \"n\" : return False elif response == \"X\" or response == \"x\" : return None else : print ( \" \\n Invalid Input. Enter Y or N -- Or enter X to return to main menu.\" )","title":"choice()"},{"location":"reference/Scripts/utils/#Scripts.utils.expand_ranges","text":"expand_ranges ( stringInput ) Source code in Scripts/utils.py 133 134 135 136 137 138 139 140 141 142 143 def expand_ranges ( stringInput ): return re . sub ( r '(\\d+)-(\\d+)' , lambda match : ',' . join ( str ( i ) for i in range ( int ( match . group ( 1 )), int ( match . group ( 2 )) + 1 ) ), stringInput )","title":"expand_ranges()"},{"location":"reference/Scripts/utils/#Scripts.utils.get_video_title","text":"get_video_title ( current , video_id ) Source code in Scripts/utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def get_video_title ( current , video_id ): if video_id in current . vidTitleDict . keys (): title = current . vidTitleDict [ video_id ] elif current . errorOccurred == False : try : results = auth . YOUTUBE . videos () . list ( part = \"snippet\" , id = video_id , fields = \"items/snippet/title\" , maxResults = 1 ) . execute () except HttpError as hx : traceback . print_exc () print_http_error_during_scan ( hx ) print_error_title_fetch () current . errorOccurred = True return \"[Unavailable]\" except Exception as ex : traceback . print_exc () print_exception_during_scan ( ex ) print_error_title_fetch () current . errorOccurred = True return \"[Unavailable]\" if results [ 'items' ]: title = results [ \"items\" ][ 0 ][ \"snippet\" ][ \"title\" ] current . vidTitleDict [ video_id ] = title elif ( len ( video_id ) == 26 or len ( video_id ) == 36 ) and video_id [ 0 : 2 ] == \"Ug\" : title = \"[Community Post - No Title]\" current . vidTitleDict [ video_id ] = title else : title = \"[Title Unavailable]\" current . vidTitleDict [ video_id ] = title else : title = \"[Title Unavailable]\" return title","title":"get_video_title()"},{"location":"reference/Scripts/utils/#Scripts.utils.make_char_set","text":"make_char_set ( stringInput , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ) Source code in Scripts/utils.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def make_char_set ( stringInput , stripLettersNumbers = False , stripKeyboardSpecialChars = False , stripPunctuation = False ): # Optional lists of characters to strip from string translateDict = {} charsToStrip = \" \" if stripLettersNumbers == True : numbersLettersChars = ( \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" ) charsToStrip += numbersLettersChars if stripKeyboardSpecialChars == True : keyboardSpecialChars = ( \"!@#$%^&*()_+-=[]\\{\\}|;':,./<>?`~\" ) charsToStrip += keyboardSpecialChars if stripPunctuation == True : punctuationChars = ( \"!? \\\" .,;:'-/()\" ) charsToStrip += punctuationChars # Adds characters to dictionary to use with translate to remove these characters for c in charsToStrip : translateDict [ ord ( c )] = None translateDict [ ord ( \" \\ufe0f \" )] = None # Strips invisible varation selector for emojis # Removes charsToStrip from string stringInput = stringInput . translate ( translateDict ) listedInput = list ( stringInput ) return set ( filter ( None , listedInput ))","title":"make_char_set()"},{"location":"reference/Scripts/utils/#Scripts.utils.print_break_finished","text":"print_break_finished ( scanMode ) Source code in Scripts/utils.py 199 200 201 202 203 204 205 206 207 def print_break_finished ( scanMode ): print ( \"------------------------------------------------\" ) print ( f \" \\n { F . LIGHTRED_EX } [!] Fatal Error Occurred During Scan! { F . BLACK }{ B . LIGHTRED_EX } Read the important info below! { S . R } \" ) print ( f \" \\n Program must skip the rest of the scan. { F . LIGHTGREEN_EX } Comments already scanned can still be used to create a log file (if you choose) { S . R } \" ) print ( f \" > You won't be able to delete/hide any comments like usual, but you can { F . LIGHTMAGENTA_EX } exclude users before saving the log file { S . R } \" ) print ( f \" > Then, you can { F . LIGHTGREEN_EX } delete the comments later { S . R } using the { F . YELLOW } mode that removes comments using a pre-existing list { S . R } \" ) if scanMode == \"entireChannel\" : print ( f \" { F . RED } NOTE: { S . R } Because of the scanning mode (entire channel) the log will be missing the video IDs and video names.\" ) input ( \" \\n Press Enter to continue...\" )","title":"print_break_finished()"},{"location":"reference/Scripts/utils/#Scripts.utils.print_error_title_fetch","text":"print_error_title_fetch () Source code in Scripts/utils.py 209 210 211 212 213 214 215 def print_error_title_fetch (): print ( \"--------------------------------------------------------------------------------------------------------------------------\" ) print ( f \" \\n { F . BLACK }{ B . RED } ERROR OCCURRED { S . R } While Fetching Video Title... { F . BLACK }{ B . LIGHTRED_EX } READ THE INFO BELOW { S . R } \" ) print ( f \"Program will { F . LIGHTGREEN_EX } attempt to continue { S . R } , but the { F . YELLOW } video title may not be available { S . R } in the log file.\" ) print ( f \" > You won't be able to delete/hide any comments like usual, but you can { F . LIGHTMAGENTA_EX } exclude users before saving the log file { S . R } \" ) print ( f \" > Then, you can { F . LIGHTGREEN_EX } delete the comments later { S . R } using the { F . YELLOW } mode that removes comments using a pre-existing log file { S . R } \" ) input ( \" \\n Press Enter to continue...\" )","title":"print_error_title_fetch()"},{"location":"reference/Scripts/utils/#Scripts.utils.print_exception_during_scan","text":"print_exception_during_scan ( ex ) Source code in Scripts/utils.py 195 196 197 def print_exception_during_scan ( ex ): print ( \"------------------------------------------------\" ) print ( f \" { B . RED }{ F . WHITE } ERROR! { S . R } Error Message: \" + str ( ex ))","title":"print_exception_during_scan()"},{"location":"reference/Scripts/utils/#Scripts.utils.print_exception_reason","text":"print_exception_reason ( reason ) Source code in Scripts/utils.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def print_exception_reason ( reason ): print ( \" Reason: \" + str ( reason )) if reason == \"processingFailure\" : print ( f \" \\n { F . LIGHTRED_EX } [!!] Processing Error { S . R } - Sometimes this error fixes itself. Try just running the program again. !!\" ) print ( \"This issue is often on YouTube's side, so if it keeps happening try again later.\" ) print ( \"(This also occurs if you try deleting comments on someone elses video, which is not possible.)\" ) elif reason == \"commentsDisabled\" : print ( f \" \\n { F . LIGHTRED_EX } [!] Error: { S . R } Comments are disabled on this video. This error can also occur if scanning a live stream.\" ) elif reason == \"quotaExceeded\" : print ( f \" \\n { F . LIGHTRED_EX } Error: { S . R } You have exceeded the YouTube API quota. To do more scanning you must wait until the quota resets.\" ) print ( \" > There is a daily limit of 10,000 units/day, which works out to around reporting 10,000 comments/day.\" ) print ( \" > You can check your quota by searching 'quota' in the google cloud console.\" ) print ( f \" { F . YELLOW } Solutions: Either wait until tomorrow, or create additional projects in the cloud console. { S . R } \" ) print ( f \" > Read more about the quota limits for this app here: { F . YELLOW } TJoe.io/api-limit-info { S . R } \" )","title":"print_exception_reason()"},{"location":"reference/Scripts/utils/#Scripts.utils.print_http_error_during_scan","text":"print_http_error_during_scan ( hx ) Source code in Scripts/utils.py 186 187 188 189 190 191 192 193 def print_http_error_during_scan ( hx ): print ( \"------------------------------------------------\" ) print ( f \" { B . RED }{ F . WHITE } ERROR! { S . R } Error Message: \" + str ( hx )) if hx . status_code : print ( \"Status Code: \" + str ( hx . status_code )) if hx . error_details [ 0 ][ \"reason\" ]: # If error reason is available, print it reason = str ( hx . error_details [ 0 ][ \"reason\" ]) print_exception_reason ( reason )","title":"print_http_error_during_scan()"},{"location":"reference/Scripts/utils/#Scripts.utils.process_spammer_ids","text":"process_spammer_ids ( rawString ) Source code in Scripts/utils.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def process_spammer_ids ( rawString ): inputList = [] # For list of unvalidated inputted items IDList = [] # For list of validated channel IDs, converted from inputList of spammer IDs - Separate to allow printing original invalid input if necessary inputList = rawString . split ( \",\" ) # Split spammer IDs / Links by commas # Remove whitespace from each list item for i in range ( len ( inputList )): inputList [ i ] = inputList [ i ] . strip () inputList = list ( filter ( None , inputList )) # Remove empty strings from list IDList = list ( inputList ) # Need to use list() instead of just setting equal so each list is separately affected, otherwise same pointer # Validate each ID in list for i in range ( len ( inputList )): valid , IDList [ i ], channelTitle = validation . validate_channel_id ( inputList [ i ]) if valid == False : print ( f \" { B . RED }{ F . BLACK } Invalid { S . R } Channel ID or Link: \" + str ( inputList [ i ]) + \" \\n \" ) return False , None return True , IDList","title":"process_spammer_ids()"},{"location":"reference/Scripts/utils/#Scripts.utils.string_to_list","text":"string_to_list ( rawString , lower = False ) Source code in Scripts/utils.py 94 95 96 97 98 99 100 101 102 103 104 105 def string_to_list ( rawString , lower = False ): if lower == True : rawString = rawString . lower () # Remove whitespace newList = rawString . split ( \",\" ) for i in range ( len ( newList )): newList [ i ] = newList [ i ] . strip () # Remove empty strings from list newList = list ( filter ( None , newList )) return newList","title":"string_to_list()"},{"location":"reference/Scripts/validation/","text":"validate_channel_id \u00b6 validate_channel_id ( inputted_channel ) Source code in Scripts/validation.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def validate_channel_id ( inputted_channel ): isolatedChannelID = \"Invalid\" # Default value inputted_channel = inputted_channel . strip () notChannelList = [ '?v' , 'v=' , '/embed/' , '/vi/' , '?feature=' , '/v/' , '/e/' ] # Check if link is actually a video link / ID isVideo = validate_video_id ( inputted_channel , silent = True ) if isVideo [ 0 ] == True : print ( f \" \\n { F . BLACK }{ B . LIGHTRED_EX } Invalid Channel ID / Link! { S . R } Looks like you entered a Video ID / Link by mistake.\" ) return False , None , None # Get id from channel link if \"/channel/\" in inputted_channel : startIndex = inputted_channel . rindex ( \"/\" ) + 1 endIndex = len ( inputted_channel ) if \"?\" in inputted_channel : endIndex = inputted_channel . rindex ( \"?\" ) if startIndex < endIndex and endIndex <= len ( inputted_channel ): isolatedChannelID = inputted_channel [ startIndex : endIndex ] elif \"/c/\" in inputted_channel or \"/user/\" in inputted_channel : if \"/c/\" in inputted_channel : startIndex = inputted_channel . rindex ( \"/c/\" ) + 3 #Start index at at character after /c/ elif \"/user/\" in inputted_channel : startIndex = inputted_channel . rindex ( \"/user/\" ) + 6 endIndex = len ( inputted_channel ) # If there is a / after the username scoot the endIndex over if startIndex != inputted_channel . rindex ( \"/\" ) + 1 : endIndex = inputted_channel . rindex ( \"/\" ) # endIndex is now at the last / if startIndex < endIndex and endIndex <= len ( inputted_channel ): customURL = inputted_channel [ startIndex : endIndex ] response = auth . YOUTUBE . search () . list ( part = \"snippet\" , q = customURL , maxResults = 1 ) . execute () if response . get ( \"items\" ): isolatedChannelID = response . get ( \"items\" )[ 0 ][ \"snippet\" ][ \"channelId\" ] # Get channel ID from custom channel URL username # Handle legacy style custom URL (no /c/ for custom URL) elif not any ( x in inputted_channel for x in notChannelList ) and ( inputted_channel . lower () . startswith ( \"youtube.com/\" ) or str ( urlparse ( inputted_channel ) . hostname ) . lower () == \"youtube.com\" ): startIndex = inputted_channel . rindex ( \"/\" ) + 1 endIndex = len ( inputted_channel ) if startIndex < endIndex and endIndex <= len ( inputted_channel ): customURL = inputted_channel [ startIndex : endIndex ] # First check if actually video ID (video ID regex expression from: https://webapps.stackexchange.com/a/101153) if re . match ( r '[0-9A-Za-z_-] {10} [048AEIMQUYcgkosw]' , customURL ): print ( f \" { F . LIGHTRED_EX } Invalid Channel ID / Link! { S . R } Did you enter a video ID / link by mistake?\" ) return False , None , None response = auth . YOUTUBE . search () . list ( part = \"snippet\" , q = customURL , maxResults = 1 ) . execute () if response . get ( \"items\" ): isolatedChannelID = response . get ( \"items\" )[ 0 ][ \"snippet\" ][ \"channelId\" ] # Get channel ID from custom channel URL username # Channel ID regex expression from: https://webapps.stackexchange.com/a/101153 elif re . match ( r 'UC[0-9A-Za-z_-] {21} [AQgw]' , inputted_channel ): isolatedChannelID = inputted_channel else : print ( f \" \\n { B . RED }{ F . BLACK } Error: { S . R } Invalid Channel link or ID!\" ) return False , None , None if len ( isolatedChannelID ) == 24 and isolatedChannelID [ 0 : 2 ] == \"UC\" : response = auth . YOUTUBE . channels () . list ( part = \"snippet\" , id = isolatedChannelID ) . execute () if response [ 'items' ]: channelTitle = response [ 'items' ][ 0 ][ 'snippet' ][ 'title' ] return True , isolatedChannelID , channelTitle else : print ( f \" { F . LIGHTRED } Error { S . R } : Unable to Get Channel Title. Please check the channel ID.\" ) return False , None , None else : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Channel link or ID! { S . R } Channel IDs are 24 characters long and begin with 'UC'.\" ) return False , None , None validate_config_settings \u00b6 validate_config_settings ( config ) Source code in Scripts/validation.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 def validate_config_settings ( config ): print ( \" \\n Validating Config Settings...\" ) print ( \"----------------------------------------------------- \\n \" ) # Helper Functions def print_quit_and_report (): print ( f \" \\n If you think this is a bug or can't figure it out, report it on the GitHub page: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( \" \\n Press Enter to exit...\" ) sys . exit () def print_int_fail ( setting , value ): print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( \"It should probably be an integer. Check the possible values listed in the config file for that setting.\" ) print_quit_and_report () # Validation Functions # -------------------------------------------------------------------------------------- def simple_settings_check ( setting , value ): if setting in validSettingsDict : # A None value means it can be any string if validSettingsDict [ setting ] == None : return True # For settings that accept more than one value, check each elif isinstance ( value , str ) and \",\" in str ( value ): try : settingList = utils . string_to_list ( value ) for settingValue in settingList : if settingValue not in validSettingsDict [ setting ]: print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( f \"It looks like you tried to enter a list. Check if that setting accepts multiple values or if you entered an invalid value.\" ) print_quit_and_report () return True except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( \"It looks like you tried to enter a list. Check if that setting accepts multiple values or if you entered an invalid value.\" ) print_quit_and_report () elif value in validSettingsDict [ setting ]: return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( \"Check the config file to see valid possible values for that setting.\" ) print_quit_and_report () else : return None def validate_levenshtein ( value ): try : value = float ( value ) if value >= 0.0 and value <= 1.0 : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'levenshtein_distance': { str ( value ) } \" ) print ( \"It must be a number from 0 to 1!\" ) print_quit_and_report () except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'levenshtein_distance': { str ( value ) } \" ) print ( \"It must be a number from 0 to 1!\" ) print_quit_and_report () def validate_directory ( path ): if path == 'logs' : return True elif os . path . isdir ( path ): return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'log_path': { str ( path ) } \" ) print ( \"Make sure the folder exists!\" ) print_quit_and_report () def validate_encoding ( value ): try : codecs . lookup ( value ) return True except LookupError : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'json_encoding': { str ( value ) } \" ) print ( \"Make sure the encoding is valid!\" ) print_quit_and_report () def validate_videos_to_scan ( value ): if value == 'ask' : return True else : try : videoList = utils . string_to_list ( value ) except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'videos_to_scan': { str ( value ) } \" ) print ( \"Make sure it is either a single video ID / Link, or a comma separate list of them!\" ) print_quit_and_report () if len ( videoList ) > 0 : for video in videoList : if not validate_video_id ( video , basicCheck = True ): print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } There appears to be an invalid video ID or Link in setting 'videos_to_scan': { str ( value ) } \" ) print_quit_and_report () return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'videos_to_scan' (it may be empty!): { str ( value ) } \" ) print ( \"Make sure it is either a single video ID / Link, or a comma separate list of them!\" ) print_quit_and_report () def validate_channel_to_scan ( value ): if value == 'ask' or value == 'mine' : return True else : result , channelID , channelName = validate_channel_id ( value ) if result == False : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Config setting for 'channel_to_scan' appears invalid: { str ( value ) } \" ) print ( \"Make sure it is either a single channel ID or channel link. If it's a link, try using the channel ID instead.\" ) print_quit_and_report () else : return True def validate_channel_ids_to_filter ( value ): if value == 'ask' : return True else : try : channelList = utils . string_to_list ( value ) except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'channel_ids_to_filter': { str ( value ) } \" ) print ( \"Make sure it is either a single channel ID / Link, or a comma separate list of them!\" ) print_quit_and_report () for channel in channelList : if len ( channel ) != 24 or channel [ 0 : 2 ] != \"UC\" : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } There appears to be an invalid channel ID in setting 'channel_ids_to_filter': { str ( value ) } \" ) print ( \"A channel ID must be 24 charactres long and begin with 'UC'!\" ) print_quit_and_report () return True def validate_chars ( value ): if value == 'ask' : return True result = utils . make_char_set ( value , stripLettersNumbers = True , stripKeyboardSpecialChars = False , stripPunctuation = True ) if result : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'characters_to_filter': { str ( value ) } \" ) print ( \"For this mode, numbers, letters, and punctuation are removed. But there were no characters left to search!\" ) print_quit_and_report () def validate_strings ( value ): if value == 'ask' : return True try : result = utils . string_to_list ( value ) if len ( result ) > 0 : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'strings_to_filter': { str ( value ) } \" ) print ( \"The list appears empty! Make sure it is either a single string, or a comma separate list of them!\" ) print_quit_and_report () except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'strings_to_filter': { str ( value ) } \" ) print ( \"Make sure it is either a single string, or a comma separate list of them!\" ) print_quit_and_report () def validate_regex_setting ( value ): if value == 'ask' : return True isValid , expression = validate_regex ( value ) if isValid : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } The config setting 'regex_to_filter' does not appear to be valid: { str ( value ) } \" ) print ( \"Make sure it is a valid regular expresion! Example: [^ \\x00 - \\xFF ]\" ) print ( \"You can test them out on websites like regex101.com\" ) print_quit_and_report () # -------------------------------------------------------------------------------------- validSettingsDict = { 'use_this_config' : ( True , False , 'ask' ), 'this_config_description' : None , 'your_channel_id' : None , # None because will be checked right away anyway 'auto_check_update' : ( True , False ), 'release_channel' : ( 'all' , 'stable' ), 'skip_confirm_video' : ( True , False ), 'moderator_mode' : ( True , False ), 'auto_close' : ( True , False ), 'scan_mode' : ( 'ask' , 'chosenvideos' , 'recentvideos' , 'entirechannel' , 'communitypost' , 'recentcommunityposts' ), 'max_comments' : ( 'ask' ), # #'videos_to_scan': None, #'channel_to_scan': None, 'recent_videos_amount' : ( 'ask' ), # 'filter_mode' : ( 'ask' , 'id' , 'username' , 'text' , 'nameandtext' , 'autoascii' , 'autosmart' , 'sensitivesmart' ), 'filter_submode' : ( 'ask' , 'characters' , 'strings' , 'regex' ), #'channel_ids_to_filter': None, 'autoascii_sensitivity' : ( 'ask' , '1' , '2' , '3' ), #'characters_to_filter': None, #'strings_to_filter': None, #'regex_to_filter': None, 'detect_link_spam' : ( True , False ), 'detect_sub_challenge_spam' : ( True , False ), 'detect_spam_threads' : ( True , False ), 'duplicate_check_modes' : ( 'none' , 'id' , 'username' , 'text' , 'nameandtext' , 'autoascii' , 'autosmart' , 'sensitivesmart' ), #'levenshtein_distance': (), #'minimum_duplicates': None, 'skip_deletion' : ( True , False ), 'delete_without_reviewing' : ( True , False ), 'enable_ban' : ( 'ask' , False ), 'remove_all_author_comments' : ( 'ask' , True , False ), 'removal_type' : ( 'rejected' , 'heldforreview' , 'reportspam' ), 'whitelist_excluded' : ( 'ask' , True , False ), 'check_deletion_success' :( True , False ), 'enable_logging' : ( 'ask' , True , False ), #'log_path': None, 'log_mode' : ( 'rtf' , 'plaintext' ), 'json_log' : ( True , False ), #'json_encoding': None, 'json_extra_data' : ( True , False ), 'json_profile_picture' : ( False , 'default' , 'medium' , 'high' ), #'quota_limit': (), #'config_version': (), } # Settings that can or must contain an integer integerSettings = [ 'max_comments' , 'recent_videos_amount' , 'minimum_duplicates' , 'quota_limit' , 'config_version' ] # Dictionary of settings requiring specific checks, and the functions to validate them specialCheck = { 'levenshtein_distance' : validate_levenshtein , 'log_path' : validate_directory , 'json_encoding' : validate_encoding , 'videos_to_scan' : validate_videos_to_scan , 'channel_to_scan' : validate_channel_to_scan , 'channel_ids_to_filter' : validate_channel_ids_to_filter , 'characters_to_filter' : validate_chars , 'strings_to_filter' : validate_strings , 'regex_to_filter' : validate_regex_setting } # ADD CHECK FOR EMPTY STRING! for settingName , settingValue in config . items (): if settingValue == None or settingValue == '' : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } The config setting ' { settingName } ' appears empty!\" ) print ( \"Please go and add a valid setting value!\" ) print_quit_and_report () # Check integer value settings if settingName in integerSettings : try : int ( settingValue ) continue except ValueError : # Check if there is another valid value besides an integer if simple_settings_check ( settingName , settingValue ) == True : continue else : print_int_fail ( settingName , settingValue ) elif settingName in specialCheck : if specialCheck [ settingName ]( settingValue ) == True : continue # Check simple value settings else : result = simple_settings_check ( settingName , settingValue ) if result == True : continue elif result == None : print ( f \" \\n { B . RED }{ F . WHITE } WARNING! { S . R } An unknown setting was found: ' { settingName } ': { str ( settingValue ) } \" ) print ( f \"If you didn't add or change this setting in the config file, a validation check was probably forgotten to be created!\" ) print ( f \"Consider reporting it: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( f \" \\n It might not cause an issue, so press Enter to continue anyway...\" ) continue validate_post_id \u00b6 validate_post_id ( post_url ) Source code in Scripts/validation.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def validate_post_id ( post_url ): if \"/post/\" in post_url : startIndex = post_url . rindex ( \"/\" ) + 1 endIndex = len ( post_url ) elif \"/channel/\" in post_url and \"/community?\" in post_url and \"lb=\" in post_url : startIndex = post_url . rindex ( \"lb=\" ) + 3 endIndex = len ( post_url ) else : isolatedPostId = post_url try : if startIndex < endIndex and endIndex <= len ( post_url ): isolatedPostID = post_url [ startIndex : endIndex ] except : return False , None , None , None , None # Post IDs used to be shorter, but apparently now have a longer format if len ( isolatedPostID ) == 26 or len ( isolatedPostID ) == 36 : if isolatedPostID [ 0 : 2 ] == \"Ug\" : validatedPostUrl = \"https://www.youtube.com/post/\" + isolatedPostID postOwnerURL = get_post_channel_url ( isolatedPostID ) valid , postOwnerID , postOwnerUsername = validate_channel_id ( postOwnerURL ) return valid , isolatedPostID , validatedPostUrl , postOwnerID , postOwnerUsername else : return False , None , None , None , None validate_regex \u00b6 validate_regex ( regex_from_user ) Source code in Scripts/validation.py 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def validate_regex ( regex_from_user : str ): try : re . compile ( regex_from_user ) is_valid = True processedExpression = regex_from_user except re . error : try : re . compile ( re . escape ( regex_from_user )) is_valid = True processedExpression = re . escape ( regex_from_user ) except re . error : print ( \"Failed\" ) is_valid = False processedExpression = None return is_valid , processedExpression validate_video_id \u00b6 validate_video_id ( video_url_or_id , silent = False , pass_exception = False , basicCheck = False ) Source code in Scripts/validation.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def validate_video_id ( video_url_or_id , silent = False , pass_exception = False , basicCheck = False ): youtube_video_link_regex = r \"^\\s*(?P<video_url>(?:(?:https?:)?\\/\\/)?(?:(?:www|m)\\.)?(?:youtube\\.com|youtu.be)(?:\\/(?:[\\w\\-]+\\?v=|embed\\/|v\\/)?))?(?P<video_id>[\\w\\-] {11} )(?:(?(video_url)\\S+|$))?\\s*$\" match = re . match ( youtube_video_link_regex , video_url_or_id ) if match == None : if basicCheck == True : return False if silent == False : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Video link or ID! { S . R } Video IDs are 11 characters long.\" ) return False , None , None , None , None elif basicCheck == True : possibleVideoID = match . group ( 'video_id' ) if len ( possibleVideoID ) == 11 : return True else : try : possibleVideoID = match . group ( 'video_id' ) result = auth . YOUTUBE . videos () . list ( part = \"snippet,id,statistics\" , id = possibleVideoID , fields = 'items/id,items/snippet/channelId,items/snippet/channelTitle,items/statistics/commentCount,items/snippet/title' , ) . execute () if possibleVideoID == result [ 'items' ][ 0 ][ 'id' ]: channelID = result [ 'items' ][ 0 ][ 'snippet' ][ 'channelId' ] channelTitle = result [ \"items\" ][ 0 ][ \"snippet\" ][ \"channelTitle\" ] videoTitle = result [ \"items\" ][ 0 ][ \"snippet\" ][ \"title\" ] # When comments are disabled, the commentCount is not included in the response, requires catching KeyError try : commentCount = result [ 'items' ][ 0 ][ 'statistics' ][ 'commentCount' ] except KeyError : if pass_exception == True : # If the video has comments disabled, the commentCount is not included in the response, but the video is still valid return True , possibleVideoID , videoTitle , \"0\" , channelID , channelTitle traceback . print_exc () print ( \"--------------------------------------\" ) print ( f \" \\n { B . RED }{ F . WHITE } ERROR: { S . R } { F . RED } Unable to get comment count for video: { S . R } { possibleVideoID } | { videoTitle } \" ) print ( f \" \\n { F . YELLOW } Are comments disabled on this video? { S . R } If not, please report the bug and include the error info above.\" ) print ( f \" Bug Report Link: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( \" \\n Press Enter to return to the main menu...\" ) return \"MainMenu\" , \"MainMenu\" , \"MainMenu\" , \"MainMenu\" , \"MainMenu\" return True , possibleVideoID , videoTitle , commentCount , channelID , channelTitle else : if silent == False : print ( \"Something very odd happened. YouTube returned a video ID, but it is not equal to what was queried!\" ) return False , None , None , None , None except AttributeError : if silent == False : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Video link or ID! { S . R } Video IDs are 11 characters long.\" ) return False , None , None , None , None except IndexError : if silent == False : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Video link or ID! { S . R } Video IDs are 11 characters long.\" ) return False , None , None , None , None","title":"validation"},{"location":"reference/Scripts/validation/#Scripts.validation.validate_channel_id","text":"validate_channel_id ( inputted_channel ) Source code in Scripts/validation.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def validate_channel_id ( inputted_channel ): isolatedChannelID = \"Invalid\" # Default value inputted_channel = inputted_channel . strip () notChannelList = [ '?v' , 'v=' , '/embed/' , '/vi/' , '?feature=' , '/v/' , '/e/' ] # Check if link is actually a video link / ID isVideo = validate_video_id ( inputted_channel , silent = True ) if isVideo [ 0 ] == True : print ( f \" \\n { F . BLACK }{ B . LIGHTRED_EX } Invalid Channel ID / Link! { S . R } Looks like you entered a Video ID / Link by mistake.\" ) return False , None , None # Get id from channel link if \"/channel/\" in inputted_channel : startIndex = inputted_channel . rindex ( \"/\" ) + 1 endIndex = len ( inputted_channel ) if \"?\" in inputted_channel : endIndex = inputted_channel . rindex ( \"?\" ) if startIndex < endIndex and endIndex <= len ( inputted_channel ): isolatedChannelID = inputted_channel [ startIndex : endIndex ] elif \"/c/\" in inputted_channel or \"/user/\" in inputted_channel : if \"/c/\" in inputted_channel : startIndex = inputted_channel . rindex ( \"/c/\" ) + 3 #Start index at at character after /c/ elif \"/user/\" in inputted_channel : startIndex = inputted_channel . rindex ( \"/user/\" ) + 6 endIndex = len ( inputted_channel ) # If there is a / after the username scoot the endIndex over if startIndex != inputted_channel . rindex ( \"/\" ) + 1 : endIndex = inputted_channel . rindex ( \"/\" ) # endIndex is now at the last / if startIndex < endIndex and endIndex <= len ( inputted_channel ): customURL = inputted_channel [ startIndex : endIndex ] response = auth . YOUTUBE . search () . list ( part = \"snippet\" , q = customURL , maxResults = 1 ) . execute () if response . get ( \"items\" ): isolatedChannelID = response . get ( \"items\" )[ 0 ][ \"snippet\" ][ \"channelId\" ] # Get channel ID from custom channel URL username # Handle legacy style custom URL (no /c/ for custom URL) elif not any ( x in inputted_channel for x in notChannelList ) and ( inputted_channel . lower () . startswith ( \"youtube.com/\" ) or str ( urlparse ( inputted_channel ) . hostname ) . lower () == \"youtube.com\" ): startIndex = inputted_channel . rindex ( \"/\" ) + 1 endIndex = len ( inputted_channel ) if startIndex < endIndex and endIndex <= len ( inputted_channel ): customURL = inputted_channel [ startIndex : endIndex ] # First check if actually video ID (video ID regex expression from: https://webapps.stackexchange.com/a/101153) if re . match ( r '[0-9A-Za-z_-] {10} [048AEIMQUYcgkosw]' , customURL ): print ( f \" { F . LIGHTRED_EX } Invalid Channel ID / Link! { S . R } Did you enter a video ID / link by mistake?\" ) return False , None , None response = auth . YOUTUBE . search () . list ( part = \"snippet\" , q = customURL , maxResults = 1 ) . execute () if response . get ( \"items\" ): isolatedChannelID = response . get ( \"items\" )[ 0 ][ \"snippet\" ][ \"channelId\" ] # Get channel ID from custom channel URL username # Channel ID regex expression from: https://webapps.stackexchange.com/a/101153 elif re . match ( r 'UC[0-9A-Za-z_-] {21} [AQgw]' , inputted_channel ): isolatedChannelID = inputted_channel else : print ( f \" \\n { B . RED }{ F . BLACK } Error: { S . R } Invalid Channel link or ID!\" ) return False , None , None if len ( isolatedChannelID ) == 24 and isolatedChannelID [ 0 : 2 ] == \"UC\" : response = auth . YOUTUBE . channels () . list ( part = \"snippet\" , id = isolatedChannelID ) . execute () if response [ 'items' ]: channelTitle = response [ 'items' ][ 0 ][ 'snippet' ][ 'title' ] return True , isolatedChannelID , channelTitle else : print ( f \" { F . LIGHTRED } Error { S . R } : Unable to Get Channel Title. Please check the channel ID.\" ) return False , None , None else : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Channel link or ID! { S . R } Channel IDs are 24 characters long and begin with 'UC'.\" ) return False , None , None","title":"validate_channel_id()"},{"location":"reference/Scripts/validation/#Scripts.validation.validate_config_settings","text":"validate_config_settings ( config ) Source code in Scripts/validation.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 def validate_config_settings ( config ): print ( \" \\n Validating Config Settings...\" ) print ( \"----------------------------------------------------- \\n \" ) # Helper Functions def print_quit_and_report (): print ( f \" \\n If you think this is a bug or can't figure it out, report it on the GitHub page: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( \" \\n Press Enter to exit...\" ) sys . exit () def print_int_fail ( setting , value ): print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( \"It should probably be an integer. Check the possible values listed in the config file for that setting.\" ) print_quit_and_report () # Validation Functions # -------------------------------------------------------------------------------------- def simple_settings_check ( setting , value ): if setting in validSettingsDict : # A None value means it can be any string if validSettingsDict [ setting ] == None : return True # For settings that accept more than one value, check each elif isinstance ( value , str ) and \",\" in str ( value ): try : settingList = utils . string_to_list ( value ) for settingValue in settingList : if settingValue not in validSettingsDict [ setting ]: print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( f \"It looks like you tried to enter a list. Check if that setting accepts multiple values or if you entered an invalid value.\" ) print_quit_and_report () return True except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( \"It looks like you tried to enter a list. Check if that setting accepts multiple values or if you entered an invalid value.\" ) print_quit_and_report () elif value in validSettingsDict [ setting ]: return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting ' { setting } ': { str ( value ) } \" ) print ( \"Check the config file to see valid possible values for that setting.\" ) print_quit_and_report () else : return None def validate_levenshtein ( value ): try : value = float ( value ) if value >= 0.0 and value <= 1.0 : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'levenshtein_distance': { str ( value ) } \" ) print ( \"It must be a number from 0 to 1!\" ) print_quit_and_report () except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'levenshtein_distance': { str ( value ) } \" ) print ( \"It must be a number from 0 to 1!\" ) print_quit_and_report () def validate_directory ( path ): if path == 'logs' : return True elif os . path . isdir ( path ): return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'log_path': { str ( path ) } \" ) print ( \"Make sure the folder exists!\" ) print_quit_and_report () def validate_encoding ( value ): try : codecs . lookup ( value ) return True except LookupError : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'json_encoding': { str ( value ) } \" ) print ( \"Make sure the encoding is valid!\" ) print_quit_and_report () def validate_videos_to_scan ( value ): if value == 'ask' : return True else : try : videoList = utils . string_to_list ( value ) except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'videos_to_scan': { str ( value ) } \" ) print ( \"Make sure it is either a single video ID / Link, or a comma separate list of them!\" ) print_quit_and_report () if len ( videoList ) > 0 : for video in videoList : if not validate_video_id ( video , basicCheck = True ): print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } There appears to be an invalid video ID or Link in setting 'videos_to_scan': { str ( value ) } \" ) print_quit_and_report () return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'videos_to_scan' (it may be empty!): { str ( value ) } \" ) print ( \"Make sure it is either a single video ID / Link, or a comma separate list of them!\" ) print_quit_and_report () def validate_channel_to_scan ( value ): if value == 'ask' or value == 'mine' : return True else : result , channelID , channelName = validate_channel_id ( value ) if result == False : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Config setting for 'channel_to_scan' appears invalid: { str ( value ) } \" ) print ( \"Make sure it is either a single channel ID or channel link. If it's a link, try using the channel ID instead.\" ) print_quit_and_report () else : return True def validate_channel_ids_to_filter ( value ): if value == 'ask' : return True else : try : channelList = utils . string_to_list ( value ) except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'channel_ids_to_filter': { str ( value ) } \" ) print ( \"Make sure it is either a single channel ID / Link, or a comma separate list of them!\" ) print_quit_and_report () for channel in channelList : if len ( channel ) != 24 or channel [ 0 : 2 ] != \"UC\" : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } There appears to be an invalid channel ID in setting 'channel_ids_to_filter': { str ( value ) } \" ) print ( \"A channel ID must be 24 charactres long and begin with 'UC'!\" ) print_quit_and_report () return True def validate_chars ( value ): if value == 'ask' : return True result = utils . make_char_set ( value , stripLettersNumbers = True , stripKeyboardSpecialChars = False , stripPunctuation = True ) if result : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'characters_to_filter': { str ( value ) } \" ) print ( \"For this mode, numbers, letters, and punctuation are removed. But there were no characters left to search!\" ) print_quit_and_report () def validate_strings ( value ): if value == 'ask' : return True try : result = utils . string_to_list ( value ) if len ( result ) > 0 : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'strings_to_filter': { str ( value ) } \" ) print ( \"The list appears empty! Make sure it is either a single string, or a comma separate list of them!\" ) print_quit_and_report () except : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } Invalid value for config setting 'strings_to_filter': { str ( value ) } \" ) print ( \"Make sure it is either a single string, or a comma separate list of them!\" ) print_quit_and_report () def validate_regex_setting ( value ): if value == 'ask' : return True isValid , expression = validate_regex ( value ) if isValid : return True else : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } The config setting 'regex_to_filter' does not appear to be valid: { str ( value ) } \" ) print ( \"Make sure it is a valid regular expresion! Example: [^ \\x00 - \\xFF ]\" ) print ( \"You can test them out on websites like regex101.com\" ) print_quit_and_report () # -------------------------------------------------------------------------------------- validSettingsDict = { 'use_this_config' : ( True , False , 'ask' ), 'this_config_description' : None , 'your_channel_id' : None , # None because will be checked right away anyway 'auto_check_update' : ( True , False ), 'release_channel' : ( 'all' , 'stable' ), 'skip_confirm_video' : ( True , False ), 'moderator_mode' : ( True , False ), 'auto_close' : ( True , False ), 'scan_mode' : ( 'ask' , 'chosenvideos' , 'recentvideos' , 'entirechannel' , 'communitypost' , 'recentcommunityposts' ), 'max_comments' : ( 'ask' ), # #'videos_to_scan': None, #'channel_to_scan': None, 'recent_videos_amount' : ( 'ask' ), # 'filter_mode' : ( 'ask' , 'id' , 'username' , 'text' , 'nameandtext' , 'autoascii' , 'autosmart' , 'sensitivesmart' ), 'filter_submode' : ( 'ask' , 'characters' , 'strings' , 'regex' ), #'channel_ids_to_filter': None, 'autoascii_sensitivity' : ( 'ask' , '1' , '2' , '3' ), #'characters_to_filter': None, #'strings_to_filter': None, #'regex_to_filter': None, 'detect_link_spam' : ( True , False ), 'detect_sub_challenge_spam' : ( True , False ), 'detect_spam_threads' : ( True , False ), 'duplicate_check_modes' : ( 'none' , 'id' , 'username' , 'text' , 'nameandtext' , 'autoascii' , 'autosmart' , 'sensitivesmart' ), #'levenshtein_distance': (), #'minimum_duplicates': None, 'skip_deletion' : ( True , False ), 'delete_without_reviewing' : ( True , False ), 'enable_ban' : ( 'ask' , False ), 'remove_all_author_comments' : ( 'ask' , True , False ), 'removal_type' : ( 'rejected' , 'heldforreview' , 'reportspam' ), 'whitelist_excluded' : ( 'ask' , True , False ), 'check_deletion_success' :( True , False ), 'enable_logging' : ( 'ask' , True , False ), #'log_path': None, 'log_mode' : ( 'rtf' , 'plaintext' ), 'json_log' : ( True , False ), #'json_encoding': None, 'json_extra_data' : ( True , False ), 'json_profile_picture' : ( False , 'default' , 'medium' , 'high' ), #'quota_limit': (), #'config_version': (), } # Settings that can or must contain an integer integerSettings = [ 'max_comments' , 'recent_videos_amount' , 'minimum_duplicates' , 'quota_limit' , 'config_version' ] # Dictionary of settings requiring specific checks, and the functions to validate them specialCheck = { 'levenshtein_distance' : validate_levenshtein , 'log_path' : validate_directory , 'json_encoding' : validate_encoding , 'videos_to_scan' : validate_videos_to_scan , 'channel_to_scan' : validate_channel_to_scan , 'channel_ids_to_filter' : validate_channel_ids_to_filter , 'characters_to_filter' : validate_chars , 'strings_to_filter' : validate_strings , 'regex_to_filter' : validate_regex_setting } # ADD CHECK FOR EMPTY STRING! for settingName , settingValue in config . items (): if settingValue == None or settingValue == '' : print ( f \" \\n { B . RED }{ F . WHITE } ERROR! { S . R } The config setting ' { settingName } ' appears empty!\" ) print ( \"Please go and add a valid setting value!\" ) print_quit_and_report () # Check integer value settings if settingName in integerSettings : try : int ( settingValue ) continue except ValueError : # Check if there is another valid value besides an integer if simple_settings_check ( settingName , settingValue ) == True : continue else : print_int_fail ( settingName , settingValue ) elif settingName in specialCheck : if specialCheck [ settingName ]( settingValue ) == True : continue # Check simple value settings else : result = simple_settings_check ( settingName , settingValue ) if result == True : continue elif result == None : print ( f \" \\n { B . RED }{ F . WHITE } WARNING! { S . R } An unknown setting was found: ' { settingName } ': { str ( settingValue ) } \" ) print ( f \"If you didn't add or change this setting in the config file, a validation check was probably forgotten to be created!\" ) print ( f \"Consider reporting it: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( f \" \\n It might not cause an issue, so press Enter to continue anyway...\" ) continue","title":"validate_config_settings()"},{"location":"reference/Scripts/validation/#Scripts.validation.validate_post_id","text":"validate_post_id ( post_url ) Source code in Scripts/validation.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def validate_post_id ( post_url ): if \"/post/\" in post_url : startIndex = post_url . rindex ( \"/\" ) + 1 endIndex = len ( post_url ) elif \"/channel/\" in post_url and \"/community?\" in post_url and \"lb=\" in post_url : startIndex = post_url . rindex ( \"lb=\" ) + 3 endIndex = len ( post_url ) else : isolatedPostId = post_url try : if startIndex < endIndex and endIndex <= len ( post_url ): isolatedPostID = post_url [ startIndex : endIndex ] except : return False , None , None , None , None # Post IDs used to be shorter, but apparently now have a longer format if len ( isolatedPostID ) == 26 or len ( isolatedPostID ) == 36 : if isolatedPostID [ 0 : 2 ] == \"Ug\" : validatedPostUrl = \"https://www.youtube.com/post/\" + isolatedPostID postOwnerURL = get_post_channel_url ( isolatedPostID ) valid , postOwnerID , postOwnerUsername = validate_channel_id ( postOwnerURL ) return valid , isolatedPostID , validatedPostUrl , postOwnerID , postOwnerUsername else : return False , None , None , None , None","title":"validate_post_id()"},{"location":"reference/Scripts/validation/#Scripts.validation.validate_regex","text":"validate_regex ( regex_from_user ) Source code in Scripts/validation.py 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def validate_regex ( regex_from_user : str ): try : re . compile ( regex_from_user ) is_valid = True processedExpression = regex_from_user except re . error : try : re . compile ( re . escape ( regex_from_user )) is_valid = True processedExpression = re . escape ( regex_from_user ) except re . error : print ( \"Failed\" ) is_valid = False processedExpression = None return is_valid , processedExpression","title":"validate_regex()"},{"location":"reference/Scripts/validation/#Scripts.validation.validate_video_id","text":"validate_video_id ( video_url_or_id , silent = False , pass_exception = False , basicCheck = False ) Source code in Scripts/validation.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def validate_video_id ( video_url_or_id , silent = False , pass_exception = False , basicCheck = False ): youtube_video_link_regex = r \"^\\s*(?P<video_url>(?:(?:https?:)?\\/\\/)?(?:(?:www|m)\\.)?(?:youtube\\.com|youtu.be)(?:\\/(?:[\\w\\-]+\\?v=|embed\\/|v\\/)?))?(?P<video_id>[\\w\\-] {11} )(?:(?(video_url)\\S+|$))?\\s*$\" match = re . match ( youtube_video_link_regex , video_url_or_id ) if match == None : if basicCheck == True : return False if silent == False : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Video link or ID! { S . R } Video IDs are 11 characters long.\" ) return False , None , None , None , None elif basicCheck == True : possibleVideoID = match . group ( 'video_id' ) if len ( possibleVideoID ) == 11 : return True else : try : possibleVideoID = match . group ( 'video_id' ) result = auth . YOUTUBE . videos () . list ( part = \"snippet,id,statistics\" , id = possibleVideoID , fields = 'items/id,items/snippet/channelId,items/snippet/channelTitle,items/statistics/commentCount,items/snippet/title' , ) . execute () if possibleVideoID == result [ 'items' ][ 0 ][ 'id' ]: channelID = result [ 'items' ][ 0 ][ 'snippet' ][ 'channelId' ] channelTitle = result [ \"items\" ][ 0 ][ \"snippet\" ][ \"channelTitle\" ] videoTitle = result [ \"items\" ][ 0 ][ \"snippet\" ][ \"title\" ] # When comments are disabled, the commentCount is not included in the response, requires catching KeyError try : commentCount = result [ 'items' ][ 0 ][ 'statistics' ][ 'commentCount' ] except KeyError : if pass_exception == True : # If the video has comments disabled, the commentCount is not included in the response, but the video is still valid return True , possibleVideoID , videoTitle , \"0\" , channelID , channelTitle traceback . print_exc () print ( \"--------------------------------------\" ) print ( f \" \\n { B . RED }{ F . WHITE } ERROR: { S . R } { F . RED } Unable to get comment count for video: { S . R } { possibleVideoID } | { videoTitle } \" ) print ( f \" \\n { F . YELLOW } Are comments disabled on this video? { S . R } If not, please report the bug and include the error info above.\" ) print ( f \" Bug Report Link: { F . YELLOW } TJoe.io/bug-report { S . R } \" ) input ( \" \\n Press Enter to return to the main menu...\" ) return \"MainMenu\" , \"MainMenu\" , \"MainMenu\" , \"MainMenu\" , \"MainMenu\" return True , possibleVideoID , videoTitle , commentCount , channelID , channelTitle else : if silent == False : print ( \"Something very odd happened. YouTube returned a video ID, but it is not equal to what was queried!\" ) return False , None , None , None , None except AttributeError : if silent == False : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Video link or ID! { S . R } Video IDs are 11 characters long.\" ) return False , None , None , None , None except IndexError : if silent == False : print ( f \" \\n { B . RED }{ F . BLACK } Invalid Video link or ID! { S . R } Video IDs are 11 characters long.\" ) return False , None , None , None , None","title":"validate_video_id()"}]}